<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Perplexity</title>
<meta name="description" content="An amazing website.">


  <meta name="author" content="Your Name">
  


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Perplexity">
<meta property="og:title" content="Perplexity">
<meta property="og:url" content="http://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo022Testing/">


  <meta property="og:description" content="An amazing website.">











  

  


<link rel="canonical" href="http://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo022Testing/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Your Name",
      "url": "http://blog.inductorsoftware.com/Perplexity/home/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/Perplexity/home/feed.xml" type="application/atom+xml" rel="alternate" title="Perplexity Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/Perplexity/home/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--delphin_page wide">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/Perplexity/home/"><img src="/Perplexity/home/assets/images/Delph-In.png" alt="Perplexity"></a>
        
        <a class="site-title" href="/Perplexity/home/">
          Perplexity
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="https://blog.inductorsoftware.com/Perplexity/home/devOverview">Home</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      





<div id="main" role="main">
  
  <div class="sidebar sticky">
  
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle Menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">Developer Tutorial Overview</span>
        

        
        <ul>
          
            <li><a href="/Perplexity/home/devOverview/">Overview</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">MRS Conceptual</span>
        

        
        <ul>
          
            <li><a href="/Perplexity/home/mrscon/devhowto0010MRS/">Minimal Recursion Semantics (MRS)</a></li>
          
            <li><a href="/Perplexity/home/mrscon/devhowto0020WellFormedTree/">Well-Formed Trees</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">MRS Solver Conceptual</span>
        

        
        <ul>
          
            <li><a href="/Perplexity/home/devcon/devcon0000Overview/">Overview</a></li>
          
            <li><a href="/Perplexity/home/devcon/devcon0010MRSSolver/">Backtracking</a></li>
          
            <li><a href="/Perplexity/home/devcon/devcon0020MRSSolverSets/">Representing 'Together'</a></li>
          
            <li><a href="/Perplexity/home/devcon/devcon0030MRSSolverSolutionGroups/">Collective, Distributive, Cumulative</a></li>
          
            <li><a href="/Perplexity/home/devcon/devcon0050MRSSolverSolutionCombinations/">Combinations and Proper Responses</a></li>
          
            <li><a href="/Perplexity/home/devcon/devcon0060WhichParseAndTree/">Choosing a Parse and Tree</a></li>
          
            <li><a href="/Perplexity/home/devcon/devcon0070SentenceForce/">Sentence Types</a></li>
          
            <li><a href="/Perplexity/home/devcon/devcon0080ErrorsChoosingWhichFailure/">Choosing a Failure</a></li>
          
            <li><a href="/Perplexity/home/devcon/devcon0040MRSSolverSolutionGroupsAlgorithm/">A. Optimizing Coll/Dist/Cuml</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Using Perplexity</span>
        

        
        <ul>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo010Overview/">Overview</a></li>
          
            <li><a href="/Perplexity/home/pxHowTo/pxHowTo012Install/">Installing Perplexity</a></li>
          
            <li><a href="/Perplexity/home/pxHowTo/pxHowTo014HelloWorld/">Hello World</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo020ImplementAPredication/">Implementing a Predication</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo022Testing/" class="active">Testing</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo030InStylePredications/">In-Style Predications</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo040LiftStylePredications/">Lift-Style Predications</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo050EventPredications/">Event Predications</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo070ActionVerbs/">Verb Predications</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo082State/">Custom State</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo085Place/">Representing Places</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo090Prepositions/">Directional Propositions</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo100NonlogicalMeaning/">Solution Group Handlers and Non-logical Meaning</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo105GlobalCriteria/">Solution Group Handlers and Global Criteria</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo110HandlingTenses/">Handling Tenses</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo120ConceptsReferringExpressions/">Conceptual References</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo080QuantifiersAndDeterminers/">Quantifiers and Determiners</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo130OpenClassWords/">Centralizing Nouns/Adjectives</a></li>
          
            <li><a href="/Perplexity/home/pxhowto/pxHowTo025SStrings/">A. Generating English with S-strings</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Perplexity Internals</span>
        

        
        <ul>
          
            <li><a href="/Perplexity/home/pxint/pxint0000Overview/">Overview</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0010PredicationContract/">The Predication Contract</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0020PythonBasics/">State and Python Basics</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0030ImplementPredication/">Implementing a Predication</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0040BuildSolver/">Initial Solver</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0050Conjunctions/">Solving Conjunctions</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0060ScopalArguments/">Solving Scopal Arguments</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0080SimplePropositions/">Propositions</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0090SimpleQuestions/">Questions</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0100SimpleCommands/">Commands</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0105ErrorsChoosingWhichFailure/">Choosing a Failure</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0110ErrorsReportingAFailure/">Naive Failure Text</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0120ErrorsConceptualFailures/">English Variable Domains</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0130ErrorsRobustFailure/">Robust Failure Text</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0070GenerateMRSAndTrees/">Generating MRS and Trees</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint0071WhichParseAndTree/">Choosing a Parse and Tree</a></li>
          
            <li><a href="/Perplexity/home/pxint/pxint03000PythonDecorators/">A. Python Decorators</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    
    
    
    

    <div class="page__inner-wrap">
      
        <header>
          


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
        <h2 id="testing">Testing</h2>
<p>Now that we have implemented a predication, it is important to understand how to test it.  In a Perplexity application, it is very easy to enhance a predication to support one scenario and break others that used to work. So, to keep the system working well and avoid functionality regressions, you should always write at least simple functionality tests for phrases once they work.</p>

<p>Since the interface to a Perplexity system is simply textual user input, and the output is also text, the built-in Perplexity test functionality just records the output that you expect for a given phrase when it is working properly. Then, you can run the test again when you’ve changed something and it will tell you if the expected output has changed.</p>

<h3 id="recording-a-test">Recording a test</h3>
<p>You can see all the commands (even beyond testing) that Perplexity supports by typing “/help”:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>? /help

Commands start with /:

****** General ******
/help Get list of commands -&gt; e.g. /help
/r Repeat the last phrase -&gt; e.g. /r
/s Repeat the last system command (i.e. the /command) -&gt; e.g. /s
/new Calls the passed function to get the new state to use -&gt; e.g. /new examples.Example18_reset
/reset Resets to the initial state -&gt; e.g. /reset
/save Saves the current world state to the ./data/default directory. If given a path, saves to that path instead. -&gt; e.g. /save
/load Loads the current world state from the ./data/default directory. If given a path, loads from that path instead. -&gt; e.g. /load
/timeout Sets timeout time for a given phrase -&gt; e.g. /timeout or /timeout 20

****** Parsing ******
/show Shows tracing information from last command. Add 'all' to see all interpretations, 1 to see only first trees -&gt; e.g. /show or /show all or /show all, 1
/soln Retrieves all solutions when parsing so they can be shown with /show. Add 'all' to see all solutions, anything else toggles the current setting -&gt; e.g. /soln or /soln all
/genall Generates all parses (normally only the first 5 are generated) -&gt; e.g. /genall 1 OR /genall True
/runall Runs all parses, doesn't stop after success -&gt; e.g. /runall 1 OR /runall True
/runparse Only runs the identified parse index and optional tree index. Pass no arguments to turn off -&gt; e.g. /runparse 1 OR /runparse 1, 0
/debugtree Shows tracing information about the tree. give a predication query after to only show trees that match it. Use '_' to mean 'anything' for an argument or the predication name -&gt; e.g. /debugtree OR /debugtree which(x,h,h) OR /debugtree _(e,x,_,h)
/debugmrs Shows tracing information about the mrs -&gt; e.g. /debugmrs
/findmrs ? -&gt; e.g. /findmrs

****** Testing ******
/recordtest Starts recording a test. Finish with /createtest or /appendtest -&gt; e.g. /record
/createtest Creates a test using name you specify based on the interactions recorded by /record -&gt; e.g. /createtest Foo
/appendtest Appends the interactions recorded by /record to an existing test -&gt; e.g. /appendtest Foo
/runtest Runs a test -&gt; e.g. /runtest subdirectory/foo
/resolvetests Resolves all the test results stored in 'testresults.txt' -&gt; e.g. /resolvetests
/logtests Logs test results to the file 'testresults.txt' -&gt; e.g. /logtests true
/runfolder Runs all tests in a directory or directories. use '.' to run folders in the root -&gt; e.g. /runfolder foldername or /runfolder a, b, c
/resume Resume running the last test (or sequence of tests in a folder) at the last reset before it was stopped -&gt; e.g. /resume
</code></pre></div></div>

<p>Let’s start by recording a test using the <code class="language-plaintext highlighter-rouge">/recordtest</code> command and by running the code we’ve done so far and doing this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>? /recordtest
Recording is now True

? a file is large
Yes, that is true.
Recorded (1 items).

? which file is large?
(File(name=/Desktop/file2.txt, size=10000000),)
Recorded (1 items).
</code></pre></div></div>

<p>You can see that the system is recording each interaction by the text <code class="language-plaintext highlighter-rouge">Recorded (1 items).</code> at the end of the interaction.  Perplexity will keep gathering all the commands until you are done. Then you can create a test like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>? /createtest test1
Created test 'test1'
Recording is now off
</code></pre></div></div>

<p>This creates a test called “test1” and stops recording.  Tests are simply JSON files that are stored in <code class="language-plaintext highlighter-rouge">/perplexity/tests</code>.  If you open the file, you’ll see:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
    "WorldName": "SimplestFileSystemStateExample",
    "TestItems": [
        {
            "Command": "a file is large",
            "Expected": "Yes, that is true.",
            "Tree": "_a_q(x3,_file_n_of(x3,i8),_large_a_1(e2,x3))",
            "Enabled": true,
            "ID": "aa9b1bbc-1939-4065-bd80-5b8aeb922076"
        },
        {
            "Command": "which file is large?",
            "Expected": "(File(name=/Desktop/file2.txt, size=10000000),)",
            "Tree": "_which_q(x3,_file_n_of(x3,i8),_large_a_1(e2,x3))",
            "Enabled": true,
            "ID": "a75503d7-fc49-4369-9cc8-bb159afc2d29"
        }
    ]
}
</code></pre></div></div>

<p>The system is simply recording the input, output, the tree that was used, and an ID.  There is also an “Enabled” field that you can set to “false” if you want a particular test to be ignored.</p>

<p>To run the test:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>? /runtest test1
**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...


**** Begin Testing...

**** Writing LastTest: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...


Test: a file is large
Yes, that is true.

Test: which file is large?
(File(name=/Desktop/file2.txt, size=10000000),)

**** Testing Complete. Elapsed time: 1.74585
</code></pre></div></div>

<p>It all looks good because nothing changed. But let’s change <code class="language-plaintext highlighter-rouge">file_n_of</code> to return a different file name:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def file_n_of(context, state, x_binding, i_binding):
    if x_binding.value is None:
#        yield state.set_x(x_binding.variable.name, ("file1.txt",))
        yield state.set_x(x_binding.variable.name, ("file2.txt",))
    elif len(x_binding.value) == 1 and x_binding.value[0] == "file1.txt":
        yield state
    else:
        report_error(["notAThing", x_binding.value, x_binding.variable.name])
        return False
</code></pre></div></div>

<p>… and run the test again:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>? /runtest test1
**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...


**** Begin Testing...

**** Writing LastTest: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...


Test: a file is large
Yes, that is true.

Test: which file is large?
(File(name=/documents/file1.txt, size=10000000),)

Expected: 
(File(name=/Desktop/file2.txt, size=10000000),)
(&lt;enter&gt;)ignore, (b)reak to end testing, (u)pdate test, (a) add alternative correct result, (d)isable test
</code></pre></div></div>

<p>Perplexity notices the output changed and tells you what it expected. Now you have to decide what to do about it:</p>

<ul>
  <li>Maybe you meant to do the change. Press “u” to update the test to use this new output as the expected output</li>
  <li>Maybe you want to ignore it for now, press “enter”</li>
  <li>Sometimes a phrase might have multiple good answers, you can add this as an alternative using “a”</li>
  <li>If you want to disable the test push “d”</li>
  <li>You stop the test by pushing “b”</li>
</ul>

<h3 id="updating-tests">Updating tests</h3>
<p>Tests usually grow over time. To do this, you can record some more interactions and use the <code class="language-plaintext highlighter-rouge">/appendtest</code> command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>? /recordtest
Recording is now True

? is a file large?
Yes.
Recorded (1 items).

? /appendtest test1
Recording is now off

? /runtest test1
**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...


**** Begin Testing...

**** Writing LastTest: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...


Test: a file is large
Yes, that is true.

Test: which file is large?
(File(name=/Desktop/file2.txt, size=10000000),)

Test: is a file large?
Yes.

**** Testing Complete. Elapsed time: 2.01737
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">/appendtest</code> simply adds these new interactions to the end of the test. You can see that, when it is run, the whole sequence gets run.</p>

<h3 id="resetting-state">Resetting State</h3>
<p>Often your tests will end up manipulating the state of the world and you’ll want to reset it to try alternatives. You can do this with the <code class="language-plaintext highlighter-rouge">/reset</code> command. You give it the <code class="language-plaintext highlighter-rouge">module.function_name</code> of your reset function, like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>? /reset hello_world.hello_world_FileSystemState.reset
State reset using hello_world_FileSystemState.reset().

Recorded (1 items).

? /appendtest test1
Recording is now off
</code></pre></div></div>

<p>(You’ll need to use the module and function name that you’ve used to successfully run the example above.)</p>

<p>Since we appended the session, the reset will now happen at the end. This might be fine if we’re going to add more interactions that we want to happen in a fresh world. But it is also a best practice to always start your tests with a reset so you know the world is starting in a known state.  You can simply edit the file and move that reset to the beginning.  It is just a JSON file. Here’s what it looks like when finished:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
    "WorldName": "SimplestFileSystemStateExample",
    "TestItems": [
        {
            "Command": "/reset hello_world.hello_world_FileSystemState.reset",
            "Expected": "",
            "Tree": "None",
            "Enabled": true,
            "ID": "455b3e38-cf6e-4ee0-9767-6197f47bd586"
        },
        {
            "Command": "a file is large",
            "Expected": "Yes, that is true.",
            "Tree": "_a_q(x3,_file_n_of(x3,i8),_large_a_1(e2,x3))",
            "Enabled": true,
            "ID": "aa9b1bbc-1939-4065-bd80-5b8aeb922076"
        },
        {
            "Command": "which file is large?",
            "Expected": "(File(name=/Desktop/file2.txt, size=10000000),)",
            "Tree": "_which_q(x3,_file_n_of(x3,i8),_large_a_1(e2,x3))",
            "Enabled": true,
            "ID": "a75503d7-fc49-4369-9cc8-bb159afc2d29"
        },
        {
            "Command": "is a file large?",
            "Expected": "Yes.",
            "Tree": "_a_q(x3,_file_n_of(x3,i8),_large_a_1(e2,x3))",
            "Enabled": true,
            "ID": "158d0487-a8c6-49ee-b01c-0a861a80d4ce"
        }
    ]
}
</code></pre></div></div>

<p>And now when we run it, you can see the reset happening at the beginning:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>? /runtest test1
**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...


**** Begin Testing...

**** Writing LastTest: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...


Test: /reset hello_world.hello_world_FileSystemState.reset
State reset using hello_world.hello_world_FileSystemState.reset().


Test: a file is large
Yes, that is true.

Test: which file is large?
(File(name=/Desktop/file2.txt, size=10000000),)

Test: is a file large?
Yes.

**** Testing Complete. Elapsed time: 2.12325
</code></pre></div></div>

<p>You can feel free to rearrange and edit the information in these test files, as long as you don’t break the JSON format.</p>

<h3 id="folders">Folders</h3>
<p>“test1.tst” was created in the <code class="language-plaintext highlighter-rouge">/perplexity/tests</code> folder. You can also organize your tests using folders:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">/createtest myfolder/test2</code>: creates a <code class="language-plaintext highlighter-rouge">/perplexity/tests/myfolder</code> folder and puts your test there.</li>
  <li><code class="language-plaintext highlighter-rouge">/runtest myfolder/test2</code>: runs the test in that folder.</li>
  <li><code class="language-plaintext highlighter-rouge">/appendtest myfolder/test2</code>: appends to it.</li>
</ul>

<p>etc.</p>

<p>You can also run <em>all</em> the tests in a folder like this:</p>

<p><code class="language-plaintext highlighter-rouge">/runfolder myfolder</code></p>

<h3 id="stopping-and-resuming-a-test">Stopping and Resuming a Test</h3>
<p>When a test breaks, you will often hit “b” to stop it, go fix it, and want to see if you fixed it. Sometimes you’d like to just restart where the break happened, especially if it is a long test.  You do this with the <code class="language-plaintext highlighter-rouge">/resume</code> command. If you type that command, Perplexity will resume the test <em>starting with the most recent <code class="language-plaintext highlighter-rouge">reset</code> command</em>. It does this because starting right where things broke might put the state in a different configuration. Restarting at the reset point ensures the state gets built up properly.</p>

<p>Due to this, it is always good to put resets into your test as you test different scenarios so you can <code class="language-plaintext highlighter-rouge">/resume</code> and get back to it more quickly and not have to start from the beginning.</p>

<p>Note that this also works for <code class="language-plaintext highlighter-rouge">/runfolder</code>.  You might have stopped the test 10 folders into the run, but <code class="language-plaintext highlighter-rouge">/resume</code> will start at that same place and skip the first 9 folders.</p>

<p>Also note that the test location is recorded on disk. So you can shut down your computer and come back and it will still resume in the right place.</p>

<h3 id="logging-tests">Logging Tests</h3>
<p>Sometimes you can’t sit there and watch the test run so you can continue over or update the tests that changed. You’d like to run the whole thing and then see what all the failures were when it is all done.  To do this, you run <code class="language-plaintext highlighter-rouge">/logtests</code> before running a test or a folder. Perplexity will then record all the failures in a file called <code class="language-plaintext highlighter-rouge">/perplexity/testresults.txt</code>. You could look at this file to see what happened, but a better way is to run <code class="language-plaintext highlighter-rouge">/resolvetests</code>. This will run you through the same interaction you would have had by just running interactively, but only on the failures.  If we redo the previous example where we intentionally broke a test, we’d get:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>? /logtests
Log Test Results is now True

? /runtest test1
**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...

Logging test results to: /Users/ericzinda/Enlistments/Perplexity/perplexity/testresults.txt

**** Begin Testing...

**** Writing LastTest: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...


Test: /reset hello_world.hello_world_FileSystemState.reset
State reset using hello_world.hello_world_FileSystemState.reset().


Test: a file is large
Yes, that is true.

Test: which file is large?
(File(name=/documents/file1.txt, size=10000000),)

Test: is a file large?
Yes.

**** Testing Complete. Elapsed time: 2.53661

? /resolvetests
Resolving test results in: /Users/ericzinda/Enlistments/Perplexity/perplexity/testresults.txt
**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...

**** Test ID: a75503d7-fc49-4369-9cc8-bb159afc2d29
which file is large?
(File(name=/documents/file1.txt, size=10000000),)

Expected: 
(File(name=/Desktop/file2.txt, size=10000000),)
(&lt;enter&gt;)ignore, (b)reak to end testing, (u)pdate test, (a) add alternative correct result, (d)isable test
</code></pre></div></div>

<p>You can see that running the tests didn’t say anything or stop when a test failed, but running <code class="language-plaintext highlighter-rouge">/resolvetests</code> allows you to figure out what the failure was and decide what to do with it.</p>

<p>Last update: 2024-10-17 by Eric Zinda [<a href="https://github.com/EricZinda/Perplexity/edit/main/docs/pxHowTo/pxHowTo022Testing.md">edit</a>]</p>

        
      </section>

      <footer class="page__meta">
        
        


        


      </footer>

      

      
    </div>

    
  </article>

  
  
</div>

<!--Scroll the navbar to the current page-->
<script type="text/javascript">
  let el = document.querySelector('.nav__list .active');
  if(el){
    el.scrollIntoView({block: "center", inline: "start"});
  }
</script>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="Enter your search term..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/Perplexity/home/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2024 Your Name. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/Perplexity/home/assets/js/main.min.js"></script>




<script src="/Perplexity/home/assets/js/lunr/lunr.min.js"></script>
<script src="/Perplexity/home/assets/js/lunr/lunr-store.js"></script>
<script src="/Perplexity/home/assets/js/lunr/lunr-en.js"></script>







  </body>
</html>
