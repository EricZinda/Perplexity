[{"body": ""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devOverview", "excerpt":"Overview\nPerplexity is a Python framework for building natural language interfaces to software. It does deep linguistic processing by using the DELPH-IN technologies which take a very different approach from that used in Large Language Models. To use Perplexity, you implement a set of logic-based functions that represent the words in your domain using Python. Thus, it is truly \"hallucination-free\" because is it uses only code that you have written, that can be inspected, debugged, etc. There is no \"magic\" going on. You can always understand exactly why a phrase was understood the way it was because you can debug it using regular tools, applied to regular Python code. The cost for this approach is that you actually need to implement the logic for all the words in your domain. This documentation will show you how.\nThe DELPH-IN technologies are the basis for the deep linguistic processing in Perplexity, but they stop at generating a logical representation of a phrase.\nThis tutorial is designed to show developers how to consume this logical representation using a narrow set of DELPH-IN technologies (especially MRS and ACE) to build an application. It focuses on one particular application (a natural language interface to a computer's file system), but the concepts should apply to any type of constrained system ('constrained' in the sense of the size of the world under discussion). It also takes one particular approach to building the system by logically evaluating the output of the DELPH-IN parsers against a world definition. While this approach may not be the right one for every application, the concepts illustrated and the tools used along the way should be more broadly applicable.\nThe tutorial will use the DELPH-IN English Resource Grammar (ERG) to parse English, but the concepts are the same across the DELPH-IN grammars.  In fact, the library functions we build have no dependency on the grammar at all. They can be used for any of the DELPH-IN grammars.\nPython was chosen as a simple, popular, open-source language available on many platforms. However, the examples and approach shown here could be implemented in any language. There is not much code in the core solver and associated helper functions that would need to be translated. The overwhelming majority of code will be in the implementation of the terms you implement for your own domain.\nIt is designed to be read in order, but the most important background is in the first two sections, The Minimal Recursion Semantics (MRS) Format and Building Scope-Resolved MRS. These should definitely be read before moving on to the rest of the topics. The rest of the topics broadly break down into how-to topics which walk through writing the Python code to implement a system and conceptual topics which cover the background on the algorithms and concepts referred to in the How-To.\nComprehensive source for the completed tutorial is available here.\n\n", "title":"Overview", "teaser":"Overview\nPerplexity is a Python framework for building natural language interfaces to software. It does deep linguistic processing by using the DELPH- ...", "site":"Perplexity", "section":"Developer Tutorial Overview", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/mrscon/devhowto0010MRS", "excerpt":"The Minimal Recursion Semantics (MRS) Format\nThis section is designed to give application developers an overview of the Minimal Recursion Semantics format which is the primary artifact used by DELPH-IN to represent the meaning of a phrase. For a deeper dive into MRS, or one that has a more academic or linguistic approach, explore Minimal Recursion Semantics: An Introduction.\n\nThe DELPH-IN English Resource Grammar (ERG) converts an English phrase into a data structure called an \"Minimal Recursion Semantics Formalism\" (MRS) which is a technical representation of human language. The ACE processor, among other processors, processes the grammar and the phrase to produce the MRS formalism and represent it in one of several formats, such as Simple MRS. Processors can be used with any of the other DELPH-IN grammars to convert other natural languages into the MRS formalism. While the examples below use English, the concepts apply across the DELPH-IN grammars.\nBecause language is ambiguous, most phrases parse into more than one MRS document, each representing a different interpretation of the phrase. Each MRS document encodes one high-level meaning of the phrase into a list of predicate-logic-like predicates (called predications).\nEach MRS document also has multiple interpretations. Using constraints that are included as part of the MRS, a set of trees (called scope-resolved mrss) can be built from the flat list of predications in a given MRS.  These scope-resolved mrss define all the alternative meanings of that particular MRS.\nSo, a phrase generates n MRS documents, each of those generates m scope-resolved mrss, which results in n x m possible interpretations of a single phrase. One of the challenges of building a system that uses natural language is to determine which of the many possible meanings was intended by the user (one approach to doing this will be discussed in the conceptual topic: Determining the Right Parse and Tree).\nFor example, the phrase: \"Look under the table.\" produces 12 different MRS documents (also called \"parses\" or \"interpretations\"). These include interpretations that mean: \n\"Look (at whatever is) under the table\" \n\n\"Look (around while you are) under the table\" \n\n... among 10 others. \nThe MRS document for the first interpretation is:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _under_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _look_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nUsing the constraints described in the HCONS section (which we will describe later), there are two scope-resolved mrss that can be built from that MRS, which describe the two alternatives that it could mean:\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x9)\n_the_q(x9,RSTR,BODY)               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\n                 \u2514\u2500 pronoun_q(x3,RSTR,BODY)    \u250c\u2500\u2500 _under_p_dir(e8,e2,x9)\n                                        \u2514\u2500 and(0,1)\n                                                 \u2514 _look_v_1(e2,x3)\n\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\npronoun_q(x3,RSTR,BODY)            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x9)\n                    \u2514\u2500 _the_q(x9,RSTR,BODY)    \u250c\u2500\u2500 _under_p_dir(e8,e2,x9)\n                                        \u2514\u2500 and(0,1)\n                                                 \u2514 _look_v_1(e2,x3)\n\nThe rest of this section will give you a base understanding of the MRS formalism so that we can explore how to build these scope-resolved mrss in a later section and ultimately write software that derives the speaker's intended meaning from them.  Deriving their intended meaning is the topic of this entire tutorial.\nUnderspecification\nA DELPH-IN parser like ACE will usually generate more than one MRS document representing the various high-level interpretations of a phrase. Each one contains a list of predicate-logic-like predications and not a tree like you'll see in many natural language systems.  That's because it is underspecified.  Even though the parser has already done one level of interpretation on the phrase, there are still (usually) multiple ways to interpret that.  \nThe final interpretations of a phrase are called \"scope-resolved MRS\". The MRS document doesn't pick a primary interpretation by choosing a specific tree, it provides the rules for building all of them. That's what \"underspecified\" means. Every book is in a cave could mean \"all books are in the same cave\" or \"every book is in a (possibly different) cave\". Given just the phrase, it isn't clear which the speaker intended, so the MRS provides all the alternatives. Context (which the MRS doesn't have) usually helps to decide which is meant.\nThis section will go through the entire MRS document in detail, but as a navigational guide to the format itself: The list of predicate-logic-like predications in provided in the RELS section of the MRS document:\n...\n\nRELS: &lt; \n[ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _under_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _look_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\n\n...\n\n... and the HCONS section lists the constraints on putting the predications together to create a scope-resolved mrs which represents a single meaning:\n... \n\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nThe MRS is underspecified, and the RELS together with the HCONS provide the information to make it specific and recover the various possible meanings.\nPredications\nA phrase is converted into a list of predicate-logic like predications in the MRS which you can see in the RELS section of the MRS for \"Look under the table\":\n...\n\nRELS: &lt; \n[ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _under_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _look_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\n\n...\n\nPredications are \"predicate-logic-like\" in that they state a relation or a fact about their arguments that must be true in order for the MRS to be true. The arguments are most often variables and, if you find values for all the variables that make all the predications in the MRS true in a given world, then you have \"solved\" or \"resolved\" the MRS. You have figured out (in a sense) the meaning of the sentence. So, predications do the work in an MRS by providing constraints or restrictions on the variables they are passed. \nFor example: the predication _table_n_1(x9) in the example above is saying \"restrict the set of things in the variable x9 to be only those which are a 'table'\" or, alternatively: \"ensure that x9 contains a 'table'\".  Depending on how you ultimately solve the MRS, you might look at these variables as containing sets or individual items. Our approach will start by iteratively solving the MRS using sets.\nIf we evaluated a different predication such as _large_a_1(x9) immediately afterward, it would mean \"also make sure the thing in x9 is 'large'\".  An MRS that contains both predications like that is saying, \"restrict x9 to be a 'large table' from the world we are talking about\".\nWe'll get into the other examples later after we've covered more basics.\nPredication Labels\nEach predication has a label in the MRS, indicated by LBL:. The label serves as an ID or a pointer to the predication. Note that predications can share the same label. In fact, this is how the MRS indicates they are \"in conjunction\" (i.e. should be interpreted together using a logical \"and\", as in the above example).\nLook at the labels for the different predications in an MRS for \"Look under the large table\" and note that _large_a_1 and _table_n_1 share the same label, indicating they are \"in conjunction\":\n[ TOP: h0\nINDEX: e2\nRELS: &lt; [ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _large_a_1 LBL: h13 ARG0: e14 [ e SF: prop TENSE: untensed MOOD: indicative PROG: bool PERF: - ] ARG1: x9 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _under_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _look_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nThese labels are used to turn the flat list of predications into the set of scope-resolved mrss that represent its various meanings. The section below on scopal arguments gives an overview of how this works. The Scope-Resolved Mrss topic describes it in detail.\nPredication Names\nThe name of a predication, for example, _table_n_1, encodes important information about it:\nThe \"lemma\" or root word (this is the first word you see): \"table\"\n\nWhether it was actually seen in the text (starts with _) or added abstractly by the grammar (no initial _)\n\nIts part of speech. The _n_ in _table_n_1 means \"table\" is a \"noun\". The _q in _the_q means \"the\" is a \"quantifier\" (quantifiers are described below)\n\nIt may have extras at the end like _1 to indicate which \"variant\" or synonym of the word it represents\n\nThere is some documentation for what the predications mean, which can be found by doing a search of the documentation. Otherwise, their meaning can often be determined by looking at the MRS and intuiting what they are trying to do using your knowledge of the language. If all else fails, you can post on the message boards.  \nPredication Arguments and Variables\nPredications have arguments with names like ARG0, ARG1, ARG2, RSTR, BODY, etc.  Think of those exactly like the name of named arguments in some programming languages such as Python.\nThey also have variables assigned to the arguments like x5, h1, e6.  The initial letter in the name indicates the \"type\" of variable it is.  The types create a hierarchy, with the bottommost \"leaves\" being the types that are the most concrete and most common in predications. Each of these types will be discussed below:\n    u\n   / \\\n  i   p\n / \\ / \\\ne   x   h\n\nThe number on a variable just makes it unique. When the same variable name appears in more than one place it is shared, just like if you used a Python variable in more than one place in a function.\nSo, if an MRS has two predications like this:\n[ _large_a_1 LBL: h13 ARG0: e14 [ e SF: prop TENSE: untensed MOOD: indicative PROG: bool PERF: - ] ARG1: x9 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n\n... you can see that:\n_large_a_1 has two arguments: ARG0 and ARG1, and the variables assigned to them are: e14 and x9. The first is of type event (e) and the second is of type instance (x)\n\n_table_n_1 shares x9 in its ARG0 and so both predications are restricting the same variable. This means that, ultimately, x9 should contain only \"large tables\"\n\nThinking of MRS variables as variables in a math equation can help: The MRS is effectively defining a formula with variables. One way to use the formula is to find the set of all variable values that make the MRS true in a given world. Those values, combined with the predications they are used in, provide a valuable tool for getting at the meaning of the original phrase.\nOf all the arguments, ARG0 is special.  It holds a variable that \"represents\" the predication, sometimes called the \"characteristic\" or \"distinguished\" variable, but most often the \"instrinsic variable\".  If you read the Minimal Recursion Semantics: An Introduction documentation, you'll see the term \"introduced\" is used to describe the intrinsic variable.  A predicate is described as \"introducing\" its \"intrinsic variable\" (which is always ARG0). Sometimes phrases like \"the variable introduced by predicate X...\" are used.  This will become important later, mostly when we talk about events or about how to convert predications back into a phrase. For now, it is enough to understand that ARG0 represents the predication in some special ways.\nOne final point: Every variable in an MRS is introduced by exactly one predication in the MRS (which is why they can serve as makeshift \"representations\" of the predication). We'll come back to this when we talk about i, p and u variable types.\nH (Handle) Variables, aka \"Scopal Arguments\"\nThe semantic meaning of an MRS is ultimately represented by a tree (described in the next topic) and handle variables passed to predications (aka \"scopal arguments\") provide the mechanism to build a tree from the list of predications.\nHandle variables represent the \"holes\" where branches of the tree can be placed. To do this, handle variables are set to the LBL of another predication. As described above, the MRS LBL field serves as a way to \"label\" each predication with a unique identifier. Thus, the LBL: of a predication can be assigned to a handle variable in a different predication to indicate that it should be placed there. By assigning LBL:s to holes like that, an entire tree can be built.\nWhen a tree is built and being resolved, a predication with handle arguments is expected to use those branches to do ... whatever it is supposed to do. For example, the _the_q has two handle arguments, h5 and h6 in the MRS for \"The dog is small\":\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _dog_n_1 LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _small_a_1 LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\nIn building a tree, we have assigned LBL: h7 to h5 and LBL: h1 to h6:\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _dog_n_1(x3)\n_the_q(x3,RSTR,BODY)\n                 \u2514\u2500 _small_a_1(e2,x3)\n\nThink of this process like a lambda function being passed to a function in a programming language like C++ or C#.  The the_q predication itself will be responsible for \"doing something\" with the two branches it is passed.  What, exactly, is specific to the predication. We go into this more in the section on  solving scopal arguments. For now, think about scopal arguments as places to put other predications which are acting like programming language \"lambda functions\".\nBecause the MRS is underspecified, it usually doesn't directly list which predication to put in which scopal argument. You figure that out by the process of creating a scope-resolved mrs.  However, if a predication has a LBL that is the same handle as a scopal argument, then that part of the tree has been specified and is \"locked in place\" (i.e. there is no hole there for something else to be).\nX (Instance) Variables\nInstance (x) variables are just like normal First Order Logic variables, or like variables in popular programming languages. The types of things they can contain are \"individuals\", which is another name for a \"thing in the world\".  They hold the things the speaker is talking about.\nIn the MRS for \"Look under the large table\":\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _large_a_1 LBL: h13 ARG0: e14 [ e SF: prop TENSE: untensed MOOD: indicative PROG: bool PERF: - ] ARG1: x9 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _under_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _look_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\n... there are only two instance variables that represent the \"things in the world being talked about\":\nx9: \"the large table\"\n\nx3: \"you\". This is implied since it is a command. I.e. \"[You] look under the large table\". You can tell it wasn't in the original phrase because the predication doesn't start with _.\n\nThe other variables in the MRS are there to help build up the tree (h variables, described previously) or allow predications to refer to each other (e variables, described next).  x variables are the most concrete type of variable that maps most obviously to what is being said in the phrase.\nNote that instance variables are always scoped by a quantifier when a scope-resolved mrs is built. Quantifiers are described later, but for now think of them as a predication named with _q and with the argument structure: (x, h, h). The first argument of the quantifier, x, is the variable being \"scoped\", and the two branches in its scopal arguments are the only branches allowed to use that particular x variable.  That's what \"scoped by a quantifier\" means. This is important to know when creating scope-resolved mrss but also helps explain some of the uses of other variable types later in this section.\nE (Event) Variables\nEvent variables have a rich history and lot of fascinating conceptual linguistic background to them (Davidson 1967a is a good start), but for our purposes, we can think of them as holding a \"bag of information\" (represented in code as a dictionary, perhaps). Predications introduce them to provide a place for other predications to hang information that will be used by the introducer. \nFor example, event variables are used by adverbs like \"slowly\" as in, \"move slowly\", to provide the move predication with information about how to move. slowly does this by adding data to the event variable that move introduces. You can see in the MRS below for \"move slowly\" that _slow_a_1 is passed the e2 event variable that _move_v_1 introduces:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _slow_a_1 LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ]\n[ _move_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\nThe _slow_a_1 predication is passed the e2 argument so that it can attach data about \"how to do something\" to the event. _move_v_1 needs e2 passed to it so that it can inspect it and determine how to do the \"moving\".  \nEvents can also be used to add information about where to do something. For example, in \"go to the store\", \"to\" is one of many prepositions that can be used with \"go\" to say where to go. So, if a preposition like \"to\" is in the phrase, it modifies the event that \"go\" introduces:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _store_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _to_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _go_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nEvent variables conceptually hold a single \"event\" that accumulates information over the course of evaluating the predications. Multiple predications may \"enrich\" it with information before it's actually used by, for example, a verb. Contrast this with an instance (x) variable which only holds a particular individual at a given point it time. Said another way: an instance variable is like a string and can only hold one value, where an event is like a dictionary or a list and can hold many and be added to over time.\nNote that the DELPH-IN grammars are very liberal in putting event variables on predications and, depending on context, sometimes they aren't used. This is just to prevent the consumer of the MRS from having to deal with the same predication both with and without an event variable.\nThe predication that introduces an event variable will often (but not always) be the predication that consumes or \"does something\" with the \"fully enriched\" event. Predications that have it in other arguments will often (but not always) be simply adding information to the event.\nOther Variables Types: I, U, P\nRecall that the variable types in DELPH-IN form a hierarchy. So far we've discussed the bottommost \"leaves\", which are most commonly seen:\n    u\n   / \\\n  i   p\n / \\ / \\\ne   x   h\n\nThe other three types of variables represent a type that is \"in-between\" or \"underspecified\" between the other \"concrete\" types (e, x, h).  In general, these appear when the ERG can't decide the type of something since it falls somewhere between the types (i.e. is \"underspecified\").  From the ERG documentation:\n\"i (for individual) is a generalization over eventualities and instances; p (the half-way mark in the alphabet between h and x) is a generalization over labels and instances; and u (for unspecific or maybe unbound) generalizes over all of the above. Note that Copestake et al. (2001) use individual for what is called instance here.\"\n\nIn practice, they appear in two pretty specific scenarios:\nUnquantified x variables: Some predications in the ERG have an argument that is conceptually an individual (x) type, but does not require quantification. Since the rules require that all x variables are scoped by a quantifier, the most appropriate of the three \"in-between\" types will be used instead as a \"work-around\". This is usually i since these are most often of type x, and i is the most specific of the options that includes x. As with all non-x variables, this will be \"existentially quantified\" (globally defined) -- that is the whole point of using them here.\nDropped arguments: Sometimes the predication that would introduce a variable is missing. For example, take \"I left\" vs. \"I left Oregon\". In the latter, \"Oregon\" becomes a predication that introduces a variable that \"left\" uses, but in the former, this predication doesn't exist, so the variable is not introduced. In this case, the missing (or \"dropped\") variable uses an i, p or u type in place of the original type. Variables typed like this should be treated like the act of passing None in Python or Null in SQL to a function. The easiest way to detect when one of these three variable types means \"dropped or ignored argument\" is by checking if any other predication is also using it (as in the previous case). If not, it is probably dropped/ignored.\n- i means dropped e or x\n- u means dropped e, x, or h\n- p means dropped x or h\nVariable Properties\nVariables in an MRS have properties, which are like single argument predications for the variables. They define many different properties of a variable that aren't included anywhere else. They are defined after the variable in the MRS, surrounded by []. You can see several examples in the MRS for \"he will go\":\n[ pronoun_q LBL: h5 ARG0: x3 [ x PERS: 3 NUM: sg GEND: m IND: + PT: std ] RSTR: h6 BODY: h7 ]\n[ pron LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg GEND: m IND: + PT: std ] ]\n[ _go_v_1 LBL: h1 ARG0: e2 [ e SF: prop TENSE: fut MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n\nThe properties provided depend on the type of variable:\nInstance (x) variables can have these properties:\nNumber (NUM): sg (singular) or pl (plural)\n\nPerson (PERS): 1,2, or 3 for first-person (speaker) I/we, second-person (hearer) you, and third-person otherwise\n\nIndividuated (IND): + or - (meaning true or false). Distinguishes individuated entities introduced by count nouns such as cat or cats from non-individuated referents for mass nouns such as rice\n\nGender (GEN): m for male, f for female, n otherwise\n\nPronoun Type(PT): ?\n\nEvent (e) variables can have these properties:\nTense (TENSE): past for past, pres for present, fut for future, or untensed\n\nViewpoint aspect (or 'grammatical aspect') describes the situation from a particular viewpoint, dividing it into endpoints and stages (Smith 1991, 1997)\nPERF (for perfect): + or - (meaning true or false)\n\nPROG (for progressive): + or - (meaning true or false)\n\n\nSentence Force (SF): comm for command, ques for question, prop for proposition. Indicates the type of sentence.\n\nMood (MOOD): Roughly describes the opinions or attitudes of the speaker, with most common values being: subjunctive and indicative\n\nQuantifier Predications\nQuantifiers in DELPH-IN are the primary predications that glue a tree together. They provide two functions: they show where in the tree certain variables can be used (i.e. provide scope to the variable) and they often also constrain \"how much\" of the variable can be used. \"The\", \"a\", \"some\" and \"all\" are really common examples. \nQuantifier predications in DELPH-IN always have a specific argument signature: \nquantifier_q(x,h,h)\n\nIn addition to (often) doing the job of saying \"how much of\" their x variable there should be to make the MRS true (\"lots\", \"some\", \"the\", etc), they provide scope to the x variable. All x variables must be scoped by a quantifier, which means that they can only be used in the branches of the tree that are contained in the quantifier's two h (scopal) arguments. This rule for well-formedness means that there are many quantifiers that don't do \"real\" quantification at all, they are in the MRS solely to scope the x variable. Some also act like \"markers\" of some kind (again without doing any quantification).\nThe MRS for \"go north\" shows an example of this:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ def_implicit_q LBL: h11 ARG0: x9 [ x PERS: 3 NUM: sg ] RSTR: h12 BODY: h13 ]\n[ place_n LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg ] ]\n[ _north_a_1 LBL: h10 ARG0: i14 [ i ] ARG1: x9 ARG2: u15 ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ loc_nonsp LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _go_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h12 qeq h10 &gt; ]\n\n                                \u250c\u2500\u2500 place_n(x9)\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n                    \u2502             \u2514 _north_a_1(i14,x9,u15)\ndef_implicit_q(x9,RSTR,BODY)\n                         \u2502                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\n                         \u2514\u2500 pronoun_q(x3,RSTR,BODY)    \u250c\u2500\u2500 loc_nonsp(e8,e2,x9)\n                                                \u2514\u2500 and(0,1)\n                                                         \u2514 _go_v_1(e2,x3)\n\nThe variable x9 represents north but nothing in the phrase is \"quantifying\" direction in any way.  Since the rules for MRS require x variables to be quantified (among other reasons), an abstract quantifier called def_implicit_q is used to do the scoping of the variable.\nNote that, unlike non-quantifier predications, the first (ARG0) argument of a quantifier does not \"introduce\" an \"intrinsic variable\" (as described in the variables section), quantifiers just scope and optionally quantify their ARG0.\nConstraints\nThe HCONS section of the MRS is used when building a scope-resolved mrs. It puts CONStraints on where the Handles for predications can be validly placed and still be a legal interpretation of the phrase. The only constraints used in \"modern\" MRS are qeq constraints so that's all you'll see in this section.  \nA qeq constraint always relates an h argument of one predication, called a \"hole\", to the handle (LBL) of another predication. It states that the handle must be a direct or eventual child of the hole in the tree and, if not direct, the only things between the hole and the handle can be quantifiers.  Said a different way: \nA qeq constraint of \"X qeq Y\" says that the direct path from X to Y must only contain quantifiers (except for the final predication Y).\n\nAs we work through fully resolving the MRS into a tree, we'll see more description and examples of how the HCONS section is used.\nIndex\nOne final part of the MRS needs to be described: INDEX:\nTOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q__xhh LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _cave_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q__xhh LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron__x LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _to_p_dir__eex LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _go_v_1__ex LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; \n\nThe MRS will represent the syntactic head of the phrase with one or more predications. Index will point to the one that could (in principle) be used to further compose the phrase with other phrases [See HPSG Backgrounder]. In general, the index predication can be used to determine what the phrase is \u201cabout\u201d, or what the phrase is \u201cbuilt around\u201d.\nThe INDEX part of the MRS indicates the variable introduced by the predication (or predications if there is a conjunction) that is the \"main point of the phrase\". It is \"the thing being done\", which is usually the main verb.  In the example above INDEX: e2 is referring to the variable introduced by _go_v_1__ex.  This indicates that the verb go is the \"main point of the phrase\". This is called the \"syntactic head\" in linguistics.\nNote that the INDEX does not always point at a verb. In phrases that just state that something \"is\" something else, such is: \"the flower is blue\", \"is\" is not included. \"blue\" acts like the verb and is the INDEX:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _flower_n_1 LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _blue_a_1 LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\n\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _flower_n_1(x3)\n_the_q(x3,RSTR,BODY)\n                 \u2514\u2500 _blue_a_1(e2,x3)\n\nMore information on INDEX is described in the section on dealing with different types of phrases.\nThe next topic walks through the rules of creating \"scope-resolved MRS\", and is the last big chunk of conceptual background needed before we start building the system.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Minimal Recursion Semantics (MRS)", "teaser":"The Minimal Recursion Semantics (MRS) Format\nThis section is designed to give application developers an overview of the Minimal Recursion Semantics fo ...", "site":"Perplexity", "section":"MRS Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/mrscon/devhowto0020WellFormedTree", "excerpt":"Building Scope-Resolved MRS\nThis section is designed to help application developers understand how to build scope-resolved mrss from MRS documents. To understand this section, first make sure you have a basic understanding of the MRS formalism or, for a more academic or linguistic approach, explore Minimal Recursion Semantics: An Introduction.  \n\nLet's use the sentence \"every book is in a cave\" as an example. If the phrase is parsed with the ACE parser, you get an MRS document like this:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _a_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _cave_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _every_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _book_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _in_p_loc LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ARG2: x9 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nOur goal is to eventually \"solve\" the MRS by finding values for its MRS variables such that it is \"true\". When complete, these variables indicate what the speaker meant and allow us to do something about it.  \nTo resolve an MRS against a world state (a particular state of the world at a moment in time) and get solutions to it (meaning the set of MRS variable assignments that make it true) you need to turn it into a scope-resolved MRS. We will examine how shortly, but for now just know that a scope-resolved MRS has (among other things) nodes that are the predications from the MRS like _every_q__xhh and arcs that are links between the scopal arguments of the predications and other nodes, like this:\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _book_n_of(x3,i8)\n_every_q(x3,RSTR,BODY)          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _cave_n_1(x9)\n                   \u2514\u2500 _a_q(x9,RSTR,BODY)\n                                     \u2514\u2500 _in_p_loc(e2,x3,x9)\n\nThis tree represents one interpretation of \"every book is in a cave\", namely, \"every book is in a (possibly different) cave\". \nTo \"solve\" this tree against a particular world state, you walk it in depth-first order: every_q is the starting, leftmost node. It starts by selecting a book on its upper branch, and then solves its lower branch with the selected book. This finds \"a cave that the (selected) book is in\". every_q does this for every book in the world state. If they all succeed (they must all succeed because the speaker said \"every\"), we have a solution to the MRS. Because _every_q chooses a book and then a cave that it is in, it allows a different cave to be selected for each book. This tree will be only true if every book is in a (possibly different) cave.\nBut this is only one interpretation. Another interpretation of the same MRS is: \"all books are in the same exact cave\". The speaker might have meant that interpretation, which is represented by this tree:\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _cave_n_1(x9)\n_a_q(x9,RSTR,BODY)              \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _book_n_of(x3,i8)\n               \u2514\u2500 _every_q(x3,RSTR,BODY)\n                                     \u2514\u2500 _in_p_loc(e2,x3,x9)\n\nWhen a_q is the leftmost node, it starts by selecting a cave on its upper branch, and then resolves its lower branch with that selection, making sure that \"every book is in the (selected) cave\". This will only be true if there is (at least one) cave that every book is in.\nDon't worry if you don't completely understand how the solutions are obtained yet.  The point is that there are different interpretations for the same MRS, represented by different trees. The rest of the tutorial will work through how these get solved.\n\nBoth of these trees are represented by the same MRS document. The MRS structure is said to be underspecified, meaning that a single MRS document allows multiple interpretations. \nHere's the MRS for \"Every book is in a cave\" again, so we can see how:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _a_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _cave_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _every_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _book_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _in_p_loc LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ARG2: x9 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nThe MRS is a flat list of predications so that it avoids building a single tree which would \"lock in\" one interpretation.  How it does this is described in detail next, but in summary: It leaves \"holes\" using scopal (h) arguments for various predications and provides constraints (the HCONS) for plugging the predications together \"legally\".  If you combine the predications by following the constraints (among other things), you'll end up with a \"scope-resolved MRS\" which defines one valid interpretation of the sentence. If you build all the scope-resolved mrss, you have all the possible interpretations.\nThis interpretation is what we need in order to eventually \"solve\" the phrase for the variables it contains. This topic describes how to build that tree.\nHoles and Constraints\n\"Holes\" are h arguments in a predication that refer to a predicate label that is not defined. In the above MRS, h0 (the TOP:), h11, h12, h5, and h6 are all \"holes\" since none of the predicates use those names as their LBL.\nThe HCONS section of the MRS puts CONStraints on which placement of Handles in holes is valid.\nThe only kind of constraint used in \"modern\" MRS is a qeq constraint.  A qeq constraint always relates a hole to a (non-hole) handle and says that the handle must be a direct or eventual child in the tree. Furthermore, if not directly connected, the only things between the hole and the handle can be quantifiers.  \nSaid a different way: \nA qeq constraint of h0 qeq h1 (as in the above example) says that the direct path in the final tree from h0 to h1 must only contain quantifier predicates, but can contain as many as you want, as long as they don't violate other constraints.\n\nSo, in this MRS:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _a_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _cave_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _every_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _book_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _in_p_loc LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ARG2: x9 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nh1 is the LBL of the _in_p_loc__exx predicate. Given the qeq constraint of h0 qeq h1, it would be perfectly valid to assign h0 = h1 (meaning put the predication labelled by h1 in the h0 hole) since the path from h0 to h1 is direct. \nAgain, given the qeq constraint of h0 qeq h1: You could alternatively assign h0 = h4 (h0 is the \"hole\" at the top of the tree, h4 is the label for _every_q), and h6 = h1 (h6 is a \"hole\" in _every_q, h1 is the label for _in_p_loc). With this configuration, h0 qeq h1 is still valid because the path from h0 to h1 only includes the every_q quantifier and h1 itself.\nOnce you fill all the holes with unique predications, and you follow all of the qeq constraints, you'll end up with a tree that is \"scope-resolved\", but not yet guaranteed to be \"well-formed\". There is one more rule to check.\nX Variable Scoping\nAll of the arguments that aren't handles in the MRS for Every book is in a cave except two (e2 and i8) are x variables:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _a_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _cave_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _every_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _book_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _in_p_loc LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ARG2: x9 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nThe rules for MRS say that any variable in the MRS is \"globally defined\" (or \"existentially qualified\" in logic terms) for the whole structure except for x variables.  So, both e2 and i8 don't need any special handling, they are globally defined.\nx variables, on the other hand, can only be defined by quantifiers, and are only defined for the branches of the tree that are attached to the quantifier's scopal (h) arguments: RSTR and BODY.\nSo, while the predications can be in any order in the tree with respect to their e  (or i or u if it had them) arguments, the tree must be checked to make sure all of the x arguments have an eventual parent which is a quantifier which puts them in scope (i.e. has the x variable as its first argument: ARG0). This is an additional constraint that has to be checked to build a \"well-formed\" tree.\nIf the labels from the MRS are all in (exactly) one place, the built tree passes all qeq constraints, and the x variables are all properly scoped, then it is a \"well-formed\" tree that we can now attempt to solve.  That's what we're going for here.\nResolving the tree\nFinding ways to efficiently create these trees is an area of active research because natural language can easily create MRS structures that have a ton of holes.  n holes, in the worst case, can require n! checks to resolve, if done exhaustively.  So, an MRS structure with 12 holes (which is easy to generate) could require up to 480,000,000 checks before finding a valid solution if you just try every combination.  \nTo generate the scope-resolved mrss, you could simply try all possible combinations of holes and labels, do the qeq and x scoping checks on each, and only keep the valid ones. This will only be practical for the simplest possible trees.\nAnother algorithm, the one we'll use in the tutorial, is able to prune the search space and works much faster.  The Python implementation can usually generate all trees for an MRS with 12 holes in around 1.5s (with some outliers being slower) on a 2013-era MacBook Pro.  This will be sufficient for the purposes of this tutorial.  Something like \"put the diamond on the table where the safe is and the book is\" generates MRS structures with up to 14 holes and could take up to 30 seconds to generate all the valid interpretations (1500+ valid interpretations in some cases!) for each MRS.  It turns out it is very rarely necessary to generate all the interpretations, but regardless: because it scales factorially, things slow down fast after 12 holes.\nThere are definitely more efficient approaches, but the algorithm below has the advantage of being relatively simple. Here is one alternative.  There are definitely more.\nA Simple, Fast Enough, Algorithm\nIt isn't important to fully understand this algorithm as long as you understand what it has to do: build a scope-resolved MRS, and what the rules are in doing that. We'll use this code as a library routine all throughout the tutorial, but we won't dive into its implementation again.\n\nThis description is for those that are interested in how the algorithm works, and isn't necessary for understanding the rest of the tutorial:\nFirst some definitions used in this algorithm:\nHole: A scopal (i.e. h type) argument in an MRS predicate that doesn't refer to an existing predication\n\nFloater: A tree of predications that have had zero or more of their scopal (i.e. h type) arguments filled by predications.  [This is not at official MRS term, it is one created for this algorithm]\n\nAs a reminder, a tree is \"well-formed\" if:\nEach predication is assigned to one, and only one, hole. No holes are left unfilled, and no predications are unassigned at the end  \n\nNone of the assignments of predications to holes violates a qeq constraint \n\nAny variable introduced by a quantifier is not used outside of the branches assigned to its RSTR or BODY arguments  \n\nHere's the intuition for how the algorithm works: We are going to walk a search tree.  Every node of the search tree represents a partial assignment of floaters to holes that meets the above 3 constraints. Every arc from a parent node in the search tree to a child node in the search tree represents a unique assignment of a (otherwise unassigned) floater to a hole.  If that assignment violates a constraint, the search tree node is not valid (since obviously keeping this assignment and adding floaters to it can't be valid either) and we stop searching that whole branch of the search tree. This pruning is what makes it faster than the really naive \"try every option\" approach. Every node in the search tree that has no holes left to assign is a solution.\nAlgorithm Flow Summary: We start at the TOP: hole and record on it any qeq constraints that apply to it and any X variables that are in scope for it (none at the start). As we traverse an arc in the search tree and assign a new floater to a hole, we propagate any constraints and in-scope variables from the (parent) hole to the holes in the (child) floater.  Then we create the next node in the search tree by choosing the next hole to fill from the existing node.\nStart with:\nEach node in the search tree has the following structures that represent where the search has progressed to:\nallHolesDict:              Dictionary populated with all the holes in the MRS. Each hole has information about:\n- The qeq constraints that currently apply to it\n- The X variables that are currently in scope for it\n- The floater it is from\nnodeAssignmentList:        Assignments of floaters to holes that the search tree node represents. Empty for the initial node.\nnodeRemainingHolesList:    Holes left to fill in this search tree node. Only contains the TOP: hole for the initial node.\nnodeRemainingFloatersList: Floaters still unassigned at this node in the search tree. Contains all floaters for the initial node. Each floater contains information about:\n- A list of holes it contains\n- A list of unresolved x variables it contains\n- A list of any Lo parts of a qeq constraint it contains (if it doesn't also have the Hi part in the floater) \nAlgorithm:\nStarting at the initial node:\nGet currentHole by removing the first hole from nodeRemainingHolesList \n\nGet currentFloater by removing each floater from nodeRemainingFloatersList and: \nIf currentFloater does not violate the constraints in currentHole: \nAdd currentHole = currentFloater to nodeAssignmentList\n\nPropagate the constraints and variables from the new parent to all holes in currentFloater \n\nAdd holes from currentFloater to the end of nodeRemainingHolesList \n\nCheck number of holes left:\nif == 0, return nodeAssignmentList as a solution\n\notherwise, continue the search by \"creating a new search tree node\" via recursing to the top of the algorithm\n\n\n\n\nReturns:\nnodeAssignmentList which is simply a dictionary where the keys are holes and the value is the floater that was assigned to it.\nOnce this has run its course you will have all the valid scope-resolved mrss for the MRS. \nCode and Example\nBelow is the Python code for the main routine, all of the code is available here.\nLet's walk through an example of \"Every person eats a steak\u201d to see how the code works:\n[ &quot;Every person eats a steak&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ _every_q&lt;0:5&gt; LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg ] RSTR: h5 BODY: h6 ]\n          [ _person_n_1&lt;6:12&gt; LBL: h7 ARG0: x3 ]\n          [ _eat_v_1&lt;13:17&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x8 [ x PERS: 3 NUM: sg IND: + ] ]\n          [ _a_q&lt;18:19&gt; LBL: h9 ARG0: x8 RSTR: h10 BODY: h11 ]\n          [ _steak_n_1&lt;20:25&gt; LBL: h12 ARG0: x8 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 h10 qeq h12 &gt; ]\n\nThere are 5 holes in the MRS that need to be assigned a predication: h0, h5, h6, h10, h11.\nTo do this, try_alternative_hole_assignments() gets called initially with all_holes_dict assigned like this:\nall_holes_dict = {\n   &#x27;h0&#x27; = {&#x27;Constraints&#x27;:  {&#x27;InScope&#x27;: {},     &#x27;QeqLo&#x27;: {&#x27;h1&#x27;: False}},    &#x27;Floater&#x27;: None, &#x27;Label&#x27;: &#x27;h0&#x27;}\n   &#x27;h5&#x27; = {&#x27;Constraints&#x27;:  {&#x27;InScope&#x27;: {&#x27;x3&#x27;}, &#x27;QeqLo&#x27;: {&#x27;h7&#x27;: False}},    &#x27;Floater&#x27;: None, &#x27;Label&#x27;: &#x27;h5&#x27;}\n   &#x27;h6&#x27; = {&#x27;Constraints&#x27;:  {&#x27;InScope&#x27;: {&#x27;x3&#x27;}, &#x27;QeqLo&#x27;: {}},               &#x27;Floater&#x27;: None, &#x27;Label&#x27;: &#x27;h6&#x27;}\n   &#x27;h10&#x27; = {&#x27;Constraints&#x27;: {&#x27;InScope&#x27;: {&#x27;x8&#x27;}, &#x27;QeqLo&#x27;: {&#x27;h12&#x27;: False}},   &#x27;Floater&#x27;: None, &#x27;Label&#x27;: &#x27;h10&#x27;}\n   &#x27;h11&#x27; = {&#x27;Constraints&#x27;: {&#x27;InScope&#x27;: {&#x27;x8&#x27;}, &#x27;QeqLo&#x27;: {}},               &#x27;Floater&#x27;: None, &#x27;Label&#x27;: &#x27;h11&#x27;}}\n\nYou can see that 'Floater' is initially set to None for all the holes. The goal is to figure out which unassigned predications (i.e. floaters) should get assigned to each of these holes.\ntry_alternative_hole_assignments() does this by searching a tree of all possible assignments. \nIt starts with the all_holes_dict from above. Since there are some holes that don\u2019t have a predication assigned, it will:\nPick the next unassigned hole: in this case, h0.\n\nPick the next unassigned floater: in this case, h1.\n\nIf assigning h1 to h0 doesn't violate any constraints on building a scope-resolved mrs: update all_holes_dict() to contain this assignment and recurse at step #1 with the new all_holes_dict().\n\nIf the assignment does violate a constraint, skip it and jump to step #2 to try the next floater.\n\nIf you recurse to the point where there are no more holes you've found a valid tree: yield it, and then keep searching for more.\ndef TryAlternativeHoleAssignments(allHolesDict, nodeRemainingHolesListOrig, nodeRemainingFloatersList, nodeAssignmentList):\n    # Grab the first hole to fill and remove it from the list\n    currentHole = allHolesDict[nodeRemainingHolesListOrig[0]]\n    nodeRemainingHolesList = nodeRemainingHolesListOrig[1:]\n\n    index = 0\n    # Try each remaining floater in this hole\n    for index in range(0, len(nodeRemainingFloatersList)):\n        # Grab the current floater and pull from the list for when we recurse\n        currentFloater = nodeRemainingFloatersList[index]\n        newNodeRemainingFloatersList = [x for i, x in enumerate(nodeRemainingFloatersList) if i != index]\n\n        # Check if constraints are met. If not, prune entire search space by\n        # skipping since none of its children can work either\n        errorOut = []\n        if not CheckConstraints(currentHole[&quot;Constraints&quot;], currentFloater, errorOut):\n            # Constraint Failed: try the next one\n            continue\n\n        # Hole successfully filled\n        # Assign the floater to the hole in a copy of assignments since we will be\n        # changing on each loop\n        currentAssignments = copy.deepcopy(nodeAssignmentList)\n        currentAssignments[currentHole[&quot;Label&quot;]] = currentFloater[&quot;Label&quot;]\n\n        if len(newNodeRemainingFloatersList) == 0:\n            # We filled the last hole, return the solution\n            yield currentAssignments\n            return\n\n        # If this floater has more holes, add them to a copy of the nodeRemainingHolesListOrig\n        # Fixup any of the holes from this floater in a *copy* of holeDict since it also holds the holes\n        # and the pointer to the hole is being changed so we don&#x27;t want other nodes to get changed too\n        newNodeRemainingHolesList = copy.deepcopy(nodeRemainingHolesList)\n        newHoleDict = copy.deepcopy(allHolesDict)\n        FixupConstraintsForFloaterInHole(currentHole[&quot;Constraints&quot;], currentFloater, newHoleDict)\n        for nextHoleName in currentFloater[&quot;FloaterTreeHoles&quot;]:\n            newNodeRemainingHolesList.append(nextHoleName)\n\n        # This hole was filled, see if any remain\n        if len(newNodeRemainingHolesList) &gt; 0:\n            # recurse\n            yield from TryAlternativeHoleAssignments(newHoleDict, newNodeRemainingHolesList, newNodeRemainingFloatersList, currentAssignments)\n\n    # At this point we tried all the floaters in this hole\n    return\n\nComprehensive source for the completed tutorial is available here\n\n", "title":"Well-Formed Trees", "teaser":"Building Scope-Resolved MRS\nThis section is designed to help application developers understand how to build scope-resolved mrss from MRS documents. To ...", "site":"Perplexity", "section":"MRS Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devcon/devcon0000Overview", "excerpt":"MRS Solver Concepts\nAll of the topics in this section are designed to describe the algorithms and concepts needed to build a backtracking solver for an MRS document -- without actually building one. It is meant to provide the background needed for anyone wanting to approach the subject without getting deep into the details of coding one up. \nThe final section, \"Perplexity Internals\", does walk through the details of building one in Python. It assumes the concepts are already understood from reading this section.\nThe first topic in this section, \"Backtracking\", walks through the general approach we'll be using to solve MRS documents. Topics after that build on this base.\n", "title":"Overview", "teaser":"MRS Solver Concepts\nAll of the topics in this section are designed to describe the algorithms and concepts needed to build a backtracking solver for a ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devcon/devcon0010MRSSolver", "excerpt":"Solving an MRS\nIt is important to understand what MRS is and what a scope-resolved MRS is before reading this section. Visit those links first to understand the basic concepts.\n\nA scope-resolved MRS can be thought of as an equation that is true or false depending on the values of its variables. Recall that predications are of the form: _table_n_1(x) or compound(e,x,x). Just like functions in mathematics or programming languages, they have a name and a set of arguments. They are true when their arguments are set to values that are or mean what the predication means. \nSo:\nIf we set x = 'a cat' then _table_n_1(x) will be false\n\nIf we set x = 'the brown table' then _table_n_1(x) will be true\n\n_table_n_1(x) means: \"the object in x is a table\". It might also be many other things, like brown or large or missing, etc. But as long as it is at least a table, _table_n_1(x) is true.\nHow a cat or the brown table are actually represented doesn't matter as long as the predication can interpret it. It could be a string or an object of some kind.\nA group of multiple predications separated by commas means they are \"in conjunction\", which means the commas should be treated as and. So,large(x), file(x) will only be true if x is set to values that make all the predications true. In this example, x must be set to something that is a large file. Again, x could be a large yellow file or a large file of paperwork, but each predication just tests for some property of x and is true as long as that property is true, regardless of its other properties.\nSolving a scope-resolved mrs means finding values for the variables that make all the predications true.\nHere's a simple example. Let's solve large(x), file(x) in a world with 3 objects in it:\na folder\na small file\na large file\n\nx variables in an MRS represent \"individuals\" or \"things in the world\". So, we need to find which are the individuals from the world that, when put into x, make both the predications in large(x), file(x) be true. \nWhile this is trivial to solve by looking at it, once the world contains a million objects we will need a more systematic approach.\nA Backtracking MRS Solver\nWe can look at solving an MRS as a constraint satisfaction problem which is a well-studied class of problems that have a finite set of constraints over variables. In the MRS case, the constraints are the predications:\nlarge(x) constrains x to only be those objects that are large\n\nfile(x) constrains x to only be those objects that are a file\n\nlarge(x), file(x) constrains x to be a large file\n\nOne simple approach to solving constraint satisfaction problems (like finding the solutions to an MRS) is to use \"backtracking\". The simplest backtracking algorithm is to:\nTraverse the predications from the scope-resolved MRS, depth-first\n\nWhen an unassigned variable in a predication is encountered: \nAssign it the first item in the world\n\nMark it as a backtrack point\n\n\nIf a predication is false:\n\"backtrack\" to the nearest backtrack point and retry with the next item in the world\n\nIf there are no more items to retry with, backtrack further to the next backtrack point and try again. \n\n\nThis will try all items in the world, in all variables, until it finds all solutions. Backtracking allows the search space to be pruned to avoid whole sets of assignments that can't possibly work, thus improving the performance vs. a full search of all possibilities.\nLet's use the backtracking algorithm to solve a slightly more interesting example, \"large file in folder\":\n[It is important to note that these are not real MRS or scope-resolved mrs examples yet!  That will come soon.]\nformula: large(x), file(x), folder(y), in(x, y)\n\nworld individuals:\na folder\na small file\na large file\n\nworld facts:\n[a large file] is in [a folder]\n\nThe \"world individuals\" above are the only objects that exist in the world. x values in the MRS will hold these as values.\nThe \"world facts\" above are facts about the relationships between things in the world that predications such as in(x, y) can refer to to see if they are true.\nAs above, it doesn't matter how either of these is actually represented in a program, as long as the predications know how to find and interpret them. We'll be building an example of such a system in the How-To section.\nTo make the backtracking algorithm more explicit, and to make the formula more like real MRS predications, we need to introduce a notion of \"variable scope\". Variable scope shows where a variable is introduced and which predications can use it. \nWe'll represent scope by a made-up function for now: scope(variable, [predication_list]). The function states that variable can be used by all the predications in [predication_list]. And, since scope() itself is a predication, more variables can be defined in predication_list using another scope(). This allows us to represent our formula using scoping, like this:\nformula: scope(x, [large(x), file(x), \n                                      scope(y, [folder(y), in(x, y)])\n                  ])\n\nThe formula is formatted to make it easier to see the nesting. You can see that this is just a flat way of representing a tree shaped like this:\n                            \u250c\u2500\u2500 large(x)\n                            \u2502 \u250c\u2500\u2500 file(x) \n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1,2)\n                \u2502               \u2514\u2500\u2500 scope(y, predication_list)\nscope(x, predication_list)                          \u2502\n                                                    \u2514\u2500 and(0,1)\n                                                           \u2502 \u2514 in(x, y)\n                                                           \u2514 folder(y)\n\n... where and(...) has been used to explicitly show the conjunctions (i.e. ands).\nThe backtracking algorithm does its job by recursively \"evaluating\" the scope() predications:\nEvaluating a scope() means:\nAssign a world value to the scope's variable\n\nEvaluate its predication_list using that value (see below for how)\n\nIf the list is false, restart the list using the next world value\n\nIf the list is true, the scope() predication is true\n\nEvaluating a predication_list means:\nEvaluate the first predication in the list using the current values of all variables in scope\n\nIf true, try the next predication in the list\n\nIf false, the list is false\n\nIf all the predications are true, the list is true\n\n\nSo, working through the example:\n|Action|Formula|\n|---|---|\n|Start with initial formula |    scope(x, [large(x), file(x), scope(y, [folder(y), in(x, y)])]) |\n|set x='a folder' (the first item in the world) |    scope('a folder', [large('a folder'), file('a folder'), scope(y, [folder(y), in('a folder', y)])]) |\n|first item in list is false|    ... large('a folder')...|\n|backtrack: set x='a small file' (the next item in the world) |    scope('a small file', [large('a small file'), file('a small file'), scope(y, [folder(y), in('a small file', y)])]) |\n|first item in list is false|    ... large('a small file')...|\n|backtrack: set x='a large file' |    scope('a large file', [large('a large file'), file('a large file'), scope(y, [folder(y), in('a large file', y)])]) |\n|first item in list is true| ... large('a large file')...|\n|second item in list is true| ... file('a large file')...|\n|third item in list is scope(): set y='a folder' (the first item in the world)|    ...  scope('a folder', [folder('a folder'), in('a large file', 'a folder')])|\n|first item in scope(y, ...) is true|    ... folder('a folder') ...|\n|second item in scope(y, ...) is true|    ... in('a large file', 'a folder')...|\n|thus: scope(y, ...) is true for y='a folder'|    ...  scope('a folder', [folder('a folder'), in('a large file', 'a folder')])|\n|thus: scope(x, ...) is true for x='a large file' and y='a folder'|scope('a large file', [large('a large file'), file('a large file'), scope('a folder', [folder('a folder'), in('a large file', 'a folder')])])|\nThis example shows how:\nIteratively assigning values to each variable in a scope and\n\nEvaluating the predication list within a scope and\n\nBacktracking when there is a failure\n\n... will eventually find all the solutions to the formula (or prove that there are none). \nIt works because we are effectively trying all values in all variables. But, it is better than literally just assigning all values to all variables, one by one, until we find the answer, because backtracking eliminates whole branches in the search space. There are other optimizations that can be done, and we will do more as we go, but the basic approach is straightforward.\nAt this point, it should be noted that there are other algorithms for solving constraint satisfaction problems. Furthermore, the MRS tree can sometimes be transformed into other forms, such as a predicate logic formula, and turned into a different kind of problem which can be solved using completely different approaches. This tutorial will be using the backtracking algorithm because it is simple, efficient enough for many problems, and has the nice property that it can handle all MRS formulas. It has the downside that it can be very inefficient in some cases. We'll work through some of those and find optimizations for some of the most egregious problems.\nBut, before we can solve a real scope-resolved MRS, we need to account for more of its features. First up is allowing the solver to represent things operating \"together\".\nThe Internals section has a description of how to implement a simple backtracking solver.\n", "title":"Solving an MRS", "teaser":"Solving an MRS\nIt is important to understand what MRS is and what a scope-resolved MRS is before reading this section. Visit those links first to unde ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devcon/devcon0020MRSSolverSets", "excerpt":"\"Together\" and \"Separately\" in the Solver\nIf there were multiple large files in folders, the formula we ended the MRS Solver section with:\nformula: large(x), file(x), folder(y), in(x, y)\n\n... would find them all as different \"solutions\". Recall that a \"solution\" is an assignment of a single value to all variables, such as:\nsolution 1: x=file1, y=folder1\nsolution 2: x=file2, y=folder2\n...\n\nSo, using that approach, we could look at the formula as representing the phrase: \"large files in folders\" since it will find multiple if they exist. But, this only works because of how \"in\" behaves. If a and b are \"in\" a folder, a is in the folder and b is in the folder. \nThis isn't true of all verbs, however. The verb \"to lift\" can distinguish cases that mean very different things.  \nFor example:\nstudents lifted a table\n\n...could mean: \nTwo students (together) lifted a table (at the same time)\n\nTwo students (separately) lifted a (different) table\n\nWe need to be able to capture the semantic of the students working together or separately in our solutions. Simply having single values assigned to variables can't do that.\nHandling Sets\nTo represent individuals operating \"together\" or \"separately\" we can make a simple extension to the algorithm: require that variables always contain a set of one or more things from the world. Predications can then interpret a set of greater than one element as meaning \"together\".  A set of one item can mean \"separately\" or \"alone\". \nThis change allows the solver to represent a solution where Alice and Bob are lifting a table together like this: lift([alice, bob], [table1]). The fact that the first argument to lift is a set of two people means they are working together, which wasn't possible to represent before.\nWith this change, a scope() predication now needs to assign all possible sets of values to its variable in order to explore the solution tree and find all the solutions. This can quickly become quite expensive, but there are optimizations we will explore. For now, we'll use the direct approach to keep the algorithm simple.\nLet's work through an example of a world where two students are lifting a table:\nformula: student(x), table(y), lift(x, y)\nscoped formula: scope(x, [student(x), scope(y, [table(y), lift(x, y)])])\n\nworld individuals:\n  alice\n  bob\n  table1\n\nworld facts:\n  [alice, bob] lift [table1]\n\nTo find all solutions, x and y now must be iteratively assigned all combinations of things in the world by their scope() predication, but the rest of the algorithm proceeds as before. \nUnlike in(), when lift() encounters a set of more than one item in either of its arguments, it has to check the world to see if the actors are lifting together, or if tables are being lifted together.\nSummarizing the results in truth table form:\n|assignment|formula result|\n|---|---|\n|x=[alice], y=[alice]| false|\n|x=[alice], y=[bob]| false|\n|x=[alice], y=[table1]| true|\n|x=[alice], y=[alice, bob]| false|\n|x=[alice], y=[alice, table1]| false|\n|x=[alice], y=[bob, table1]| false|\n|x=[alice], y=[alice, bob, table1]| false|\n|x=[bob], y=[alice]| false|\n|x=[bob], y=[bob]| false|\n|x=[bob], y=[table1]| true|\n|x=[bob], y=[alice, bob]| false|\n|x=[bob], y=[alice, bob, table1]| false|\n|x=[alice, bob], y=[alice]| false|\n|x=[alice, bob], y=[bob]| false|\n|x=[alice, bob], y=[table1]| true|\n|...| etc.|\nObserve how the variable assignments now contain sets (represented by []), and every combination of world individuals (that is not the empty set) is tried. Not all combinations are shown for all variables because:\nThe number of non-empty combinations of world individuals is (2^n - 1): think about representing each individual as a binary bit saying whether the individual is included (1) or not (0). n individuals means n bits. n bits can represent 2^n numbers. We subtract off the number that has all zeros since we don't want an empty set. In this case, that only means 7 combinations of individuals. \n\nBut: we also need all combinations of assignments of those individuals to x and y. That is a \"cartesian product\", which means we'd need to show (2^n - 1) * (2^n - 1) = 49 assignments in the list. This can quickly become an unmanageable number, but there are some approaches to taming the combinatorics that we'll go through later.\n\nIn the new form, the solutions we get back (i.e. the variable assignments that make the formula  true in the above table) are shown below, along with their meaning:\n|assignment|meaning|\n|---|---|\n|x=[alice], y=[table1]| Alice lifted a table|\n|x=[bob], y=[table1]| Bob lifted a table|\n|x=[alice, bob], y=[table1]| Alice and Bob lifted a table together|\nThus, the algorithm still gives us all the assignments of variables that make the formula true in the world, but now our formulation can express things operating together or separately.\nHowever, we need something more to allow representing plurals in a phrase, as described in the next section.\n", "title":"Representing 'Together'", "teaser":"\"Together\" and \"Separately\" in the Solver\nIf there were multiple large files in folders, the formula we ended the MRS Solver section with:\nformula: la ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devcon/devcon0030MRSSolverSolutionGroups", "excerpt":"Collective, Distributive, and Cumulative Readings\nIf we change the \"students lifted a table\" example from the previous section slightly, we can uncover another layer of meaning we need to represent in the solver. \nFor example:\nTwo students lifted one table\n\n...could mean: \n1. Two students [together] lifted one table [at the same time]\n2. Two students [separately] lifted one [different] table\n\nSo, in addition to representing things working together or separately by using sets as we did in the previous section, we need to deal with the fact that terms representing sets in language create a new layer of ambiguity: it isn't always clear if you are talking about the whole group of \"two students\" working together, or subsets of the group working separately. The solver needs to be able to find either solution properly.\nLet's start by defining some linguistics terminology to help us talk about the different ways students are grouped in the interpretations above:\nA group of items operating together are called collective: #1 has collective students.\n\nA group of items where different subsets of the group operate \"separately\" are called distributive: #2 has distributive students. \n\nNow, notice that there is more going on than just a different grouping of students. Reading #1 above describes a single table being lifted, whereas reading #2 has two ... but they both come out of a phrase that says \"... lifted one table\". This happens because the phrases are both being interpreted as \"one table [per group]\". #1 has a single group (of two students), #2 has two groups (of one student). \nSo, to discuss the whole phenomena across the phrase (and not just how the students are being grouped), the term \"reading\" is used in conjunction with collective or distributive. As in: \"#1 is a collective reading\" and \"#2 is a distributive reading\". Defining these a bit more rigorously:\nFor: \"M students lifting N tables\":\nTo be the distributive reading:\nStudents: must be grouped distributively into subgroups, which means:\n2 or more subgroups\n\nEvery student is in exactly one subgroup\n\nThe total of students across the subgroups must add up to M\n\n\nTables: Each student subgroup with more than one student must be together lifting exactly N tables\n\nTo be the collective reading:\nStudents must be grouped collectively, which means:\nExactly 1 \"subgroup\" that contains the entire set of students\n\n\nTables: Identical to the distributive reading, but using just one \"subgroup\" that contains everyone\n\n\nCumulative Readings\nIf we change the phrase again just slightly to allow for more than one table:\nTwo students lifted two tables\n\n... language lets in one more possible interpretation ... by counting total tables (not per group):\n3. One student lifted one table and another student lifted a different table.\n\nThis interpretation distributively groups the students, but counts the tables differently.  This can be confusing, so let's do the three definitions at once:\nFor: \"M students lifting N tables\":\nThe distributive reading: \"Two students [separately] lifted two tables [each]\"\nStudents: must be grouped distributively into subgroups, which means:\n2 or more subgroups\n\nEvery student is in exactly one subgroup\n\nThe total of students across the subgroups must add up to M\n\n\nTables: Each student subgroup with more than one student must be together lifting exactly N tables\n\nThe collective reading: \"Two students [together] lifted two tables [at the same time]\"\nStudents must be grouped collectively, which means:\nExactly 1 \"subgroup\" that contains the entire set of students\n\n\nTables: Identical to the distributive reading, but using just one \"subgroup\" that contains everyone\n\nThe cumulative reading: \"One student lifted one table and another student lifted a different table\"\nStudents: Identical to the distributive reading.\n\nTables: The total of tables across all subgroups must add up to M\n\n\nNote how the math for the cumulative reading is different than the math for collective and distributive readings. Collective and distributive readings require M tables per student subgroup, whereas cumulative requires M tables, total, across all student subgroups.\nIt is important to note that this is not some DELPH-IN feature or artifact, this is how human language works. We are just trying to emulate it by building an algorithm that processes phrases like a human would.\nAlgorithm Fixes for Collective, Distributive and Cumulative\nThe backtracking algorithm we've defined in previous sections will actually find the collective, distributive, and cumulative solutions to an MRS, if they exist, because it will find all solutions to the MRS.  But, there is a problem with the way we're currently defining \"solution\". To see why, let's bring back the three readings:\n\"two students lifted two tables\"\nThe distributive reading: \"Two students [separately] lifted two tables [each]\"\n\nThe collective reading: \"Two students [together] lifted two tables [at the same time]\"\n\nThe cumulative reading: \"One student lifted one table and another student lifted a different table\"\n\n\nNote that situations #1 and #3 are only properly represented by a group of solutions as we've defined \"solution\": \nSolution: Assignments of single set-based values to all variables that make the MRS true \n\nThere isn't a way to represent #1 and #3 as a single solution (i.e. a single set of variable assignments) in this model. For example, look at #1: Since each student is lifting a different \"two tables\", it will take 4 solutions to capture the meaning:\nx=[student1], y=[table1]\nx=[student1], y=[table2]\nx=[student2], y=[table3]\nx=[student2], y=[table4]\n\nEven if each student is lifting two tables at the same time, we still need two solutions:\nx=[student1], y=[table1, table2]\nx=[student2], y=[table3, table4]\n\nWe need to represent 2 students operating separately which means they must be in their own set, and variables can only be assigned one set-based value in a solution. Thus, distributive or cumulative scenarios will require a group of solutions to represent the answer. This is the change we need to make to the solver.\nSolution Groups\nWe can address the problem by changing our solver algorithm to generate solution groups, and then start interpreting a group of solutions as a complete answer. Let's go through the different scenarios using the grouping approach.\nFirst, a collective reading scenario:\nformula: student(x), table(y), lift(x, y)\nscoped formula: scope(x, [student(x), scope(y, [table(y), lift(x, y)])])\n\nworld individuals:\n  alice\n  bob\n  table1\n  table2\n\nworld facts:\n  [alice, bob] lift [table1, table2]\n\nThe solution group that represents this can actually be represented by a single solution in the group:\nSolution Group for the collective reading: \"Two students [together] lifted two tables [at the same time]\"\n|solution|interpretation|\n|---|---|\n|x=[alice, bob], y=[table1, table2]| Alice and Bob [together] lifted two tables [at the same time]|\n\nNext, a distributive reading scenario:\nformula: student(x), table(y), lift(x, y)\nscoped formula: scope(x, [student(x), scope(y, [table(y), lift(x, y)])])\n\nworld individuals:\n  alice\n  bob\n  table1\n  table2\n  table3\n  table4\n\nworld facts:\n  [alice] lift [table1]\n  [alice] lift [table2]\n  [bob] lift [table3]\n  [bob] lift [table4]\n\nThe solution group that represents this requires multiple solutions in the group:\nSolution Group for the distributive reading: \"Two students [separately] lifted two tables [each]\"\n|solution|interpretation|\n|---|---|\n|x=[alice], y=[table1]| Alice [separately] lifted one table|\n|x=[alice], y=[table2]| Alice [separately] lifted another table|\n|x=[bob], y=[table3]| Bob [separately] lifted one table|\n|x=[bob], y=[table4]| Bob [separately] lifted another table|\n\nFinally, a cumulative reading:\nformula: student(x), table(y), lift(x, y)\nscoped formula: scope(x, [student(x), scope(y, [table(y), lift(x, y)])])\n\nworld individuals:\n  alice\n  bob\n  table1\n  table2\n\nworld facts:\n  [alice] lift [table1]\n  [bob] lift [table2]\n\nThe solution group that represents this also requires multiple solutions in the group:\nSolution Group for The cumulative reading: \"One student lifted one table and another student lifted a different table\"\n|solution|interpretation|\n|---|---|\n|x=[alice], y=[table1]| Alice [separately] lifted one table|\n|x=[bob], y=[table2]| Bob [separately] lifted one table|\n\nSummary\nWith the addition of solution groups, the solver can now properly represent the meaning of plural sentences across collective, distributive and cumulative readings.\nThe appendices have a description of how the solver can actually do the grouping and arrive at those answers.\nTODO: talk about forward and reverse readings with respect to word order being a function of the tree that is generated.\n", "title":"Collective, Distributive, Cumulative", "teaser":"Collective, Distributive, and Cumulative Readings\nIf we change the \"students lifted a table\" example from the previous section slightly, we can uncove ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devcon/devcon0060WhichParseAndTree", "excerpt":"Determining the Right Parse and Tree\nAs discussed in the MRS topic and the Scope-Resolved Mrs topic, a single phrase like \"Look under the table\" produces m MRS documents, and each of those produces n scope-resolved mrss, thus generating m x n potential interpretations of a phrase. How do you determine which one is the one the user meant?\nThe short answer is that, just like when you are talking to a human, you never really know what they meant unless you pick your best guess and confirm it with them. But: there are a couple of things that help: First, ACE uses a machine-learning-based algorithm to sort the MRS documents and returns the \"most common\" ones first. This means the more obscure MRS interpretations will be sorted last. Unfortunately, there is no such mechanism for the scope-resolved mrss. So, at best we have a partial ordering of the m x n trees in terms of \"most commonly meant\". \nWith that in mind, a simple approach to choosing the \"right\" interpretation that works surprisingly well is: \nSolve each scope-resolved MRS against the world state in the provided partial ordering of MRS documents. Assume the first one that succeeds is what the user meant. If none succeed, return the first failure.\n\nThis works for the same reason human interactions work: Most phrases are meant to convey information that makes sense. I.e. the phrase discusses things that actually exist, uses verbs that make sense with objects being discussed, etc. So, most phrases the user gives your system should have a solution given the current world state. Furthermore, humans have an intuitive understanding of the ambiguity of language and are forgiving of errors when they are understandable and logical failures. I.e. \"I can see why you thought that, even though it wasn't what I meant...\". \nSo, if the system finds a tree that has a solution in the current world state, it is likely to be at least close to what the user meant. Even if it isn't, given that it was a solution in the world state, it will still be logical and the user will very often understand (and sometimes be delighted by) how their phrase was misinterpreted.\nThus, the approach to finding which of the m x n meanings is the \"meant one\" is to run them all, in the best order we have, and assume the first that works is the right one.\nThings get a little trickier if none of them works. However, the same principle holds: as long as the error response we give is logical and understandable, it will make sense to the user, even if it isn't quite the answer a person would have given. Often we can do better than just returning the first failure, but this requires knowing what kinds of errors your particular system produces, which ones are less useful, etc. Returning the first failure is a good place to start.\nPerplexity Internals walks through how Perplexity implements this logic internally.\nComprehensive source for the completed tutorial is available here.\n\n", "title":"Choosing a Parse and Tree", "teaser":"Determining the Right Parse and Tree\nAs discussed in the MRS topic and the Scope-Resolved Mrs topic, a single phrase like \"Look under the table\" produ ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devcon/devcon0070SentenceForce", "excerpt":"Sentence Types\nWe've been using a lot of examples that are questions and propositions without actually working through how the system should detect the type of phrase the user said and respond to it. Now it is time to start working through types of sentences and actually giving the answers people will expect from each type.\nLet's look at the MRS for the sentence we've been working with so far, \"A file is very large\":\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _a_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _file_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _very_x_deg LBL: h1 ARG0: e9 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ]\n[ _large_a_1 LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\n\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _file_n_of(x3,i8)\n_a_q(x3,RSTR,BODY)    \u250c\u2500\u2500 _very_x_deg(e9,e2)\n               \u2514\u2500 and(0,1)\n                        \u2514 _large_a_1(e2,x3)\n\nYou can see what type of phrase it is by looking at the properties of its variables. This is the first time we've had to inspect variable properties, so lets dig in there a bit. \nYou can see that, next to each argument in the MRS, there is a list of properties surrounded by []. It looks like this for the e2 argument of _large_a_1:\n e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ]\n\nThis is the list of properties for that variable. It provides various information about the kind of things that should be in that variable. Think of it as \"metadata\" about the variable or single argument predications for that variable.  The property we are interested in here is:\nSF: prop (\"sentence force\": \"proposition\").  \n\nEvery sentence is categorized into a type, indicated by the SF (\"sentence force\") property of one or more of its variables (note that the SF should be the same even if it appears on more than one variable):\nProposition (SF: prop): \"A file is large.\"\n\nQuestion (SF: ques): \"Is a file large?\", \"Which file is large?\", \"A file is large?\"\n\nCommand (SF: comm): \"Make a file large.\"\n\nThe \"sentence force\" of a sentence indicates what kind of response the user expects:\nUser: \"A file is large.\" -> \"Yes, that is true\"\n\nUser: \"Is a file large?\" -> \"Yes\"\n\nUser: \"Which file is large?\" -> \"test1.txt\"\n\nUser: \"Make a file large.\" -> \"test1.txt is now large\"\n\nNote that these are all answers the user would expect if the statement worked.  All but the last would be very different if there were no large files in the system:\nUser: \"A file is large.\" -> \"No, that isn't true\"\n\nUser: \"Is a file large?\" -> \"No\"\n\nUser: \"Which file is large?\" -> \"No files are large\"\n\nUser: \"Make a file large.\" -> \"test1.txt is now large\" (still works because it isn't looking for large files, it is making them large)\n\nSo, the sentence force property is key to understanding the types of responses a user expects. Perplexity Internals discusses how to go about coding responses to these different sentence types concretely.\nIn the next section we'll talk about how to handle failures in a backtracking system.\nComprehensive source for the completed tutorial is available here.\n\n", "title":"Sentence Types", "teaser":"Sentence Types\nWe've been using a lot of examples that are questions and propositions without actually working through how the system should detect th ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devcon/devcon0080ErrorsChoosingWhichFailure", "excerpt":"Reporting the Right Failure\nBecause a backtracking system can encounter many failures before finding a solution (or not), we have a few challenges to work through in building an approach for reporting errors.\nThe first challenge is to figure out which of the failures to return. Usually there is more than one. To see why, recall that we are solving MRS by effectively pushing all combinations of items in the world \"through\" the MRS until we find the ones that make it true. \nFor \"A file is large\", the MRS and a resolved tree are:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _a_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _file_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _large_a_1 LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _file_n_of(x3,i8)\n_a_q(x3,RSTR,BODY)    \n               \u2514\u2500 _large_a_1(e2,x3)\n\nA described in the section on backtracking, our idealized approach to solving it is:\n_a_q iteratively sets x3 to each object in the world and calls _file_n_of with that value\n\nIf _file_n_of succeeds, _a_q then calls _large_a_1 with the values returned\n\nIf large_a_1 succeeds, then a_q succeeds and stops iterating. \n\nSo, let's take a world that has the following items in it, run it through the MRS for \"A file is large\" and see where things fail:\na folder\na small file\na large file\na dog\n\na folder:\n_a_q sets x3 to a folder and calls _file_n_of with that value\n\n_file_n_of fails\n\na small file:\n_a_q sets x3 to a small file and calls _file_n_of with that value\n\n_file_n_of succeeds, _a_q then calls _large_a_1 with the values returned\n\nlarge_a_1 fails. \n\na large file:\n_a_q sets x3 to a large file and calls _file_n_of with that value\n\n_file_n_of succeeds, _a_q then calls _large_a_1 with the values returned\n\nlarge_a_1 succeeds, therefore a_q succeeds and stops iterating. \n\nSo, when solving the MRS with this world definition, we hit (in this order):\na _file_n_of failure\n\na large_a_1 failure\n\na solution (i.e. no failure)\n\nEven though the system hit two failures in solving the MRS, the user that said \"a file is large\" wouldn't expect any failures to be reported. They would expect something like \"Correct!\" to be said.\nAnother example: What if the user said, \"A file is very large\"? In solving the MRS with the same world you'd get (in this order):  \na _file_n_of failure\n\na large_a_1 failure (since none are \"very large\")\n\na large_a_1 failure (since none are \"very large\")\n\na _file_n_of failure\n\nThere were 4 failures encountered when solving the MRS for this case. The user would ideally like the error to be something like, \"No, there isn't a very large file\", which presumably corresponds to the middle two. Which heuristic helps us choose those?\nOne heuristic that works well in practice is this: If there is a solution for an MRS, don't report any errors. If there is no solution for an MRS, report the error from the \"deepest/farthest\" failure possible.\n\nThe intuition for why this works is this:\nIf there was a solution, it means that there was a way to make the phrase work logically in the world. Presumably, it will make sense to the user too, even if it isn't what they meant (though likely it is), so no failure should be reported. \nIf there wasn't a solution, the user will want to know why not. The \"real\" reason is \"because the MRS did not have a solution\", but that is unsatisfying and no human would respond with that. A human would respond with where they got blocked attempting to do what the user asked. Furthermore, even if the human tried, or thought about, 10 different approaches to performing the request, they usually won't describe the 10 ways they tried that didn't work out. They'll likely list the failure that is \"the closest they got to succeeding\".  For example:\n(In a world where there are 10 things on the counter, \nincluding milk, and Bob is holding things he can&#x27;t put down)\n\nAlice: &quot;Could you give me the milk?&quot;\nBob: (good answer) &quot;My hands are full&quot;\nBob: (bad answer) &quot;I thought about handing you ketchup, \n                    but then realized it wasn&#x27;t milk&quot;\n\nThe second answer is bad for many reasons, but here we'll focus on the fact that Alice probably wanted the answer \"closest to the solution\" as a starting point. She could always ask for more detail or alternative solutions if she really wanted them.\nLet's look into Bob's head to see how the answers were generated: Bob tried to solve the request by looking at each thing on the counter until he found the milk (that was 9 different \"failures\" until one succeeded). Then, he tried to \"give it to Alice\" which failed because his hands were unavailable. The last failure happened \"closest to the solution\" and generated the best answer. The other 9 failures were earlier in the process and generated less optimal answers. The failures that get the farthest in the tree are usually closest to a solution and thus will usually \"make the most sense\" to report.\nHere's a more explicit algorithm:\nTrack the \"depth\" of each predication in the tree, where \"depth\" means \"call order\"\n\nEvery time a predication fails, if it is the \"deepest\" failure so far, remember that error\n\nIf the MRS has no solutions, report the remembered error to the user\n\nPerplexity Internals gives a good example of how Perplexity registers and reports failures using this approach.\n", "title":"Choosing a Failure", "teaser":"Reporting the Right Failure\nBecause a backtracking system can encounter many failures before finding a solution (or not), we have a few challenges to  ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devcon/devcon0040MRSSolverSolutionGroupsAlgorithm", "excerpt":"Appendix: Implementing the Solution Group Algorithm\n[This is an appendix because it doesn't change the overall concepts you need to understand to use the system, it just walks through one architecture for how to implement them.]\nAs described in the section describing Solution Groups, we saw that the only way to represent the semantics of collective, distributive and cumulative readings of a sentence like:\nstudents lifted a table\n\nformula: student(x3), table(x10), lift(x3, x10)\nscoped formula: scope(x3, [student(x3), scope(x10, [table(y), lift(x3, x10)])])\n\n... is to have the solver create groups of solutions (\"solution groups\") that are the complete answers -- a single solution to the MRS is not enough. This section describes one algorithm that can accomplish this.\nOverview\nThe basic approach is to generate the solutions, exactly like we've been doing so far, but then add a new \"grouping pass\" afterward. The grouping pass will find the groups of solutions that meet all the numeric constraints that the words in the phrase have placed on the variables. The groups found represent the complete answers to the MRS.  \nTo illustrate what \"numeric constraint\" means, take \"students lifted a table\":\n\"students ...\" is plural, which means the contraint is: count(students) > 2\n\n\"... a table\" means the constraint is: count(tables) = 1\n\netc.\n\nTo generate solution groups from the flat list of solutions, we could start by generating all combinations of solutions and testing them. For a given combination from the above example: to determine count(students), we could simply count the students across all the solutions in the combination. If we do this as well for count(tables), and return those combinations where count(students) > 1 and count(tables) = 1, we will produce groups which are valid, but will miss any answers that require a \"per previous value\" count. So, we'll miss the distributive groups. We need to do a slightly more complicated counting algorithm that is \"per previous value\" to get all the readings.\nHere's an overview of how the algorithm can determine groups that properly account for cumulative, collective and distributive readings:\nDetermine the order variables appear when evaluating the tree\n\nWalk the variables in order. For each variable: count individuals in the solutions two different ways:\nCumulatively: Total the variable individuals across all solutions in the group (as above)\n\nDistributively/collectively: Group the individuals by the value of the previous variable in the order, and then do the total per previous value. If the totals are all the same, across all previous values, that is the count. If not, this count fails and has no value.\nIf this is the first variable: there is no \"previous variable\" to use for the \"total per previous value\" definition of collective and distributive. Therefore, the first variable can only be totalled as cumulative. \n\n\n\nIf either count meets the variable constraint, it succeeds and the next variable in the order is tried. If not, this group fails.\n\nIf the end is reached and all variables succeeded, this is a valid solution group.\n\n\nTo get the groups that should be checked using the process above, we (you guessed it...) try every combination of solutions that solving the tree produced. We will end this entire section with ways of efficiently doing this, but we'll start with the simplistic approach because it is easier to follow and does work, just not efficiently as it could. \nFiguring out which constraints are on the variables is a longer story, which the next few sections will cover.\nVariable Constraints Overview\nNotice that every x variable used in a tree has some kind of numeric constraint applied to it, even if implied. We can model them all using a between(min, max) (inclusive) constraint with a lower bound and an upper bound. The upper bound can be \"inf\", meaning \"infinity\".\nFor \"students lifted a table\":\n\"students ...\" is plural, which means: between(2, inf)\n\n\"... a table\" means: between(1, 1) (i.e. exactly 1)\n\nFor \"which file is under 2 tables?\":\n\"... file ...\" is singular, which means: between(1, 1)\n\n\"... 2 tables ...\" specifies two, so: between(2, 2)\n\nbetween(1, inf) is the default constraint, meaning: \"anything\". Variables with no other constraint get this one -- it is implied.\nThe next section talks about how to extract these constraints from the tree itself.\nDetermining Constraints From the MRS Tree\nNumeric constraints can come from 3 places in an MRS: quantifiers, adjectives and the plurality property of a variable. Determining constraints will force us to finally start looking at full MRS documents as opposed to simplified MRS fragments that use the artificial scope() predication we invented in the previous section.\nLet's start with \"two students lifted a table\". Here's one MRS reading of it, along with one scope-resolved mrs:\n[ &quot;two students lifted a table&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: prop TENSE: past MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ udef_q&lt;0:3&gt; LBL: h4 ARG0: x3 [ x PERS: 3 NUM: pl IND: + ] RSTR: h5 BODY: h6 ]\n          [ card&lt;0:3&gt; LBL: h7 ARG0: e9 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: x3 CARG: &quot;2&quot; ]\n          [ _student_n_of&lt;4:12&gt; LBL: h7 ARG0: x3 ARG1: i10 ]\n          [ _lift_v_cause&lt;13:19&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x11 [ x PERS: 3 NUM: sg IND: + ] ]\n          [ _a_q&lt;20:21&gt; LBL: h12 ARG0: x11 RSTR: h13 BODY: h14 ]\n          [ _table_n_1&lt;22:27&gt; LBL: h15 ARG0: x11 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 h13 qeq h15 &gt; ]\n\n                        \u250c\u2500\u2500 _student_n_of(x3,i10)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n            \u2502             \u2514 card(2,e9,x3)\nudef_q(x3,RSTR,BODY)\n                 \u2502             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x11)\n                 \u2514\u2500 _a_q(x11,RSTR,BODY)\n                                    \u2514\u2500 _lift_v_cause(e2,x3,x11)\n\nText Tree: udef_q(x3,[_student_n_of(x3,i10), card(2,e9,x3)],_a_q(x11,_table_n_1(x11),_lift_v_cause(e2,x3,x11)))\n\nTwo points to note as we transition to using real MRS trees instead of simplified trees:\nAt this point, we can dispense with the artificial scope() predication because the MRS quantifier predications (those with _q at the end) fulfill the same variable scoping role as scope(). They declare where in the tree a variable can be used.  They also can add numeric constraints to the variable, as we'll see below.\n\nPredications in MRS have variable types beyond the x-type variables we've been using. For the examples we'll see here, these can be safely ignored. We'll handle those in a later section.\n\nWith that covered, let's walk through how to get the numeric constraints from the above MRS.\nOrder of Variables\nFirst, notice that the variable order in this tree is [x3, x11] (read left to right) since that is the order of the variable quantifiers when evaluating the tree depth-first.\nQuantifier Constraints\nEach variable in an MRS must have a quantifier that scopes it (the artificial scope() predication performed this function in prior examples), and quantifiers always add a numeric criteria to the variable they scope.  Some, like udef_q in our example, add the default criteria between(1, inf). This simply means: \"at least one\". The _a_q quantifier means \"a single thing\", so it adds between(1, 1). \nThus, the quantifiers in this example add these constraints:\n|x3 (students)|x11(table)|\n|---|---|\n|udef: between(1, inf)| _a_q: between(1, 1)|\nAdjective Constraints\nSome adjectives also add numeric constraints. In our example, the adjective \"two\" gets converted to the predication: card(2,e9,x3) in the MRS. This predication adds the constraint between(2, 2) to x3. Now we have these:\n|x3 (students)|x11(table)|\n|---|---|\n|udef: between(1, inf)| _a_q: between(1, 1)|\n|card: between(2, 2)| |\nPlural Variable Properties\nFinally, some variables (x3 in our example), are defined to be plural by the MRS, as indicated by NUM: pl in the variable properties of x3:\n[ udef_q&lt;0:3&gt; LBL: h4 ARG0: x3 [ x PERS: 3 NUM: pl IND: + ] RSTR: h5 BODY: h6 ]\n\nThis adds the constraint between(2, inf) to x3. \nx11 from _table_n_1(x11) is singular based on its variable properties:\n[ _lift_v_cause&lt;13:19&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x11 [ x PERS: 3 NUM: sg IND: + ] ]\n\n...  so it adds between(1, 1):\nThus, our final list of constraints is:\n|x3 (students)|x11(table)|\n|---|---|\n|udef: between(1, inf)| _a_q: between(1, 1)|\n|card: between(2, 2)| [NUM: sg]: between(1, 1) |\n|[NUM: pl]: between(2, inf)| |\nCombining Constraints\nThe final constraints from the example can be combined.  If x3 must be:\n\"between 1 and infinity\" and \"between 2 and infinity\" then saying \"between 2 and infinity\" is enough.\n\n\"between 2 and infinity\" and \"between 2 and 2 (i.e. exactly 2)\" then saying \"between 2 and 2\" is enough.\n\nUsing this logic, the final list of constraints above can be reduced to:\n|x3 (students)|x11(table)|\n|---|---|\n|between(2, 2)| between(1, 1)|\nWhich matches the intuition that there should be exactly two students and exactly one table (possibly for each student) in \"two students lifted a table\".\nMRS Constraints Summary\nSo, now we have an approach to gathering the constraints from the MRS:\nFor each x variable in the MRS:\nAdd the appropriate constraint for its quantifier\n\nAdd any constraints from adjectives that modify it\n\nAdd the NUM: pl or NUM: sg constraint\n\nReduce them to the minimal set\n\n\nThe Final Algorithm: Introducing Phase 0\nThis section started by describing the two phases of the solver algorithm:\nPhase 1: Evaluate the MRS tree to get the solutions\n\nPhase 2: Group the solutions into solution groups that meet the phrase's numeric constraints\n\nIt turns out that the (just described) process of building the numeric constraints is really a \"Phase 0\". And, if you think about what adjectives like \"two\" (or \"a few\" or \"many\") actually do, their entire contribution is to act as a numeric constraint. Their work happens during Phase 2 ... they have nothing to do in Phase 1. So, after we extract the criteria from them in Phase 0, they should be removed from the tree and Phase 1 should be solved using the modified tree without them.\nFurthermore, recall that quantifiers do two things: scope a variable and add a numeric constraint to the variable. So, after you extract the numeric constraint from quantifiers like _a_q or _some_q, you've also removed all of their contribution to Phase 1 except for variable scoping. So, we don't remove them, but we do replace them with the most generic quantifier: udef_q.\nThus, Phase 0 analyzes a full tree for \"2 students lifted a table\", one of which is this:\n                        \u250c\u2500\u2500 _student_n_of(x3,i10)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n            \u2502             \u2514 card(2,e9,x3)\nudef_q(x3,RSTR,BODY)\n                 \u2502             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x11)\n                 \u2514\u2500 _a_q(x11,RSTR,BODY)\n                                    \u2514\u2500 _lift_v_cause(e2,x3,x11)\n\n... but then, after extracting numeric constraints, converts it to a tree without the numeric constraints in it (since those will run in Phase 2), and provides this modified tree to Phase 1:\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _student_n_of(x3,i10)\n            \u2502             \nudef_q(x3,RSTR,BODY)\n                 \u2502               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x11)\n                 \u2514\u2500 udef_q(x11,RSTR,BODY)\n                                      \u2514\u2500 _lift_v_cause(e2,x3,x11)\n\n... and finally Phase 3 runs the extracted numeric constraints over the Phase 1 solutions to generate the final solution groups. \nHere's the full algorithm all in one place:\nPhase 0: Setup\nStart with a scope-resolved MRS\n\nDetermine the list of x variables in the tree and the order they will be evaluated in\n\nDetermine the constraints placed on each x variable by predications that modify it\n\nCreate a modified tree by:\nRemoving adjective predications that added numeric constraints\n\nChanging quantifiers that added numeric constraints to udef_q\n\n\nPhase 1: Solution Generation\nGenerate the list of solutions to the modified tree using the approach described in the previous section\n\nPhase 2: Group Generation\nFor each possible combination of solutions from Phase 1: Walk the x variables in evaluation order. \n\nFor each x variable: Count individuals in the solutions two different ways:\nCumulatively: Total the variable individuals across all solutions in the combination\n\nDistributive/collectively: Group the individuals by the value of the previous variable in the order, and total individuals in this variable per previous value. If the totals are all the same, across all previous values, that is the count. If not, this count fails and has no value.\nIf this is the first variable, there is no \"previous variable\" to use in the \"total per previous value\" definition of distributive/collective. Therefore, the first can only be totalled cumulatively\n\n\n\nIf either count meets the variable constraints: it succeeds and the next variable in the order is tried\nIf not: this group fails and the next combination group starts at step #5\n\n\nIf the end of the variables is reached and all succeeded, this combination is a valid solution group\n\n\nWhen numeric constraints are removed from an MRS we are left with a relatively straightforward constraint satisfaction problem that should be able to return solutions quickly, but there still may be many solutions.\nExample\nThat can be a lot to take in, so let's go through an example, \"students lifted a table\":\n[ &quot;students lifted a table&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: prop TENSE: past MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ udef_q&lt;0:8&gt; LBL: h4 ARG0: x3 [ x PERS: 3 NUM: pl IND: + ] RSTR: h5 BODY: h6 ]\n          [ _student_n_of&lt;0:8&gt; LBL: h7 ARG0: x3 ARG1: i8 ]\n          [ _lift_v_cause&lt;9:15&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n          [ _a_q&lt;16:17&gt; LBL: h10 ARG0: x9 RSTR: h11 BODY: h12 ]\n          [ _table_n_1&lt;18:23&gt; LBL: h13 ARG0: x9 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _student_n_of(x3,i8)\nudef_q(x3,RSTR,BODY)          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x10)\n                 \u2514\u2500 _a_q(x10,RSTR,BODY)\n                                   \u2514\u2500 _lift_v_cause(e2,x3,x10)\n\nText Tree: udef_q(x3,_student_n_of(x3,i8),_a_q(x10,_table_n_1(x10),_lift_v_cause(e2,x3,x10)))\n\nPhase 0: Setup\nStart with a scope-resolved MRS\n\nDetermine the list of x variables in the tree and the order they will be evaluated in\n\nDetermine the constraints placed on each x variable by predications that modify it.\n\n\nUsing the approach described above, the evaluation order of variables is [x3, x10] in a depth-first traversal and the found constraints for the variables are:\n|x3 (students)|x10(table)|\n|---|---|\n|udef: between(1, inf)| _a_q: between(1, 1)|\n|[NUM: pl]: between(2, inf)| [NUM: sg]: between(1, 1) |\nWhen simplified, they are:\n|x3 (students)|x10(table)|\n|---|---|\n|between(2, inf)| between(1, 1) |\nCreate a modified tree by:\nRemoving adjective predications that added numeric constraints\n\nChanging quantifiers that added numeric constraints to udef_q\n\n\n\nThe modified tree is:\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _student_n_of(x3,i8)\nudef_q(x3,RSTR,BODY)             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x10)\n                 \u2514\u2500 udef_q(x10,RSTR,BODY)\n                                      \u2514\u2500 _lift_v_cause(e2,x3,x10)\n\nPhase 1: Solution Generation\nGenerate the list of solutions to the modified tree using the approach described in the previous section\n\n\nUsing a (unshown) world state, and using the approach described in the previous section, the solutions to the modified tree are (let's say):\n&quot;students lifted a table&quot;\n\nTree: udef_q(x3,_student_n_of(x3,i8),udef_q(x10,_table_n_1(x10),_lift_v_cause(e2,x3,x10)))\n\nSolution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\nSolution 2: x3=[student2], x10=[table2]\nSolution 3: x3=[student3], x10=[table3]\nSolution 4: x3=[student3], x10=[table4]\nSolution 5: x3=[student4], x10=[table5]\nSolution 6: x3=[student4], x10=[table6]\nSolution 7: x3=[student5,student6], x10=[table7]            &quot;student5 and student6 [together] are lifting table7&quot;\nSolution 8: x3=[student5,student6], x10=[table8]\nSolution 9: x3=[student7,student8], x10=[table9, table10]   &quot;student7 and student8 [together] are lifting table9 and table10 [at the same time]&quot;\nSolution 10: x3=[student9], x10=[table11, table12]          &quot;student9 is lifting table11 and table12 [at the same time]&quot;\nSolution 11: x3=[student10,student11], x10=[table13]\nSolution 12: x3=[student12], x10=[table14]\n\nPhase 2: Group Generation\nFor each possible combination of solutions from Phase 1: Walk the x variables in evaluation order. \n\n\nStart by generating (as yet untested) groups that are all combinations of the above solutions. These may or may not be solution groups, we don't know yet: we need to test each one:\nGroup 1:\n  Solution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\n\nGroup 2:\n  Solution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\n  Solution 2: x3=[student2], x10=[table2]\n\nGroup 3:\n  Solution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\n  Solution 2: x3=[student2], x10=[table2]\n  Solution 3: x3=[student3], x10=[table3]\n\n... etc. (there are *many* more groups not listed)\n\nFor each group:\nFor each x variable: Count individuals in the solutions two different ways:\nCumulatively: Total the variable individuals across all solutions\n\nDistributive/collectively: Group the individuals by the value of the previous variable in the order, and total individuals in this variable per previous value. If the values are all the same, that is the count. If not, this count fails and has no value.\nIf this is the first variable, there is no \"previous variable\" to use in the \"total per previous value\" definition of distributive/collective. Therefore, the first can only be totalled cumulatively\n\n\n\nIf either count meets the variable constraints: it succeeds and the next variable in the order is tried\nIf not: this group fails and the next group starts at step #5\n\n\nIf the end of the variables is reached and all succeeded, this combination is a valid solution group\n\n\nUsing the constraints we determined:\n|x3 (students)|x10(table)|\n|---|---|\n|between(2, inf)| between(1, 1) |\n... let's analyze each group:\nGroup 1:\n  Solution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\n\nx3 is the first variable so we only do the cumulative count for it: cumulative_count=1. The constraint on x3 is between(2, inf). Thus: this group fails.\nGroup 2:\n  Solution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\n  Solution 2: x3=[student2], x10=[table2]\n\nx3 is the first variable so we only do the cumulative count for it: cumulative_count=2 which passes the constraint between(2, inf). Try the next variable.  \nx10 gets both kinds of count: \ncumulative_count=2. This fails the between(1, 1) constraint, but we have one more try...\n\ndist_coll_count(student1)=1, dist_coll_count(student2)=1. Both counts are the same so dist_coll_count=1 The constraint on x10 is between(1, 1). Thus: this variable succeeds.\n\nThere are no more variables, thus this group is an answer: a distributive answer.\netc. \nAll the groups that succeed are solution groups and will be valid collective, distributive or cumulative readings of the phrase in that world.\nThere are some subtleties that need to be address with this algorithm. Namely: which of these solution groups to respond to the user with (described in Appendix A since it is not necessary for understanding the concept) and global constraints from words like \"the\" (described in TBD).\n", "title":"A. Implementing Solution Groups", "teaser":"Appendix: Implementing the Solution Group Algorithm\n[This is an appendix because it doesn't change the overall concepts you need to understand to use  ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devcon/devcon0050MRSSolverSolutionCombinations", "excerpt":"Appendix: Optimizing the Solution Group Algorithm\n[This is an appendix because it doesn't change the overall concepts you need to understand to use the system, it just walks through one architecture for how to implement them.]\nIn the section introducing the solution grouping algorithm, the algorithm starts with:\nFor each possible combination of solutions from Phase 1 ...\n\nAnd leaves how to generate them as an exercise for the reader. In this section, we'll go through one approach to generating combinations of solutions that properly deals with the kinds of answers users expect and allows for some performance optimizations.\nOnly 2 Solution Groups Are Needed\nThe number of solution groups for a tree in a given world can be quite large, but the system only needs 2 of them for any response (question, proposition or command). This allows for some nice performance optimizations. Let's go through each type of phrase to see why.\nWH-Questions\n\"WH-Questions\" are \"which/who/what/where\" questions that expect a list as a response. Let's use this tree from the phase \"which 2 files are in a folder?\":\n                          \u250c\u2500\u2500 _file_n_of(x3,i10)\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n              \u2502             \u2514 card(2,e9,x3)\n_which_q(x3,RSTR,BODY)\n                   \u2502             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _folder_n_of(x11,i16)\n                   \u2514\u2500 _a_q(x11,RSTR,BODY)\n                                      \u2514\u2500 _in_p_loc(e2,x3,x11)\n\n... in this world:\n\\desktop\\file1.txt\n\\desktop\\file2.txt\n\\system\\file3.txt\n\\system\\file4.txt\n\nSome solution groups for this are:\nGroup:\n  \\desktop\\file1.txt\n  \\desktop\\file2.txt\n\nGroup:\n  \\system\\file3.txt\n  \\system\\file4.txt\n  \nGroup:\n  \\desktop\\file1.txt\n  \\system\\file3.txt\n\nGroup:\n  \\desktop\\file1.txt\n  \\system\\file4.txt\n\nGroup:\n  \\desktop\\file1.txt\n  \\system\\file4.txt\n  \netc., there are more ...\n\nHow many of these solution groups does the system need in order to respond? 1 of them? all of them? If we want the system to respond in the way a user expects, we need to observe the way a human would respond. \nHere are some typical responses a human might make when asked questions about the world above:\nLin: Which 2 files are in a folder?\nMila: Umm...there are more than 2 files in a folder ... which do you mean?\n\nIrene: Which 2 files are in a folder?\nHana: Actually, there are a bunch of files in a folder, 2 of of them are: file1.txt and file2.txt\n\nJuan: Which 2 files are in a folder?\nCarlos: Well, lets see: file1.txt and file2.txt are in \\desktop, file3.txt and file4.txt are in \\documents, ...\n\nThe first two explicitly or implicitly acknowledge that the question is implying there are only 2 files in a folder, but the participants are willing to respond to a phrase the user didn't ask, giving them the benefit of the doubt. The last one interprets the phrase more broadly as something like \"what are all the sets of 2 files in a folder\".  Carlos is probably a puzzle or math guy and thought it was a trick question.\nAnother example: In a physics class of 20 students, where only one student got 100%, the professor is asked, \"Which students aced the exam?\" and responds with \"Only Mariam.\" Note that the question had \"students\" (plural) and the professor felt the need to say \"only\" to indicate that they weren't really answering the question asked since they responded in singular. Saying simply \"Mariam\" feels slightly wrong, but note that if 2 students aced it, saying \"Mariam and Aron\" would be just fine and not feel wrong at all. So, something is being acknowledged in the one student case.\nSo, building a system that is completely literal and responds to \"Which 2 files are in a folder?\" with \"There are more than only 2 files in a folder.\" (Mila's response above), might be correct but will be annoying.  The Carlos answer is the most complete and generous, but could result in a huge (possibly expensive) answer when the user, who also understands that the question implicitly means \"only\", probably misunderstood the world state. Hana's answer is a good middle ground that gives an answer \"just in case\", but acknowledges that the question was probably a misunderstanding of the world state. Hers also doesn't overload the questioner with a huge number of answers.\nThis implies that, for WH-questions (where, what, who, etc), we need to get one answer to respond and see if there is another to let the questioner know there are more. We need 2 answers.\nYes/No Questions\nWhat about (using the same examples from above): \"Are there 2 files in a folder?\" or \"Did students ace the exam\"? These act the same as WH-questions:\nResponding to \"Are there 2 files in a folder?\" with \"Yes.\" is technically true for the above example, but would probably be considered a little misleading. So the answerer might respond with something like \"Technically yes, but there are more.\"\n\nResponding to \"Did students ace the exam?\" with \"Yes.\" would cause most people to be mildly annoyed later if they find out there was only one. \n\nThis implies that, for Yes/No questions, we need to get one answer to respond and test if there is another answer to let the questioner know there are more. So, we also need 2 answers.\nPropositions\nContinuing with our example, this time as a proposition: \"2 files are in a folder\" or \"students aced the exam\". These act just like Yes/No questions: The first is \"technically true\" the second is just wrong. So: 2 answers required.\nCommands\nWhat should \"delete 2 files in a folder\" do? Deleting all examples of \"2 files in a folder\" feels wrong. There seems to be an implied \"one instance of\" after delete. A clearer example might be \"delete a file in a folder\". There are 4 examples (solution groups) of \"a file in a folder\" in the world in question, but deleting them all due to that phrase would be certainly wrong.\nSo, if we decide that we should only pick one of the solution groups to act on for commands, it should be noted that deleting \"2 files\" or \"a file\" when there is more than one solution group feels a bit random. For this example, a human might ask, \"Do you mean a random 2 files?\". Certainly saying, \"delete files in a folder\", if there is only 1 file, feels wrong, just like \"Talk to the students that aced the exam\" when there is only one student feels wrong.  Either would probably get a response like \"OK, but there is only one\" to communicate that the listener isn't going to do exactly what was commanded.\nAll this is to say that, again, commands should also retrieve 2 solution groups. The first is what will be \"done\", the second is to see if some kind of clarifying response should be given.\nSo, to summarize, we only need to return 2 solution groups in the algorithm we develop, across all types of phrases. This will give us some room for performance optimization.\nMaximal, Minimal, and Subset Solution Groups\nBased on the above analysis, we're going to need to retrieve two solution groups (if they exist) when processing any user phrase and show the user (or do) the first group. The second group is just tested to see if it exists and then say \"there are more answers here...\" in some form.\nThe problem is: as we've seen in previous sections, there can be many correct solution groups for a given answer which aren't \"maximal\".  To see what \"maximal\" means, take: \"which files are in a folder?\" when there are these files in a folder:\n/folder/file1.txt\n/folder/file2.txt\n/folder/file3.txt\n/folder/file4.txt\n\n... one technically correct answer is:\n/folder/file1.txt\n/folder/file2.txt\n\n... another technically correct answer is:\n/folder/file1.txt\n/folder/file2.txt\n/folder/file3.txt\n\netc. \nBasically, any combination of files in a folder is a \"technically correct\" answer so long as it is > 1 (due to plural \"files\"). While it is technically correct, if you asked a person, \"which files are in a folder\" and they gave you one of those answers, you might be a bit annoyed and clarify with \"can you give me the whole list?\"  Let's call these \"subset solution groups\".\nSo, since we are only going to return one solution group, we really want to return the maximal solution group, the one where no more solutions can be added to the group while still keeping it a valid group. Keeping it a valid group means all solutions in the group conform to at least one type of answer (collective, distributive or cumulative). It is OK if they all conform to more than one, however.\nIn general, subset solution groups can be generated any time a criteria for a variable has a range of values that can be true. When the solution group is at the bottom of the range for that variable it is a \"minimal\" solution, at the top is a \"maximal\" solution, anything in between is a \"subset\" solution. \nTwo examples:\nEven one plural variable in an MRS can potentially generate multiple subset groups.  For example: \"men are walking\" (when talking about a specific group of men). The entire group of \"men\" can be represented in one solution group, so you'd just expect one group in answer to, \"Which men are walking?\". But: subsets of that group would also be true, so other solution groups are also technically correct.\n\nWith two variables: \"men(x) are walking a dog(y)\" (when talking about one group of men walking a particular dog) you'd still only expect one solution group in answer to \"Which men are walking a dog?\": the \"maximal\" solution. But again, subsets would be technically true, just not really telling the whole story.\n\nAll this is to say: if you're only going to give one answer (which we are), it should be a maximal one. To make the system responsive, though, it should start returning an answer as soon as one meets the constraints (i.e. when we have a \"minimal\" answer), but then keep returning answers as the set gets enlarged. That way, the user can see answers as they come.\nTo sum up:\nSince we are only going to show the user one solution group, it should be a maximal group\n\nIt should get returned iteratively, starting as soon as there is a minimal group that meets its constraints, but the entire maximal group should be ultimately returned\n\nThe complete solution group shown should meet the rules for one of the three types (collective, distributive or cumulative)\n\nBased on this, it is worth defining a few terms that we can use as we walk through more scenarios:\na \"minimal solution group\" is one where the constraints meet the minimum required to be a solution group. Since adding a new solution only ever increases variable counts (since variables always have at least one individual), the first solution group that meets the criteria will always be minimal (it may also be maximal!)\n\na \"maximal solution group\" is one where no more solutions can be added to the solution group and still have it a) meet the criteria and b) have all solutions be contributing to a single mode. This could be because all the criteria are at their maximum, or it could be because there are no more solutions to add.\n\na \"subset solution group\" is anything that isn't maximal but is still a solution. It is a \"subset\" of some maximal solution group in that all of its rows are completely included in that other group.\n\na \"unique solution group\" is one that isn't a subset of another solution group. It has at least one solution that is not in any other.\n\nWe'll use these terms as we develop the algorithm below.\nIt is important to note that these terms are all invented for this algorithm. They (or even the notion of \"solution group\") are not DELPH-IN or even linguistic terms.  They are artifacts of the particular approach being used to solve MRS trees.\nAlgorithm Version 1\nThis will form the skeleton of the algorithm we're going to eventually settle on. It is a general purpose algorithm that creates all combinations of items in a set:\nStart with a list of sets: set_list, which initially contains a single empty set. \n\nWhen a new solution is found, for each selected_set in set_list:\n\nBuild a new_set by adding the solution to selected_set \n\nIf new_set meets or could eventually meet the criteria (once more rows are added), add it to set_list\n\nIf new_set actually did meet the criteria, also return it as a solution group\n\nThis algorithm works because each set in set_list becomes a base for creating new combinations when a new solution comes in. And, when that new alternative is created, it also gets added to set_list so it can also form new combinations. In this way, we generate all possible combinations.\nThis algorithm for creating all possible combinations has a very useful property: it doesn't require knowing the length of the flat list of solutions coming in, and it builds combinations out of the items it already has before retrieving another solution. This means it will allow us to efficiently stream solutions to it without having to calculate them all up front, which could be very expensive.  \nThis is not the final algorithm because, while it will produce all combinations that meet the criteria, it also produces the problematic \"subset\" or \"minimal\" solutions that we described above. But, it will form a good skeleton for an algorithm we can use with modifications.\nAlgorithm Version 2\nWe need 3 things from the final algorithm:\n(for all cases) Retrieve a minimal solution group as quickly as possible. For yes/no questions and propositions, we just need to prove there is one solution, so a minimal solution is enough to create the initial answer. For wh-questions and commands, we want to start showing the answers as soon as we have them for responsiveness.  So, in all cases, we don't care if it is maximal for the initial response, we just want it quickly.\n\n(for WH-questions and commands) We want to stream the rest of the solutions until there is a maximal group. This is so we respond to the user or do the command with a full answer (as described above). After receiving the minimal solution group, we'd like to continue getting additional solutions that belong in that solution group as they become available, until we have the maximal solution group. \n\n(for all cases) Detect if there is more than one unique solution group. This allows us to say \"there are more\" (as described above). Importantly, it needs to be a unique solution group, not one that is a subset of another group.\n\nLet's walk through how to modify the algorithm so it meets each requirement.\nRetrieve a Minimal Solution Group Quickly\nAlgorithm version 1 already does this. It returns a solution group as soon as it detects it is a valid collective, distributive or cumulative solution. No changes are needed to meet this requirement.\nStreaming Solutions Until There is a Maximal Group\nAlgorithm version 1 only generates alternative solution groups -- it doesn't say which are simply enlarging a previously returnedsolution group with another solution.\nTo fix this, note that each returned solution group was generated by taking an existing group from the set list and adding a solution to it. So, the algorithm can give each set a unique ID and a \"lineage\" that tracks where it came from. For example, set id 5 might have a lineage of 0:3:5 indicating that it came directly from set 3, and 3 came from 0. The lineage shows the set history (which sets this set came from) for this set.\nIf we include the lineage when we return a solution group, the caller can see if it is a simple update of a solution group they already have by comparing their lineages.  If they share a prefix, then the new one is a descendent -- it is just \"a little more\" of that solution. The caller must then use that new lineage as its base to compare from. This last step is needed so it doesn't think all the alternatives generated from its current solution group were also \"a little more\". It is effectively following one set as it grows.\nIn this way, we can get a minimal solution group first and slowly grow it over time by examining every solution group that comes from the algorithm and comparing the lineages to the solution we have. This allows us to stream the solutions as they get added to a solution group, eventually ending with the maximal solution group.\nIf there are 5 unique solution groups for a given phrase, this means we will effectively be picking one at random to show the user. This is OK since, if there are many solutions, it really doesn't matter which we show. [TODO: explain why].\nBut, this only works if all the subsets of a unique solution group have the same lineage.  Let's examine that next.\nGenerate Only Unique Maxmimal Solution Groups\nAlgorithm 1 will generate all non-empty combinations of solutions. That means if the MRS is simply \"files(x)\" (which has the constraint between(1, inf)), and there are 2 files, it will generate:\nGroup 1:\n  file1\n\nGroup 2:\n  file2\n\nGroup 3:\n  file1\n  file2\n\nThe lineage technique will allow the caller to know that Group 3 is really just an updated Group 2, but Group 2 will look like an independent \"unique\" solution, when it really isn't. Constraints with an inf upper limit can accept all individuals and so will always generate duplicate solutions if they are allowed to form new sets. This is true even if their lower limit is > 1. So, any variable that has an upper constraint of inf should not on its own be a reason to add a new group to the set_list. \nHowever, if the tree has multiple variables with constraints, other variables may be a reason to form a new group. If another variable has an upper limit < inf then we do want to return all combinations of, say, \"2 files\". Thus, in that case we do want to create a new set in set_list with the new solution so that it can form new combinations, but only if the value for that variable in the new solution is not already in a set. Because, if it is already in a set, it is already being tracked and creating a new set to form combinations will, again, create duplicates. \nSo, the logic for creating new sets needs to be: Merge a solution into an existing set if it doesn't contribute new individuals to any variables that have constraints that have a max < inf. If it doesn't get merged into any existing set, create a new one and add it to set_list.\nThis means that, in the new algorithm, set_list begins with no sets. The empty set that Algorithm 1 started with is only used if a solution wasn't merged into an existing set.\nDetect If There Is More Than One Unique Solution Group\nAlgorithm Version 1 doesn't indicate whether a returned solution group is a unique solution group -- one that isn't a subset of any other. It just returns solution groups that have 1 more solution than those it has generated before. This problem is really the inverse of the one above. In this case, we want to see if a new solution group isn't a subset of the one we've selected.\nThe lineage described above provides a way to determine this. A solution group can only be a subset of another if its lineage is a prefix of the other. Said another way: if group 1 is a subset of group 2, group 2 will have group 1's exact lineage as the start of its lineage. This is because lineage shows a complete history of how a set came to be. If there is a solution that has a different lineage than the one we are tracking as \"the chosen solution to show the user\", it must include at least one answer that is different than the chosen one, and thus it must be a different unique solution.\nSo, we will be able to detect if we have more than one unique solution group by picking the lineage that is \"the answer\" we'll show the user, and then seeing if we can find another solution group that has a different lineage. If there is one, that is a second unique solution group.\nWhen Can We Stop\nIf at least one variable has max=inf we need to go all the way to the end to get the maximal solution. If none do, we actually want the minimal solution (but tell the user there are more). So we can stop after we find two solutions\nTODO: finish this\nAlgorithm 2 Design\nWe now have everything we need to design Algorithm 2. It will be more efficient than Algorithm 1 while also allowing us to give the kinds of answers a user will expect. It uses the same skeleton as Algorithm 1, but has some extensions to meet the requirements above. There are two parts: a \"combination generator\" based on Algorithm 1, and a \"solution group picker\" which is new.\nCombination Generator\nStart with:\nset_list (a list of sets), which initially is empty\n\nWhen a new_solution is found, for each selected_set in set_list:\nBuild new_set by adding new_solution to selected_set\n\nGenerate a unique_id. Then, create a lineage for new_set by appending unique_id to the end of the selected_set lineage\n\nIf new_set meets or could meet the criteria (once more rows are added):\n\nIf it can be merged into selected_set merge it\n\nIf not, add it, along with its lineage, to set_list\n\nIf new_set actually did meet the criteria, also return it, and its lineage, as a solution group\n\nIf new_solution meets or could meet the criteria and did not get merged into any set in set_list, add it to set_list. \nSolution Group Picker\nStart with more_than_one_solution_group=False and chosen_solution=None\nGet the first solution group from the combination generator. This is the chosen_solution. Yield it as the \"minimal solution\" to the caller.\n\nFrom then on, for each new_solution_group returned from the combination generator:\n\nIf the lineage of chosen_solution is a prefix of new_solution_group:\nReturn the new solution in new_solution_group as the next solution in chosen_solution.\n\nSet chosen_solution to be the new_solution_group\n\n\nOtherwise, set more_than_one_solution_group to True\n\nWhen complete, indicate to the caller if more_than_one_solution_group is True or False\nThis algorithm will allow the user interface to call the Solution Group Picker and have it return the \"answer\" solution group (if one exists), as well as a flag indicating if there are other solution groups so it can respond appropriately as described above.\nPerformance Optimizations\nGiven what we now know about what is needed from our combination generator, there are many optimizations that can be made to improve performance. Here are a couple:\nQuit generating at 2: Since we only really care about 2 solution groups, the generator doesn't need to keep track of all the sets to build all combinations.  Instead, once it has returned two unique solution groups, it only needs to generate iterations of those. In fact, it really only needs to generate iterations of the first. This eliminates a lot of work generating and testing sets that aren't used.\n\nMerge answers: We can reduce the number of sets we have to consider in set_list by observing that we only need to add a new set to the set list if we have a set that needs to be the base for more alternatives. Variables that have constraints with an upper limit of inf don't need to generate all the combinations since they will just be subsets of the one maximal set. So, if a solution only introduces new individuals to variables that have an upper limit of inf, it can just be merged into that set, it doesn't need to be added as a separate set to set_list.\n\n", "title":"B. Optimizing Solution Groups", "teaser":"Appendix: Optimizing the Solution Group Algorithm\n[This is an appendix because it doesn't change the overall concepts you need to understand to use th ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo010Overview", "excerpt":"Using Perplexity\nPerplexity is a Python library designed to support building natural language software interfaces on DELPH-IN grammars. Interfaces are built by implementing an application vocabulary using Python functions.\nThis section is designed to teach users how to use the Perplexity system to build a natural language interface to a piece of software. It assumes a general understanding of concepts described in the MRS Solver Conceptual section, but also links to them liberally as encountered. \nIf you are looking for how Perplexity itself is implemented, take a look at the Perplexity Internals section. \nWith that said, let's get started. The first step is to install Perplexity.\n", "title":"Overview", "teaser":"Using Perplexity\nPerplexity is a Python library designed to support building natural language software interfaces on DELPH-IN grammars. Interfaces are ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxHowTo/pxHowTo012Install", "excerpt":"Installing Perplexity\nPerplexity is all Python code, with one exception: it requires the DELPH-IN ACE parser for using the DELPH-IN grammars that parse natural language. \nBelow are instructions for installing everything you'll need to run Perplexity and begin developing applications.\nClone Perplexity Using GitHub LFS\nVERY IMPORTANT: This project uses GitHub LFS for storing grammar files. You won't be able to use it properly unless you install GitHub LFS and activate it for the repository by following the below steps.\n\nThe Perplexity repository contains very large grammar files and it uses GitHub LFS to store them. If you don't have GitHub LFS installed yet:\nInstall GitHub LFS following the instructions at that link\n\ngit lfs install for the git user account that you will clone Perplexity with\n\n\ncd to the directory where you want to clone Perplexity\n\n(must be done after the above steps!) Clone the Perplexity project: \ngit clone https://github.com/EricZinda/Perplexity.git\n\n\nNow you can choose to run Perplexity in a Docker container or on your local machine. Instructions for each are below.\nOption 1: Run Perplexity via Docker\nVERY IMPORTANT: This project uses GitHub LFS for storing large grammar files. You won't be able to use it properly unless you install GitHub LFS, activate it for your account, and then clone the repository as described above.\n\nClone Perplexity using GitHub LFS as described above\n\nInstall Docker\n\nFollow the instructions at the top of the docker/Dockerfile file in the Perplexity repository to build an image and run a sample\n\nOption 2: Run Perplexity on Your Machine\nVERY IMPORTANT: This project uses GitHub LFS for storing large grammar files. You won't be able to use it properly unless you install GitHub LFS, activate it for your account, and then clone the repository as described above.\n\nClone Perplexity using GitHub LFS as described above\n\nInstall Python 3.8 or greater on your machine\n\ncd to the directory where you cloned Perplexity: \ncd <Perplexity repository root>\n\n\nCreate an environment for this project: \npython3 -m venv ./env\n\n\nActivate the environment\nsource env/bin/activate\n\n\nInstall the libraries required by Perplexity:\npip install pydelphin\n\npip install inflect\n\npip install openai (note that the ESL sample is the only thing that uses openai for an example, it will just disable this feature if you don't set an OpenAI key to enable it)\n\n\nNow you need to install the ACE Parser, which is the only non-Python part of the project:\nInstall the DELPH-IN ACE parser\n\nMake sure your operating system path is set to the ACE binary you download from there. \n\nThe mac download in the ACE link above does not support the Mac M1 processor. You'll need a special build that is only available on the forum at the moment if you have an M1. Download that here.\n\nNotes: \nThe best location for the ACE binary on a Mac is: /usr/local/bin, but it can be anywhere as long as the path points to it\n\nRead the notes in the \"Troubleshooting\" section of the ACE documentation in the link above: ACE needs execute permissions to your TEMP directory\n\nRunning Tests/Samples on Your Machine\nIf everything is installed correctly, you should be able to successfully run all the tests:\nGo to the directory where Perplexity was cloned:\ncd <Perplexity repository path>\n\n\nActivate the environment\nsource env/bin/activate\n\n\nTell Python that it should look in this directory for modules:\nexport PYTHONPATH=$PYTHONPATH:<Perplexity repository path>\n\n\nRun the file system example and its tests:\npython3 ./examples/file_system_example/examples.py\n\n/runfolder file_system_example\n\n\nOR: Run the ESL Restaurant example and its tests:\npython3 ./examples/esl/tutorial.py\n\n/runfolder esl\n\n\nDaily Workflow\nOnce everything in installed, to begin a session of Perplexity development you need to activate the Python environment you created above and then run Perplexity:\nGo to the directory where Perplexity was cloned:\ncd <Perplexity repository path>\n\n\nActivate the environment\nsource env/bin/activate\n\n\nTell Python that it should look in this directory for modules:\nexport PYTHONPATH=$PYTHONPATH:<Perplexity repository path>\n\n\nStart the Perplexity engine:\npython3 ./examples/file_system_example/examples.py \n\n\nNext Step: Hello World\nNow that you've got Perplexity installed, the next step is to create the minimal \"Hello World\" application.\nCompile a Grammar\nOn the (very rare) chance you will need to compile an ERG grammar, here are the steps:\nDecide which version you want, in this case we'll use 2020.  Replace 2020 below with the version you select\n\nsvn checkout http://svn.delph-in.net/erg/tags/2020\n2a. To get the latest (but no commitment on quality) grammar: http://svn.delph-in.net/erg/trunk\n\ncd 2020/ace\n\nace -G grammar.dat -g ./config.tdl\n\nThe grammar file will be called 'grammar.dat' in the 2020/ace folder\n\nComprehensive source for the completed tutorial is available here\n\n", "title":"Installing Perplexity", "teaser":"Installing Perplexity\nPerplexity is all Python code, with one exception: it requires the DELPH-IN ACE parser for using the DELPH-IN grammars that pars ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxHowTo/pxHowTo014HelloWorld", "excerpt":"Hello World\nThe simplest Perplexity application is:\nfrom perplexity.state import State\nfrom perplexity.user_interface import UserInterface\nfrom perplexity.vocabulary import Vocabulary\nfrom perplexity.world_registry import register_world\n\n\n# The Vocabulary object will eventually be where all of the \n# functions that implement the MRS predications get registered\n# Is just an initial object since we have none\nvocabulary = Vocabulary()\n\n\n# Called to initialize or reset the micro-world state\ndef reset():\n    return State([])\n\n\n# Creates the micro-world interface on startup\n# or if the user loads the world later\ndef ui():\n    ui = UserInterface(world_name=&quot;SimplestExample&quot;,\n                       reset_function=reset,\n                       vocabulary=vocabulary)\n    return ui\n\n\n# Worlds need to be registered so the user can switch between them by name\n# and so that the engine can search for their autocorrect and other cached files\n# in the same directory where the ui() function resides\nregister_world(world_name=&quot;SimplestExample&quot;,\n               module=&quot;hello_world&quot;,\n               ui_function=&quot;ui&quot;)\n\n\nif __name__ == &#x27;__main__&#x27;:\n    user_interface = ui()\n    while user_interface:\n        # The loop might return a different user interface\n        # object if the user changes worlds\n        user_interface = user_interface.default_loop()\n\nThe basics are described in comments above, but the basic flow is: \nA micro-world gets registered with a name (\"SimplestExample\") and a pointer to the module and function where the system can create its UserInterface object to run it.\n\nIn __main__, this UserInterface object is created and run in a loop.  Each iteration of the loop processes one phrase from the user.\n\nThe state of the world is encapsulated, in whatever form the developer wants, in the object that is returned by the reset function (reset()).\nThat's it! All of these objects will be described more as we go through the tutorial.\nTo run this:\nCreate a hello_world directory in the Perplexity project\n\nCreate a hello_world.py file in that directory with the code above\n\nFrom within the hello_world directory, run: python ./hello_world.py\n\n[Note: As always, you will need to have your environment activated as described in the Installing Perplexity topic to successfully run]\nYou'll get something like this:\npython ./hello_world.py\n? Hello!\nI don&#x27;t know the words: Hi, Hi!\n\n? Where am I?\nI don&#x27;t know the words: I, Where\n\nSo far, it has no vocabulary so it will just keep saying, \"I don't know the words...\" to any phrases typed until we implement some. That's what the remainder of the tutorial is about.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Hello World", "teaser":"Hello World\nThe simplest Perplexity application is:\nfrom perplexity.state import State\nfrom perplexity.user_interface import UserInterface\nfrom perple ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo020ImplementAPredication", "excerpt":"Implementing a Predication\nRecall from the conceptual topic on backtracking that Perplexity interprets a phrase by:\nConverting the phrase to an MRS document\n\nCreating a scope-resolved mrs from the MRS document\n\nUsing backtracking to walk the tree and find values for the variables that make the MRS true\n\nUsing that approach, the phrase \"A file is large.\" creates this MRS and tree (among others):\n[ &quot;a file is large&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ _a_q&lt;0:1&gt; LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n          [ _file_n_of&lt;2:6&gt; LBL: h7 ARG0: x3 ARG1: i8 ]\n          [ _large_a_1&lt;10:15&gt; LBL: h1 ARG0: e2 ARG1: x3 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\n\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _file_n_of(x3,i8)\n_a_q(x3,RSTR,BODY)\n               \u2514\u2500 _large_a_1(e2,x3)\n\nAs described in the backtracking section, the backtracking solver maps each predication in the tree to a Python function and does a depth-first traversal of the tree. A State object is used to track the current value of all MRS variables (such as x3) as the solver goes through this process. At a given point in the traversal, the State object always has the current value of all MRS variables and any other current state the application needs to do its own work. Each program that uses Perplexity derives an object from State to allow predications to interact with the application.\nThe rest of this section describes how to write these predication functions and how to interact with the State object.\nPredication Function Arguments\nPerplexity comes preinstalled and configured to use the DELPH-IN English grammar, which is called the \"English Resource Grammar\" or \"ERG\".  You can see from the MRS document in the above example that the ERG predication generated for \"file\" is:\n_file_n_of(x3,i8)\n\nPerplexity uses the Vocabulary object to map this to a Python function that can be called. All predication Python functions have the same two initial arguments: context and state, followed by arguments that represent the predication arguments, x3 and i8 in this case.  So, the Python implementation of _file_n_of looks like this:\ndef file_n_of(context, state, x_binding, i_binding):\n   ...\n\ncontext represents the current point in the tree traversal and can be called to report errors or manually traverse the tree farther.  We'll see that used later. Think of it as holding useful helper functions you might need.\nstate is the State object described above that represents the state of the world when the predication is called. It holds, among other things, the current value of all the MRS variables at this point in the solver backtracking process.  Because of backtracking, the same predication can be called many times with different states as the solver attempts to find a solution to the MRS. \nx_binding and i_binding hold all the information about the MRS variables that _file_n_of uses. These are VariableBinding objects and have properties like x_binding.variable.name that will return the MRS variable name (x3 or i8 in this example), as well as their current value (x_binding.value) from the state object. \nPredication Success\nRecall from the section on backtracking that the job of a predication is to be true when its arguments \"are set to values that are (or mean) what the predication means\".  So, file_n_of should be true if x_binding and i_binding have values that mean \"file\" in the world it is implementing.\nPredication functions must be Python generator functions so they can return multiple values iteratively by calling the Python yield operator (we'll see this used next). true is indicated by yielding the state object, as is, to indicate that this predication is true for the current state of the arguments. false is indicated by calling Python return directly -- i.e. returning without yielding anything.\nHere's a simple example: Let's say we are building an interface to a program that has one file in it, called file1.txt. We could implement file_n_of like this:\ndef file_n_of(context, state, x_binding, i_binding):\n    if x_binding.value is not None and len(x_binding.value) == 1 and x_binding.value[0] == &quot;file1.txt&quot;:\n        yield state\n\nNote that i_binding is ignored since i variables usually indicate an ignored (or 'dropped') argument as described in the section on MRS.\nThe code illustrates that bindings have a binding.value property that returns the current variable's value, which is always a list for reasons described in the Together conceptual topic . So, this function retrieves the first item in the list and checks to see if it is the one file we have in our world. That is the only time this will be true since that is all we have. If so, it yields the state object to indicate that this predication is true for the current state of its variables. The state object is just yielded, as is, since we are just checking if the values passed in are a \"file\" and not changing anything. \nPredications will often be called with all of their variables bound like this. But, recall from the section on The Predication Contract that sometimes the engine will be looking for the function to provide a list of all file_n objects as opposed to checking if a particular object is a file. It indicates this by leaving one or more variables \"unbound\", which is when: binding.value is None.  This indicates to the function that it should yield all the things in the world that are a file, like this:\ndef file_n_of(context, state, x_binding, i_binding):\n    if x_binding.value is None:\n        yield state.set_x(x_binding.variable.name, (&quot;file1.txt&quot;, ))\n    elif len(x_binding.value) == 1 and x_binding.value[0] == &quot;file1.txt&quot;:\n        yield state\n\n[Note that sets are represented as a Python tuple, and Python tuples require single element tuples to have a trailing ,, so returning a single item tuple is done like this: (\"file1.txt, )]\nx_binding.value being None means that the MRS variable x3 is unbound (not set to anything). When a variable is unbound, the predication needs to yield all the the variable assignments that could make it true -- which in this case is just one: \"file1.txt\". It does this by setting the variable in the state object and yielding it.\nNote that the state object is immutable, meaning that it cannot be changed directly.  Instead, when methods like state.set_x() are called, the method returns a copy of the object with only the change the method accomplished. That's why the function yields like this: yield state.set_x(...) -- it needs to yield the copy with changes in it.\nSince our world only has one file in it, we've just hard-coded it here. Obviously the code would be more complicated in a real example.\nPredication Failure\nIf the predication is called with variable values that make it false, it simply returns without yielding. However, it needs to register an error first so we can report something to the user. Reporting errors is done by calling context.report_error() and passing it a list. The list names the error and includes any other information needed to build a message for the user, like this:\ndef file_n_of(context, state, x_binding, i_binding):\n    if x_binding.value is None:\n        yield state.set_x(x_binding.variable.name, (&quot;file1.txt&quot;,))\n    elif len(x_binding.value) == 1 and x_binding.value[0] == &quot;file1.txt&quot;:\n        yield state\n    else:\n        report_error([&quot;notAThing&quot;, x_binding.value, x_binding.variable.name])\n        return False\n\nErrors are reported as a list and here we've created a custom notAThing error to show how it is done. To create a custom error, we pick a string to represent it like \"notAThing\", and include all the information we'll need later to generate a nice text string for the user. In this case, we provide x_binding.value as its first argument, which will be some non-file object like \"folder1\". The second argument is x_binding.variable.name, which is the name of the variable: x3. Perplexity has functions that can convert variable names like x3 to their actual words like \"a file\". So, passing the variable name is a way of not hard-coding the predication name and allowing the system to generate richer errors. This is described more in the Converting Variables to English topic, and the mechanics of it is shown next.\nConverting Errors to Messages\nIf the error returned is a system error, the system will convert it to a message for the user.  If we have custom errors like \"notAThing\", we need to create a function that converts the custom error information to messages and pass that function as an additional argument to the UserInterface object, like this:\n...\n\ndef ui():\n    ui = UserInterface(world_name=&quot;SimplestExample&quot;,\n                       reset_function=reset,\n                       vocabulary=vocabulary,\n                       message_function=generate_custom_message)\n    return ui\n\n\n# Generates all the responses that predications can\n# return when an error occurs\ndef generate_custom_message(state, tree_info, error_term):\n    # See if the system can handle converting the error\n    # to a message first\n    system_message = perplexity.messages.generate_message(state, tree_info, error_term)\n    if system_message is not None:\n        return system_message\n    \n    else:\n        # error_term is of the form: [index, error] where &quot;error&quot; is another\n        # list like: [&quot;name&quot;, arg1, arg2, ...]. The first item is the error\n        # constant (i.e. its name). What the args mean depends on the error\n        error_predicate_index = error_term[0]\n        error_arguments = error_term[1]\n        error_constant = error_arguments[0] if error_arguments is not None else &quot;no error set&quot;\n        arg_length = len(error_arguments) if error_arguments is not None else 0\n        arg1 = error_arguments[1] if arg_length &gt; 1 else None\n        arg2 = error_arguments[2] if arg_length &gt; 2 else None\n        arg3 = error_arguments[3] if arg_length &gt; 3 else None\n        arg4 = error_arguments[4] if arg_length &gt; 4 else None\n    \n        if error_constant == &quot;notAThing&quot;:\n            # s() acts like a Python &quot;f string&quot; but also\n            # converts a variable name like &#x27;x3&#x27; into the english words\n            # that it represented in the MRS. The &quot;*&quot; in {*arg1} tells\n            # it to use the value of arg1 directly without converting it \n            # (described below)\n            return s(&quot;{*arg1} is not {arg2}&quot;, tree_info)\n    \n        else:\n            # No custom message, just return the raw error for debugging\n            return str(error_term)\n\n\nYou can use whatever logic you want for converting the error code to a string, this is just an example. Note the use of the s-string function s():\nreturn s(&quot;{*arg1} is not {arg2}&quot;, tree_info)\n\n... This is how a variable name like x3 gets converted to a string like \"file\". S-strings are a Perplexity feature described in a separate topic.  \nThe logic Perplexity uses for reporting errors is not obvious, it is worth reading the section on errors to understand how it works.\nVariables are a Tuple\nRecall from the Together conceptual topic that Perplexity represents items operating together as a set (represented as a tuple in Python). Because users of the system may ask questions like, \"Are the files 20 mb?\" (meaning are they 20mb together), predications need to be prepared to deal with variables that have a set of more than one item. Let's update the file_n_of() function to handle this case.\nAssume we have two more files in our example, so that now we have: file1.txt, file2.txt and file3.txt. There is no extra meaning for files \"together\" vs. files \"separately\" as far as being files: they are still just \"files\".  So, we only have to change the logic to loop through the list and make sure they are all files. However, if the x variable is unbound, we need to yield all combinations of files since any combination of them could make this predication true, like this:\ndef file_n_of(context, state, x_binding, i_binding):\n    if x_binding.value is None:\n        # Yield all combinations of files in the system\n        yield state.set_x(x_binding.variable.name, (&quot;file1.txt&quot;,))\n        yield state.set_x(x_binding.variable.name, (&quot;file2.txt&quot;,))\n        yield state.set_x(x_binding.variable.name, (&quot;file3.txt&quot;,))\n        yield state.set_x(x_binding.variable.name, (&quot;file1.txt&quot;,&quot;file2.txt&quot;))\n        yield state.set_x(x_binding.variable.name, (&quot;file1.txt&quot;,&quot;file3.txt&quot;))\n        yield state.set_x(x_binding.variable.name, (&quot;file2.txt&quot;,&quot;file3.txt&quot;))\n        yield state.set_x(x_binding.variable.name, (&quot;file1.txt&quot;,&quot;file2.txt&quot;,&quot;file3.txt&quot;))\n        \n    else:\n        for item in x_binding.value:\n            if item not in [&quot;file1.txt&quot;, &quot;file2.txt&quot;, &quot;file3.txt&quot;]\n                context.report_error([&quot;notAThing&quot;, x_binding.value, x_binding.variable.name])\n                return False\n        yield state\n\nManually returning all combinations of a set like this can get complicated and obviously won't work if you don't know the set ahead of time. To make this easier, Perplexity provides a helper function called combinatorial_predication_1 that does it for you. The _1 means it is only appropriate for predications with one x argument. \nTo use this function, you provide it two functions and then let the helper work out all the combinations, like this:\ndef file_n_of(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if value in [&quot;file1.txt&quot;, &quot;file2.txt&quot;, &quot;file3.txt&quot;]:\n            return True\n        else:\n            context.report_error([&quot;notAThing&quot;, x_binding.value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield &quot;file1.txt&quot;\n        yield &quot;file2.txt&quot;\n        yield &quot;file3.txt&quot;\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\nThe bound_variable() function only needs to implement the logic to check if a single value is a file and report an error if not. The helper does the work of iterating through the set and calling the function to see if each element is a file. \nThe unbound_variable() function only needs to yield each item that is a file and the system handles yielding all the combinations.\nNote that there are several optimizations the system does to avoid having to do the most brute force approach shown above, and the helper handles them all automatically.\nAdding Predications to the Vocabulary\nThe final step in creating a predication is to register the function as part of the vocabulary and indicate which ERG predication it maps to. This is done using Python \"decorators\" which are really just special functions you can use to label other functions. They are preceded by @, like this:\n@Predication(vocabulary, names=[&quot;_file_n_of&quot;])\ndef file_n_of(context, state, x_binding, i_binding):\n    ...\n\nThe first argument to @Predication is the Vocabulary object that the program wants to register the predication in, and names=[] provides a list of all the predication names (in case some are synonyms) that should use this function.\nNote that Perplexity requires that the function have the right number of arguments for the predications listed in names=[], that the names of the function arguments start with the arguments type (like x- or i-) and that those types match the types of all predications listed.\nWith that, the system can now recognize that the function exists and know which ERG predication(s) to map it to.\nImplementing \"large\"\nLet's finish by implementing the predication for \"large\" (_large_a_1(e2, x3) from the MRS above) so we can see the system process \"a file is large\".\nJust like file_n_of, _large_a_1(e2, x3) has a single x variable, so we can copy the approach above to implement it. For now, we can just ignore the event variable e2, we'll describe how to handle that in the Event Predications topic later.\nWe'll implement large by making it be true only for \"file2.txt\" to simulate that being the only \"large thing\" in the system:\n@Predication(vocabulary, names=[&quot;_large_a_1&quot;])\ndef large_a_1(context, state, e_introduced_binding, x_target_binding):\n    def criteria_bound(value):\n        if value == &quot;file2.txt&quot;:\n            return True\n\n        else:\n            context.report_error([&quot;adjectiveDoesntApply&quot;, &quot;large&quot;, x_target_binding.variable.name])\n            return False\n\n    def unbound_values():\n        # Find all large things\n        yield &quot;file2.txt&quot;\n\n    yield from combinatorial_predication_1(context,\n                                           state, \n                                           x_target_binding, \n                                           criteria_bound,\n                                           unbound_values)\n\nOnce the implementation of large_a_1 and file_n_of are added to hello_world.py, we can now run hello_world.py and get this:\npython ./hello_world.py\n? a file is large\nI don&#x27;t know the words: a\n\nWe dont yet have an implementation for the word \"a\".  You can see that this is required by typing /show. Perplexity will then output the MRS, tree, and other debugging information:\n? a file is large\nI don&#x27;t know the words: a\n\n? /show\nUser Input: a file is large\n1 Parses\n\n***** CHOSEN Parse #0:\nSentence Force: prop\n[ &quot;a file is large&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ _a_q&lt;0:1&gt; LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n          [ _file_n_of&lt;2:6&gt; LBL: h7 ARG0: x3 ARG1: i8 ]\n          [ _large_a_1&lt;10:15&gt; LBL: h1 ARG0: e2 ARG1: x3 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\n-- CHOSEN Parse #0, CHOSEN Tree #0: \n\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _file_n_of(x3,i8)\n_a_q(x3,RSTR,BODY)\n               \u2514\u2500 _large_a_1(e2,x3)\n\nText Tree: _a_q(x3,_file_n_of(x3,i8),_large_a_1(e2,x3))\n\nInterpretation: None\nError: (0, [&#x27;unknownWords&#x27;, [(&#x27;_a_q&#x27;, [&#x27;x&#x27;, &#x27;h&#x27;, &#x27;h&#x27;], &#x27;prop&#x27;, False, &#x27;a&#x27;)]], 0)\nResponse:\nI don&#x27;t know the words: a\n\nLuckily, Perplexity provides many built-in predication implementations that you can load by calling the system_vocabulary() helper instead of starting with an empty Vocabulary object.  This will return a vocabulary object already filled with the built-in perplexity predications:\n# Instead of vocabulary = Vocabulary() call this:\nvocabulary = system_vocabulary()\n\nRunning after that change yields this:\npython ./hello_world.py\n? a file is large\nYes, that is true.\n\n? which file is large?\n(&#x27;file2.txt&#x27;,) \n\n(Note that Perplexity also provided the predication which_q which was needed for the second phrase)\nPerplexity has built-in logic for responding to propositions like \"a file is large\" and for answering questions like \"which file is large?\" automatically. So, by implementing just file_n_of and large_a_1, we can already start processing a few phrases.\nBelow is the full source for the predications we've gone through above. Next up, we'll handle a few more kinds of predications.\nExample Full Source\nThe full source for the example is now:\nfrom perplexity.predications import combinatorial_predication_1\nfrom perplexity.state import State\nfrom perplexity.system_vocabulary import system_vocabulary\nfrom perplexity.user_interface import UserInterface\nfrom perplexity.vocabulary import Predication\nfrom perplexity.world_registry import register_world\nimport perplexity.messages\n\n\nvocabulary = system_vocabulary()\n\n\n@Predication(vocabulary, names=[&quot;_file_n_of&quot;])\ndef file_n_of(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if value in [&quot;file1.txt&quot;, &quot;file2.txt&quot;, &quot;file3.txt&quot;]:\n            return True\n        else:\n            context.report_error([&quot;notAThing&quot;, x_binding.value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield &quot;file1.txt&quot;\n        yield &quot;file2.txt&quot;\n        yield &quot;file3.txt&quot;\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\n\n@Predication(vocabulary, names=[&quot;_large_a_1&quot;])\ndef large_a_1(context, state, e_introduced_binding, x_target_binding):\n    def criteria_bound(value):\n        if value == &quot;file2.txt&quot;:\n            return True\n\n        else:\n            context.report_error([&quot;adjectiveDoesntApply&quot;, &quot;large&quot;, x_target_binding.variable.name])\n            return False\n\n    def unbound_values():\n        # Find all large things\n        yield &quot;file2.txt&quot;\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_target_binding,\n                                           criteria_bound,\n                                           unbound_values)\n\n\n# Called to initialize or reset the micro-world state\ndef reset():\n    return State([])\n\n\n# Creates the micro-world interface on startup\n# or if the user loads the world later\ndef ui():\n    ui = UserInterface(world_name=&quot;SimplestExample&quot;,\n                       reset_function=reset,\n                       vocabulary=vocabulary)\n    return ui\n\n\n# Generates all the responses that predications can\n# return when an error occurs\ndef generate_custom_message(state, tree_info, error_term):\n    # See if the system can handle converting the error\n    # to a message first\n    system_message = perplexity.messages.generate_message(state, tree_info, error_term)\n    if system_message is not None:\n        return system_message\n\n    else:\n        # error_term is of the form: [index, error] where &quot;error&quot; is another\n        # list like: [&quot;name&quot;, arg1, arg2, ...]. The first item is the error\n        # constant (i.e. its name). What the args mean depends on the error\n        error_predicate_index = error_term[0]\n        error_arguments = error_term[1]\n        error_constant = error_arguments[0] if error_arguments is not None else &quot;no error set&quot;\n        arg_length = len(error_arguments) if error_arguments is not None else 0\n        arg1 = error_arguments[1] if arg_length &gt; 1 else None\n        arg2 = error_arguments[2] if arg_length &gt; 2 else None\n        arg3 = error_arguments[3] if arg_length &gt; 3 else None\n        arg4 = error_arguments[4] if arg_length &gt; 4 else None\n\n        if error_constant == &quot;notAThing&quot;:\n            # s() acts like a Python &quot;f string&quot; but also\n            # converts a variable name like &#x27;x3&#x27; into the english words\n            # that it represented in the MRS. The &quot;*&quot; in {*arg1} tells\n            # it to use the value of arg1 directly without converting it\n            # (described below)\n            return s(&quot;{*arg1} is not {arg2}&quot;, tree_info)\n\n        else:\n            # No custom message, just return the raw error for debugging\n            return str(error_term)\n\n\n# Worlds need to be registered so the user can switch between them by name\n# and so that the engine can search for their autocorrect and other cached files\n# in the same directory where the ui() function resides\nregister_world(world_name=&quot;SimplestExample&quot;,\n               module=&quot;hello_world_simplest&quot;,\n               ui_function=&quot;ui&quot;)\n\n\nif __name__ == &#x27;__main__&#x27;:\n    user_interface = ui()\n    while user_interface:\n        # The loop might return a different user interface\n        # object if the user changes worlds\n        user_interface = user_interface.default_loop()\n\nComprehensive source for the completed tutorial is available here\n\n", "title":"Implementing a Predication", "teaser":"Implementing a Predication\nRecall from the conceptual topic on backtracking that Perplexity interprets a phrase by:\nConverting the phrase to an MRS do ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo022Testing", "excerpt":"Testing\nNow that we have implemented a predication, it is important to understand how to test it.  In a Perplexity application, it is very easy to enhance a predication to support one scenario and break others that used to work. So, to keep the system working well and avoid functionality regressions, you should always write at least simple functionality tests for phrases once they work.\nSince the interface to a Perplexity system is textual user input, and the output is also text, the built-in Perplexity test functionality just records the output that you expect for a given phrase when it is working properly. Then, you can run the test again when you've changed something and it will tell you if the expected output has changed.\nRecording a test\nYou can see all the commands (even beyond testing) that Perplexity supports by typing \"/help\":\n? /help\n\nCommands start with /:\n\n****** General ******\n/help Get list of commands -&gt; e.g. /help\n/r Repeat the last phrase -&gt; e.g. /r\n/s Repeat the last system command (i.e. the /command) -&gt; e.g. /s\n/new Calls the passed function to get the new state to use -&gt; e.g. /new examples.Example18_reset\n/reset Resets to the initial state -&gt; e.g. /reset\n/save Saves the current world state to the ./data/default directory. If given a path, saves to that path instead. -&gt; e.g. /save\n/load Loads the current world state from the ./data/default directory. If given a path, loads from that path instead. -&gt; e.g. /load\n/timeout Sets timeout time for a given phrase -&gt; e.g. /timeout or /timeout 20\n\n****** Parsing ******\n/show Shows tracing information from last command. Add &#x27;all&#x27; to see all interpretations, 1 to see only first scope-resolved MRSs -&gt; e.g. /show or /show all or /show all, 1\n/soln Retrieves all solutions when parsing so they can be shown with /show. Add &#x27;all&#x27; to see all solutions, anything else toggles the current setting -&gt; e.g. /soln or /soln all\n/genall Generates all parses (normally only the first 5 are generated) -&gt; e.g. /genall 1 OR /genall True\n/runall Runs all parses, doesn&#x27;t stop after success -&gt; e.g. /runall 1 OR /runall True\n/runparse Only runs the identified parse index and optional scope-resolved MRS index. Pass no arguments to turn off -&gt; e.g. /runparse 1 OR /runparse 1, 0\n/debugtree Shows tracing information about the scope-resolved MRS. give a predication query after to only show scope-resolved MRSs that match it. Use &#x27;_&#x27; to mean &#x27;anything&#x27; for an argument or the predication name -&gt; e.g. /debugtree OR /debugtree which(x,h,h) OR /debugtree _(e,x,_,h)\n/debugmrs Shows tracing information about the mrs -&gt; e.g. /debugmrs\n/findmrs ? -&gt; e.g. /findmrs\n\n****** Testing ******\n/recordtest Starts recording a test. Finish with /createtest or /appendtest -&gt; e.g. /record\n/createtest Creates a test using name you specify based on the interactions recorded by /record -&gt; e.g. /createtest Foo\n/appendtest Appends the interactions recorded by /record to an existing test -&gt; e.g. /appendtest Foo\n/runtest Runs a test -&gt; e.g. /runtest subdirectory/foo\n/resolvetests Resolves all the test results stored in &#x27;testresults.txt&#x27; -&gt; e.g. /resolvetests\n/logtests Logs test results to the file &#x27;testresults.txt&#x27; -&gt; e.g. /logtests true\n/runfolder Runs all tests in a directory or directories. use &#x27;.&#x27; to run folders in the root -&gt; e.g. /runfolder foldername or /runfolder a, b, c\n/resume Resume running the last test (or sequence of tests in a folder) at the last reset before it was stopped -&gt; e.g. /resume\n\nLet's start by recording a test using the /recordtest command and by running the code we've done so far:\n? /recordtest\nRecording is now True\n\n? a file is large\nYes, that is true.\nRecorded (1 items).\n\n? which file is large?\n(File(name=/Desktop/file2.txt, size=10000000),)\nRecorded (1 items).\n\nYou can see that the system is recording each interaction by the text Recorded (1 items). at the end of the interaction.  Perplexity will keep gathering all the commands until you are done. Then you can create a test like this:\n? /createtest test1\nCreated test &#x27;test1&#x27;\nRecording is now off\n\nThis creates a test called \"test1\" and stops recording.  Tests are simply JSON files that are stored in /perplexity/tests.  If you open the file, you'll see:\n{\n    &quot;WorldName&quot;: &quot;SimplestFileSystemStateExample&quot;,\n    &quot;TestItems&quot;: [\n        {\n            &quot;Command&quot;: &quot;a file is large&quot;,\n            &quot;Expected&quot;: &quot;Yes, that is true.&quot;,\n            &quot;Tree&quot;: &quot;_a_q(x3,_file_n_of(x3,i8),_large_a_1(e2,x3))&quot;,\n            &quot;Enabled&quot;: true,\n            &quot;ID&quot;: &quot;aa9b1bbc-1939-4065-bd80-5b8aeb922076&quot;\n        },\n        {\n            &quot;Command&quot;: &quot;which file is large?&quot;,\n            &quot;Expected&quot;: &quot;(File(name=/Desktop/file2.txt, size=10000000),)&quot;,\n            &quot;Tree&quot;: &quot;_which_q(x3,_file_n_of(x3,i8),_large_a_1(e2,x3))&quot;,\n            &quot;Enabled&quot;: true,\n            &quot;ID&quot;: &quot;a75503d7-fc49-4369-9cc8-bb159afc2d29&quot;\n        }\n    ]\n}\n\nThe system is simply recording the input, output, the scope-resolved MRS that was used, and an ID.  There is also an \"Enabled\" field that you can set to \"false\" if you want a particular test to be ignored.\nTo run the test:\n? /runtest test1\n**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...\n\n\n**** Begin Testing...\n\n**** Writing LastTest: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...\n\n\nTest: a file is large\nYes, that is true.\n\nTest: which file is large?\n(File(name=/Desktop/file2.txt, size=10000000),)\n\n**** Testing Complete. Elapsed time: 1.74585\n\nIt all looks good because nothing changed. But let's change file_n_of to return a different file name:\ndef file_n_of(context, state, x_binding, i_binding):\n    if x_binding.value is None:\n#        yield state.set_x(x_binding.variable.name, (&quot;file1.txt&quot;,))\n        yield state.set_x(x_binding.variable.name, (&quot;file2.txt&quot;,))\n    elif len(x_binding.value) == 1 and x_binding.value[0] == &quot;file1.txt&quot;:\n        yield state\n    else:\n        report_error([&quot;notAThing&quot;, x_binding.value, x_binding.variable.name])\n        return False\n\n... and run the test again:\n? /runtest test1\n**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...\n\n\n**** Begin Testing...\n\n**** Writing LastTest: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...\n\n\nTest: a file is large\nYes, that is true.\n\nTest: which file is large?\n(File(name=/documents/file1.txt, size=10000000),)\n\nExpected: \n(File(name=/Desktop/file2.txt, size=10000000),)\n(&lt;enter&gt;)ignore, (b)reak to end testing, (u)pdate test, (a) add alternative correct result, (d)isable test\n\nPerplexity notices the output changed and tells you what it expected. Now you have to decide what to do about it:\nMaybe you meant to do the change. Press \"u\" to update the test to use this new output as the expected output\n\nMaybe you want to ignore it for now, press \"enter\"\n\nSometimes a phrase might have multiple good answers, you can add this as an alternative using \"a\"\n\nIf you want to disable the test push \"d\"\n\nYou stop the test by pushing \"b\"\n\nUpdating tests\nTests usually grow over time. To do this, you can record some more interactions and use the /appendtest command:\n? /recordtest\nRecording is now True\n\n? is a file large?\nYes.\nRecorded (1 items).\n\n? /appendtest test1\nRecording is now off\n\n? /runtest test1\n**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...\n\n\n**** Begin Testing...\n\n**** Writing LastTest: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...\n\n\nTest: a file is large\nYes, that is true.\n\nTest: which file is large?\n(File(name=/Desktop/file2.txt, size=10000000),)\n\nTest: is a file large?\nYes.\n\n**** Testing Complete. Elapsed time: 2.01737\n\n/appendtest simply adds these new interactions to the end of the test. You can see that, when it is run, the whole sequence gets run.\nResetting State\nOften your tests will end up manipulating the state of the world and you'll want to reset it to try alternatives. You can do this with the /reset command. You give it the module.function_name of your reset function, like this:\n? /reset hello_world.hello_world_FileSystemState.reset\nState reset using hello_world_FileSystemState.reset().\n\nRecorded (1 items).\n\n? /appendtest test1\nRecording is now off\n\n(You'll need to use the module and function name that you've used to successfully run the example above.)\nSince we used /appendtest the session, the reset will now happen at the end of the test. This might be fine if we're going to add more interactions that we want to happen in a fresh world. But it is also a best practice to always start your tests with a reset so you know the world is starting in a known state.  You can simply edit the file and move that reset to the beginning.  It is just a JSON file. Here's what it looks like when finished:\n{\n    &quot;WorldName&quot;: &quot;SimplestFileSystemStateExample&quot;,\n    &quot;TestItems&quot;: [\n        {\n            &quot;Command&quot;: &quot;/reset hello_world.hello_world_FileSystemState.reset&quot;,\n            &quot;Expected&quot;: &quot;&quot;,\n            &quot;Tree&quot;: &quot;None&quot;,\n            &quot;Enabled&quot;: true,\n            &quot;ID&quot;: &quot;455b3e38-cf6e-4ee0-9767-6197f47bd586&quot;\n        },\n        {\n            &quot;Command&quot;: &quot;a file is large&quot;,\n            &quot;Expected&quot;: &quot;Yes, that is true.&quot;,\n            &quot;Tree&quot;: &quot;_a_q(x3,_file_n_of(x3,i8),_large_a_1(e2,x3))&quot;,\n            &quot;Enabled&quot;: true,\n            &quot;ID&quot;: &quot;aa9b1bbc-1939-4065-bd80-5b8aeb922076&quot;\n        },\n        {\n            &quot;Command&quot;: &quot;which file is large?&quot;,\n            &quot;Expected&quot;: &quot;(File(name=/Desktop/file2.txt, size=10000000),)&quot;,\n            &quot;Tree&quot;: &quot;_which_q(x3,_file_n_of(x3,i8),_large_a_1(e2,x3))&quot;,\n            &quot;Enabled&quot;: true,\n            &quot;ID&quot;: &quot;a75503d7-fc49-4369-9cc8-bb159afc2d29&quot;\n        },\n        {\n            &quot;Command&quot;: &quot;is a file large?&quot;,\n            &quot;Expected&quot;: &quot;Yes.&quot;,\n            &quot;Tree&quot;: &quot;_a_q(x3,_file_n_of(x3,i8),_large_a_1(e2,x3))&quot;,\n            &quot;Enabled&quot;: true,\n            &quot;ID&quot;: &quot;158d0487-a8c6-49ee-b01c-0a861a80d4ce&quot;\n        }\n    ]\n}\n\nAnd now when we run it, you can see the reset happening at the beginning:\n? /runtest test1\n**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...\n\n\n**** Begin Testing...\n\n**** Writing LastTest: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...\n\n\nTest: /reset hello_world.hello_world_FileSystemState.reset\nState reset using hello_world.hello_world_FileSystemState.reset().\n\n\nTest: a file is large\nYes, that is true.\n\nTest: which file is large?\n(File(name=/Desktop/file2.txt, size=10000000),)\n\nTest: is a file large?\nYes.\n\n**** Testing Complete. Elapsed time: 2.12325\n\nYou can feel free to rearrange and edit the information in these test files, as long as you don't break the JSON format.\nFolders\n\"test1.tst\" was created in the /perplexity/tests folder since just the name test1 was used in /createtest and /appendtest. You can also organize your tests using folders:\n/createtest myfolder/test2: creates a /perplexity/tests/myfolder folder and puts your test there.\n\n/runtest myfolder/test2: runs the test in that folder.\n\n/appendtest myfolder/test2: appends to it.\n\netc.\nYou can also run all the tests in a folder like this:\n/runfolder myfolder\nStopping and Resuming a Test\nWhen a test breaks, you will often hit \"b\" to stop it, go fix it, and want to see if you fixed it. Sometimes you'd like to just restart where the break happened, especially if it is a long test.  You do this with the /resume command. If you type that command, Perplexity will resume the test starting with the most recent reset command. It does this because starting right where things broke might put the state in a different configuration. Restarting at the reset point ensures the state gets built up properly.\nDue to this, it is always good to put resets into your test as you test different scenarios so you can /resume and get back to it more quickly and not have to start from the beginning.\nNote that this also works for /runfolder.  You might have stopped at the tenth test in that folder, but /resume will start at that same place and skip the first 9 folders.\nAlso note that the test location is recorded on disk. So you can shut down your computer and come back and it will still resume in the right place.\nLogging Tests\nSometimes you can't sit there and watch the test run so you can skip or update tests that changed. You'd like to run the whole thing and then see what all the failures were when it is all done.  To do this, you run /logtests before running a test or a folder. Perplexity will then record all the failures in a file called /perplexity/testresults.txt. You could look at this file to see what happened, but a better way is to run /resolvetests. This will run you through the same interaction you would have had by just running interactively, but only on the failures.  If we redo the previous example where we intentionally broke a test, we'd get:\n? /logtests\nLog Test Results is now True\n\n? /runtest test1\n**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...\n\nLogging test results to: /Users/ericzinda/Enlistments/Perplexity/perplexity/testresults.txt\n\n**** Begin Testing...\n\n**** Writing LastTest: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...\n\n\nTest: /reset hello_world.hello_world_FileSystemState.reset\nState reset using hello_world.hello_world_FileSystemState.reset().\n\n\nTest: a file is large\nYes, that is true.\n\nTest: which file is large?\n(File(name=/documents/file1.txt, size=10000000),)\n\nTest: is a file large?\nYes.\n\n**** Testing Complete. Elapsed time: 2.53661\n\n? /resolvetests\nResolving test results in: /Users/ericzinda/Enlistments/Perplexity/perplexity/testresults.txt\n**** Running test: /Users/ericzinda/Enlistments/Perplexity/perplexity/tests/test1.tst...\n\n**** Test ID: a75503d7-fc49-4369-9cc8-bb159afc2d29\nwhich file is large?\n(File(name=/documents/file1.txt, size=10000000),)\n\nExpected: \n(File(name=/Desktop/file2.txt, size=10000000),)\n(&lt;enter&gt;)ignore, (b)reak to end testing, (u)pdate test, (a) add alternative correct result, (d)isable test\n\nYou can see that running the tests didn't say anything or stop when a test failed, but running /resolvetests allows you to figure out what the failure was and decide what to do with it.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Testing", "teaser":"Testing\nNow that we have implemented a predication, it is important to understand how to test it.  In a Perplexity application, it is very easy to enh ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo030InStylePredications", "excerpt":"In-Style Predications\nLogic gets more complicated when there is more than one x argument because there are many cases to handle. The ERG generates the following predication for \"in\" from \"a file is in a folder\":\n_in_p_loc(e1,x1,x2)\n\nIgnoring the event argument e2 for the moment, there are two x arguments. The predication's job is to check whether x1 is \"in\" x2 (whatever that means in the application). Because arguments are tuples that can have more than one value (described in the previous topic), the predication could be called with an argument that has two values, like this:\n_in_p_loc(e1,(file1, file2),(folder1, ))\n\n... which means \"file1 and file2 are in folder1 together\". For files, saying two files are in a folder \"together\" is no different than saying they are in a folder \"separately\". If file1 is in folder1 and file2 is in folder2, then they are both in there separately and together. Note that the meaning of \"in\" in this case also doesn't exclude someone saying \"together\" or \"separately\". It is perfectly fine to say \"Are file1 and file2 in folder2 together?\", it just doesn't add anything to the meaning.\nThis observation allows us to separately check the files like this:\ncheck: (file1,) in (folder1,)?\ncheck: (file2,) in (folder1,)?\n\nIf those are both true, then this must be too (without having to check) since \"in a folder together\" is the same as \"in a folder separatley\":\ncheck: (file1, file2) in (folder1,)?\n\nThis allows us to write a single function that can handle tuples of one or more items by simply implementing the one item case and calling it over and over.\nAs in the single x case from the previous topic, Perplexity has a helper function that performs the right logic and only requires the caller to implement the check() function for a single value, like this:\n@Predication(vocabulary, names=(&quot;_in_p_loc&quot;))\ndef in_p_loc(context, state, e_introduced_binding, x_actor_binding, x_location_binding):\n    def check_item_in_item(item1, item2):\n        return is_item_in_item(item1, item2)\n    \n    ...\n                                          \n    yield from in_style_predication_2(context,\n                                      state, \n                                      x_actor_binding, \n                                      x_location_binding, \n                                      check_item_in_item, \n                                      ...)\n\n[The example uses a placeholder function is_item_in_item(item1, item2) to do the checking since its logic is application specific.]\nThe function is called in_style_predication_2() because it uses the behavior of the word \"in\" as a template and has two x arguments.  Any predication that is like \"in\" (meaning that it doesn't have a different meaning for \"together\" or \"separately\" but is OK if they are said) can use this same helper to implement the logic efficiently.\nUnbound Arguments\nAs discussed in the previous topic, arguments to a predication aren't always set (i.e. bound) as in the above example. When they are missing, the predication needs to yield all possible values for them that make the predication true.  \nTo support unbound arguments, in_style_predication_2() has two additional functions it supports: one for the first argument being unbound and another for the second. There is a final argument that is rarely used for when both are unbound. If that one isn't set, the system reports the system error beMoreSpecific since the user said something really broad like \"what is in anything?\"\nPresumably the system we are building would have an efficient way to find \"things in something else\" (or vice versa) so the example below uses fake functions as placeholders:\n@Predication(vocabulary, names=(&quot;_in_p_loc&quot;))\ndef in_p_loc(context, state, e_introduced_binding, x_actor_binding, x_location_binding):\n    def check_item_in_item(item1, item2):\n        return is_item_in_item(item1, item2)\n    \n    def all_item1_in_item2(item2):\n        yield from all_contained_in(item2)\n\n    def all_item2_containing_item1(item1):\n        yield from all_containing(item1)\n\n    yield from in_style_predication_2(context, \n                                      state, \n                                      x_actor_binding, \n                                      x_location_binding, \n                                      check_item_in_item, \n                                      all_item1_in_item2, \n                                      all_item2_containing_item1)\n\nNote that the two new functions need to yield all alternatives and not just return true or false, just like combinatorial_style_predication_1() did in the previous topic. And, just like in that previous example, the helper function will generate all combinations if other predications in the tree need this.\nAnd, as with the first \"check\" function, in_style_predication_2() does all the work to make sure that the two unbound functions are only passed single values -- even if the incoming values are combinatorial or sets > 1 item.  \nComprehensive source for the completed tutorial is available here\n\n", "title":"In-Style Predications", "teaser":"In-Style Predications\nLogic gets more complicated when there is more than one x argument because there are many cases to handle. The ERG generates the ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo040LiftStylePredications", "excerpt":"Lift-Style Predications\nNot all words are associative with sets like \"in\" from the previous section: The verb \"to lift\" interprets sets vs. individuals as very different things.  For example:\nStudents lifted a table.\n\n...could mean: \nTwo students (together) lifted a table (at the same time)\n\nTwo students (separately) lifted a (different) table\n\nThis is a case where the prediction for \"lift\":\n_lift_v_cause(e1,x1,x2)\n\n... can't just check if each value of x1 is lifting a value in x2 and assume that means they are all also lifting separately or together.  Lifting together means something different, and thus, unlike \"in\", all combinations do need to be checked. There is a different helper that will do the logic for this scenario: lift_style_predication_2(). In contrast to in_style_predication_2(), the check functions need to be prepared for tuples with more than one item and check if they are working together.\nFor this example, we'll assume that \"Elsa\" and \"Seo-Yun\" are lifting \"table1\" together:\n@Predication(vocabulary, names=[&quot;_lift_v_cause&quot;])\ndef lift(context, state, e_introduced_binding, x_actor_binding, x_item_binding):\n    def check_items_lifting_items(item1, item2):\n        if item1 == (&quot;Elsa&quot;, &quot;Seo-Yun&quot;) and len(item2) == 1 and item2[0] == &quot;table1&quot;:\n            return True\n        else:\n            context.report_error([&quot;xIsNotYZ&quot;, x_actor_binding.variable.name, &quot;lifting&quot;, x_item_binding.variable.name])\n\n    def all_item1s_lifting_item2s(item2):\n        if len(item2) == 1 and item2[0] == &quot;table1&quot;:\n            yield (&quot;Elsa&quot;, &quot;Seo-Yun&quot;)\n\n    def all_item2s_being_lifted_by_item1s(item1):\n        if item1 == (&quot;Elsa&quot;, &quot;Seo-Yun&quot;):\n            yield (&quot;table1&quot;,)\n\n    yield from lift_style_predication_2(context,\n                                        state, \n                                        x_actor_binding, \n                                        x_item_binding,\n                                        check_items_lifting_items, \n                                        all_item1s_lifting_item2s,\n                                        all_item2s_being_lifted_by_item1s)\n\nSo, lift_style_predication_2() works very much like the in_style_predication_2() from the previous section but calls the check function with tuples instead of single values.\nDeclaring Arguments that Understand Tuples of More Than One Item\nAs written, however, these check functions will still only get called with a tuple containing a single item. That is because the helper functions won't go through the work to generate all combinations unless a predication declares that it will use a tuple of more than one item if provided. It's too expensive to calculate if it will be thrown away.  \nTo declare that lift() actually interprets meaning in tuples > 1 (and therefore wants them passed in), we declare which arguments semantically understand tuples of more than one by adding information to the @Predication declaration, like this:\n@Predication(vocabulary,\n             names=[&quot;_lift_v_cause&quot;],\n             arguments=[(&quot;e&quot;,), (&quot;x&quot;, ValueSize.all), (&quot;x&quot;, ValueSize.all)])\ndef lift(state, e_introduced_binding, x_actor_binding, x_item_binding):\n    ...\n\nAll the rest of the function is unchanged.\nAdding the arguments=[] list to @Predication() tells the engine that we want to override the defaults for arguments and declare them ourselves.  The default for all arguments is to only have single values since that is much faster.  Only predications which interpret meaning in larger tuples should ask for them. The declaration for lift asks for them by setting ValueSize.all on both x arguments.\nOther options for ValueSize are: exactly_one (the default) and more_than_one. more_than_one can be used when an argument only makes sense for more than one individual to be doing it. One example is the verb \"met\" when used like \"Shal and Vienna met\". You can't say \"Shal met\", it doesn't really make sense. So it will always require at least two individuals.\nRunning the Example\nAs is, we can't run the example, yet. We need to teach the system \"students\" and \"tables\" first.  This is easy enough using the approach we used in our first topic about files:\n@Predication(vocabulary, names=[&quot;_student_n_of&quot;])\ndef student_n_of(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if value in [&quot;Elsa&quot;, &quot;Seo-Yun&quot;]:\n            return True\n        else:\n            context.report_error([&quot;notAThing&quot;, x_binding.value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield &quot;Elsa&quot;\n        yield &quot;Seo-Yun&quot;\n\n    yield from combinatorial_predication_1(context, state, x_binding, bound_variable, unbound_variable)\n\n\n@Predication(vocabulary, names=[&quot;_table_n_1&quot;])\ndef table_n_1(context, state, x_binding):\n    def bound_variable(value):\n        if value in [&quot;table1&quot;]:\n            return True\n        else:\n            context.report_error([&quot;notAThing&quot;, x_binding.value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield &quot;table1&quot;\n\n    yield from combinatorial_predication_1(context, state, x_binding, bound_variable, unbound_variable)\n\nAdding those, plus the implementation of _lift_v_cause above, allows us to have this interaction:\npython ./hello_world.py\n? students are lifting a table\nYes, that is true.\n\n? a student is lifting a table\nThere are more than a student\n\n? which students are lifting the table\n(&#x27;Elsa&#x27;, &#x27;Seo-Yun&#x27;)\n\n? a student is large\na student is not large\n\nA few things to note:\nBecause we defined _lift_v_cause to only be true when both students are lifting the table, we get the (mangled) error, \"There are more than a student\". This is trying to say \"There is more than one student lifting a table\". We'll go through how to fix the English on these in a future topic.  We should probably add logic that allows either student lifting the table to be true as well.\nNote that we can also use world like \"large\" from previous scenarios and they do work correctly (since we haven't said either student is large in the system, it will just always fail).\nNext we will tackle event predications so that we can handle words like \"very\" and other modifiers.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Lift-Style Predications", "teaser":"Lift-Style Predications\nNot all words are associative with sets like \"in\" from the previous section: The verb \"to lift\" interprets sets vs. individual ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo050EventPredications", "excerpt":"Predications with Event Variables\nSo far, we have been conveniently ignoring event variables (variables that start with \"e\"). Where instance (x) variables contain a single set, event (e) variables are designed to build up a structure. They allow words like \"very\" and \"slowly\" to modify other words. \nFor example, we've been talking about a _large_a_1(e2,x3), _file_n_of(x3) and have ignored what the event variable e2 is for. We can't do this if we are trying to find a _very_x_deg(e2, e1), _large_a_1(e1,x3), _file_n_of(x3).\nIn an MRS, any predication except a quantifier is said to \"introduce\" its first argument. If you look closely, you'll see that every variable is only \"introduced\" by one predication in a given MRS -- only one predication has a given variable as its first argument.  So, in a sense, that variable represents that predication.  If a predication like _large_a_1(e2,x3) introduces event variable e2, it does so to provide a place for other predications to hang modifiers to it.\nFor example, to represent something that is \"very large\", the word \"very\" needs to be able to attach its \"veryness\" to \"large\". For \"very very large\", a chain is needed where the first \"very\" modifies the second, which modifies \"large\". This is all done with events, and it happens like this because human languages allow all kinds of chained constructions like this. DELPH-IN needed a way to model the behavior.\nHere are the predications generated for: \"very large\" and \"very very large\". A comma (\",\") is being used to indicate a conjunction (i.e. \"and\"):\n# Very large\n_very_x_deg(e2, e1), _large_a_1(e1,x3)\n\n# Very very large\n_very_x_deg(e3, e2), _very_x_deg(e2, e1), _large_a_1(e1,x3)\n\nYou can see that in \"very large\", _very_x_deg takes the event variable introduced by _large_a_1 as an argument. The job of _very_x_deg is to put something in that event that _large_a_1 can modify its behavior to be \"very large\". \n_very_x_deg also introduces its own event variable that other predications can modify as in \"very very large\". The first \"very\" modifies the event variable introduced by the second \"very\", etc.\nThis means, first, that we need a mechanism for handling event variables and, second, that our implementation of _large_a_1 needs to be modified to pay attention to modifications to its event.\nSince event variables need to be able to capture what could be a large buildup of modifications in a given sentence, Perplexity uses a dictionary for them. The State object passed to every predication has an add_to_e() method to allow predications to build up information on event variables.  So, add_to_e() has arguments that indicate what information to add to the event. However, just like set_x(),  add_to_e() returns a new state that must be yielded to indicate success. The State object is still immutable.\nThe add_to_e() method looks like this:\ndef add_to_e(self, event_name, key, value):\n    ...\n\nadd_to_e() adds the key and value to a dictionary that represents the event state and returns a new State object, just like set_x() does. But, unlike set_x(), it adds to whatever was in the event variable before instead of replacing it. This allows information to get built up in the event.\nUsing the add_to_e() method, let's create a _very_x_deg predication along with a _large_a_1 predication that pays attention to modifications to its event.\nLet's start with _very_x_deg:\n@Predication(vocabulary, names=[&quot;_very_x_deg&quot;])\ndef very_x_deg(context, state, e_introduced_binding, e_target_binding):\n    # We&#x27;ll interpret every &quot;very&quot; as meaning &quot;one order of magnitude larger&quot;\n    yield state.add_to_e(e_target_binding.variable.name,\n                         &quot;DegreeMultiplier&quot;,\n                         {&quot;Value&quot;: 10,\n                          &quot;Originator&quot;: context.current_predication_index()})\n\n_very_x_deg() doesn't have any x variables, so we don't have to consider if they are bound or unbound. Event variables always exist. Predications like this simply have to add information to the e variable they are modifying. Recall that the first argument (in this case, e_introduced_binding) represents this predication, so the variable being modified is the second one: e_target_binding.\nIt really doesn't matter what the predication adds to e_target_binding as long as the predications that consume it know what to look for. It is application specific. However, the system will look for the Originator: <index> field and use it to produce nice errors if it exists. \nSo, we've chosen to use the key \"DegreeMultiplier\" in the event dictionary as the name of the information provided by very_x_deg, and added a value for it (that is also a dictionary) that indicates to what degree something should be increased: \"Value\": 10. This is an arbitrary value, your application should do whatever makes sense for it.\nWe can now build a helper that knows about the names we've chosen so that any predication that understands \"very\" can call it:\n# This is a helper function that any predication that can\n# be &quot;very&#x27;d&quot; can use to understand just how &quot;very&#x27;d&quot; it is\ndef degree_multiplier_from_event(context, state, e_introduced_binding):\n    # if a &quot;very&quot; is modifying this event, use that value\n    # otherwise, return 1\n    if e_introduced_binding.value is None or \\\n            &quot;DegreeMultiplier&quot; not in e_introduced_binding.value:\n        degree_multiplier = 1\n\n    else:\n        degree_multiplier = e_introduced_binding.value[&quot;DegreeMultiplier&quot;][&quot;Value&quot;]\n\n    return degree_multiplier\n\nThe helper function gets passed an event variable and looks for the information that very_x_deg adds to it. If found, it returns it. Otherwise, it just returns 1. Now, any predication can multiply numbers by this value.  Here's an example of a modified large_a_1 that now uses it:\n\n@Predication(vocabulary, names=[&quot;_large_a_1&quot;])\ndef large_a_1_very(context, state, e_introduced_binding, x_target_binding):\n    # See if any modifiers have changed *how* large we should be\n    degree_multiplier = degree_multiplier_from_event(context, state, e_introduced_binding)\n\n    def criteria_bound(value):\n        if degree_multiplier &gt;= 1 and value == &quot;file2.txt&quot;:\n            return True\n\n        else:\n            context.report_error([&quot;adjectiveDoesntApply&quot;, &quot;large&quot;, x_target_binding.variable.name])\n            return False\n\n    def unbound_values():\n        if degree_multiplier &gt;= 1 and criteria_bound(&quot;file2.txt&quot;):\n            yield &quot;file2.txt&quot;\n\n    yield from combinatorial_predication_1(context, state, x_target_binding, criteria_bound, unbound_values)\n\nWe have modified the large_a_1 implementation from the first section to now pay attention to \"very\". For the example, we assume that \"file2.txt\" is very large.\nNote that if large_a_1 is called with an unbound variable, it calls the same criteria_bound() function so it will say that \"file2.txt\" is both large and very large.\nDeclaring Use of Event Information\nThere is a problem, however. This doesn't work yet. If the user says \"a file is very large\" the system will respond with:\nI don&#x27;t understand the way you are using &#x27;very&#x27; with &#x27;large&#x27;\n\nThis is because Perplexity is designed to make sure it understands every word in a sentence so that users gain confidence that they are truly understood and that the system isn't just doing \"keyword picking\". One way it does this is by ensuring that any information added to an event is actually consumed by another predication in the phrase. If not, it replies with that error.\nSince we have implemented \"very\" with \"large\", the fix is simple: we just need to add information to the @Predication() declaration, like this:\n@Predication(vocabulary, \n             names=[&quot;_large_a_1&quot;], \n             handles=[(&quot;DegreeMultiplier&quot;, EventOption.optional)])\ndef large_a_1(state, e_introduced_binding, x_target_binding):\n\n    ...\n\nThe handles=[] clause lists out all the keys that the predication knows how to process in its introduced event. In this case, we have also added EventOption.optional to say that large doesn't require \"very\", but understands it if it exists. Now it will properly process the phrase.\nExample\nAdding these to hello_world.py allows us to have this interaction:\npython ./hello_world.py\n? which file is large?\n(&#x27;file2.txt&#x27;, )\n\n? which file is very large?\n(&#x27;file2.txt&#x27;, )\n\n? a file is very large\nYes, that is true.\n\n? a file is large\nYes, that is true.\n\nNow we are ready to tackle action verbs in the next topic.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Event Predications", "teaser":"Predications with Event Variables\nSo far, we have been conveniently ignoring event variables (variables that start with \"e\"). Where instance (x) varia ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo070ActionVerbs", "excerpt":"Action Verbs\nAll the predications we've dealt with so far have just been used to ask questions like \"Is a file large?\" or make propositions like \"A file is large.\" (which is just a kind of question in terms of the kind of response a person would expect). Now it is time to implement \"action verbs\" -- verbs that actually do something to the system. Let's implement \"delete\".\n\"Delete\" goes beyond asking questions about the state of the system. To implement it, we need to actually modify the state of the system. Since the current state of all parts of the system is represented by the state object, we'll end up calling a method on that object in some form to delete a file.\nIf the user says, \"delete a file\", this MRS and tree are produced (among others):\n[ &quot;delete a file&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ pronoun_q&lt;0:13&gt; LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n          [ pron&lt;0:13&gt; LBL: h7 ARG0: x3 ]\n          [ _delete_v_1&lt;0:6&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x8 [ x PERS: 3 NUM: sg IND: + ] ]\n          [ _a_q&lt;7:8&gt; LBL: h9 ARG0: x8 RSTR: h10 BODY: h11 ]\n          [ _file_n_of&lt;9:13&gt; LBL: h12 ARG0: x8 ARG1: i13 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 h10 qeq h12 &gt; ]\n\n\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\npronoun_q(x3,RSTR,BODY)          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _file_n_of(x8,i13)\n                    \u2514\u2500 _a_q(x8,RSTR,BODY)\n                                      \u2514\u2500 _delete_v_1(e2,x3,x8)\n\nLet's ignore the pronoun related predications and focus on _delete_v_1(e2,x3,x8). We're not going to handle any modifiers to it either, so we can ignore both e2 and x3 (since x3 represents the pronoun). That leaves x8, which is the thing the user wants to delete. \nWe could try implementing _delete_v_1 like the other single x predications we've built by calling the combinatorial_predication_1() helper. The problem is: _delete_v_1 doesn't support sets > 1. \"Delete\" doesn't make sense for a set of items \"together\".  Deleting items together sounds dangerously like \"deleting them in a transaction\" which our file system can't do.  Really, delete can only apply to one item at a time, and it shouldn't support a \"together\" semantic unless it can really enforce it. So, it will use a different helper called, individual_style_predication_1() which ensures that only single individuals make it through, like this:\n@Predication(vocabulary, names=[&quot;_delete_v_1&quot;])\ndef delete_v_1_comm(context, state, e_introduced_binding, x_actor_binding, x_what_binding):\n    def criteria(value):\n        # Only allow deleting files and folders that exist\n        # value will not be a tuple since individual_style_predication_1() was used\n        if value in [&quot;file1.txt&quot;, &quot;file2.txt&quot;, &quot;file3.txt&quot;]:\n            return True\n\n        else:\n            context.report_error([&quot;cantDo&quot;, &quot;delete&quot;, x_what_binding.variable.name])\n\n    def unbound_what():\n        report_error([&quot;cantDo&quot;, &quot;delete&quot;, x_what_binding.variable.name])\n\n    yield from individual_style_predication_1(context,\n                                              state, \n                                              x_what_binding,\n                                              criteria, unbound_what,\n                                              [&quot;cantXYTogether&quot;, &quot;delete&quot;, x_what_binding.variable.name])\n\nNote that individual_style_predication_1() has an extra argument at the end which is the error to report if it gets called with a set of more than one item.\nSo, this does some of the work we need: it will only succeed if the user asks to delete a file that exists, and it won't allow phrases like \"delete everything\" that would produce an unbound x8. However, it won't actually delete anything because there isn't any code to do the deleting. \nindividual_style_predication_1() yields a state object when delete_v_1_comm is successful. So, we could start by doing the actual delete when that function yields a value because it means everything has been checked and is true.\nLet's imagine that we added a state.delete_object() to the State object that actually deletes a file and yields a new state with that file deleted. That approach could look like this:\n@Predication(vocabulary, names=[&quot;_delete_v_1&quot;])\ndef delete_v_1_comm(context, state, e_introduced_binding, x_actor_binding, x_what_binding):\n    def criteria(value):\n        # Only allow deleting files and folders that exist\n        # value will not be a tuple since individual_style_predication_1() was used\n        if value in [&quot;file1.txt&quot;, &quot;file2.txt&quot;, &quot;file3.txt&quot;]:\n            return True\n\n        else:\n            context.report_error([&quot;cantDo&quot;, &quot;delete&quot;, x_what_binding.variable.name])\n\n    def unbound_what():\n        context.report_error([&quot;cantDo&quot;, &quot;delete&quot;, x_what_binding.variable.name])\n\n    for success_state in individual_style_predication_1(context,\n                                                        state, \n                                                        x_what_binding,\n                                                        criteria, \n                                                        unbound_what,\n                                                        [&quot;cantXYTogether&quot;, &quot;delete&quot;, x_what_binding.variable.name]):\n        object_to_delete = success_state.get_binding(x_what_binding.variable.name).value[0]\n        yield success_state.delete_object(object_to_delete)        \n\nThis works because: \nWhen individual_style_predication_1() yields a new state, it means this predication was successful. That happened because the criteria() function returned true. The new state has all the MRS variables set to the value that made the predication true, which means that the x_what_binding variable should now be set to the thing being deleted. \nHowever, we need to be careful to ask for the value of the variable represented by x_what_binding in the new state. Remember that state objects are immutable, so we have to look at the copy being returned to get the new value of the variable. That's what this line does:\nobject_to_delete = success_state.get_binding(x_what_binding.variable.name).value[0]\n\nThis is basically the approach we are going to use, but we need some extra mechanisms to do it. The reason why is described next.\nOperations\nActions that modify anything in the world state besides an MRS variable are called an Operation in Perplexity.  They go beyond manipulating the MRS and actually affect the world the person is speaking about. Predications like _delete_v_1 that want to modify the state of the world need to use an Operation.\nOperations are a way of recording what to do and then doing it later: Think of an Operation as a way to package up a method call into an object and then later ask it to execute. \nAn Operation is simply any Python class that includes this method:\ndef apply_to(self, state):\n\n    ...\n\nThe constructor (i.e. the __init__ method) packages up all the information needed to perform the operation later by storing them as members in the class. When it is time to actually perform the operation, apply_to() is called, and the state object that it should be applied to is passed in.\nHere is an example of what a DeleteOperation could look like:\nclass DeleteOperation(object):\n    def __init__(self, value_to_delete):\n        self.value_to_delete = value_to_delete\n\n    def apply_to(self, state):\n        state.file_system.delete_item(self.value_to_delete)\n\nThe DeleteOperation itself is very simple, it is really just remembering what to delete. When it is asked to apply_to(), it calls the method in the state object that actually deletes the file, in that state object (which might be different than the one it was added to).\nTo use the DeleteOperation, we create an instance of one and pass it to the record_operations() method in the State object, like this:\noperation = DeleteOperation(new_state.get_binding(x_what_binding.variable.name).value[0])\nyield new_state.record_operations([operation])\n\nThe record_operations() method takes a list of operations to apply, but in this case we're only doing one. Those two lines of code record that we want to delete a particular file, but doesn't actually do it yet.  Later, when we have the final solution group, we can gather all of the Operations that were done to the solutions in the group and call apply_operations() (which will actually do the work) on the one single state we want to represent the new world.\nDoing things in this more roundabout way solves two problems. Recall that the solver builds a list of all solutions (conceptually) and then groups them into solution groups. We don't want files actually being deleted during this phase because some of the solutions might not be used! Furthermore, each solution in a group will only have a subset of the files deleted. Using operations allows us to both delay state changes as well as apply them all to a single state which can represent the \"new state of the world\" once we know what to do.\nNow we can write the basic implementation of \"delete\":\n@Predication(vocabulary, names=[&quot;_delete_v_1&quot;])\ndef delete_v_1_comm(context, state, e_introduced_binding, x_actor_binding, x_what_binding):\n    def criteria(value):\n        # Only allow deleting files and folders that exist\n        # value will not be a tuple since individual_style_predication_1() was used\n        if value in [&quot;file1.txt&quot;, &quot;file2.txt&quot;, &quot;file3.txt&quot;]:\n            return True\n\n        else:\n            context.report_error([&quot;cantDo&quot;, &quot;delete&quot;, x_what_binding.variable.name])\n\n    def unbound_what():\n        context.report_error([&quot;cantDo&quot;, &quot;delete&quot;, x_what_binding.variable.name])\n\n    for success_state in individual_style_predication_1(context,\n                                                        state, \n                                                        x_what_binding,\n                                                        criteria, \n                                                        unbound_what,\n                                                        [&quot;cantXYTogether&quot;, &quot;delete&quot;, x_what_binding.variable.name]):\n        object_to_delete = success_state.get_binding(x_what_binding.variable.name).value[0]\n        operation = DeleteOperation(object_to_delete)\n        yield success_state.record_operations([operation])\n\nThe final step that merges together all the operations and applies them to a single state is done by Perplexity automatically at the end of user_interface.default_loop(). That's where DeleteOperation.apply_to() gets called for every solution in the solution group.\nThe pron() Predication\nThe MRS we are working with is:\n[ &quot;delete a file&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ pronoun_q&lt;0:13&gt; LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n          [ pron&lt;0:13&gt; LBL: h7 ARG0: x3 ]\n          [ _delete_v_1&lt;0:6&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x8 [ x PERS: 3 NUM: sg IND: + ] ]\n          [ _a_q&lt;7:8&gt; LBL: h9 ARG0: x8 RSTR: h10 BODY: h11 ]\n          [ _file_n_of&lt;9:13&gt; LBL: h12 ARG0: x8 ARG1: i13 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 h10 qeq h12 &gt; ]\n\n\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\npronoun_q(x3,RSTR,BODY)          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _file_n_of(x8,i13)\n                    \u2514\u2500 _a_q(x8,RSTR,BODY)\n                                      \u2514\u2500 _delete_v_1(e2,x3,x8)\n\n... and pron(x) is the last predication to implement (pronoun_q is a quantifier that is implemented by the system). pron(x) is true when x is bound to an object that represents what the specified pronoun is referring to. The \"specified pronoun\" is determined by looking at the properties for the x variable to determine if the pronoun is \"you\". The properties could be: PERS: 2 (second person: i.e. \"you\"), PERS: 3 (third person: i.e. \"him/her\"), etc. If x is bound to an object that represents what that pronoun is referring to, it is true. \nThere were not any pronouns in our command \"delete a file\", so where did the pron predication come from? In this case, the pronoun is an implied \"you\" since it is a command. I.e \"(You) delete a large file\".  Because we are not including the notion of other people in the file system, the only pronouns we probably care to understand are \"you\" (\"can you delete the file?\" or the implied case above) and maybe \"I\" (\"I want to delete a file\"). For now, let's just do \"you\" and fail otherwise. \n@Predication(vocabulary, names=[&quot;pron&quot;])\ndef pron(context, state, x_who_binding):\n    person = int(state.get_binding(&quot;tree&quot;).value[0][&quot;Variables&quot;][x_who_binding.variable.name][&quot;PERS&quot;])\n\n    def bound_variable(value):\n        if person == 2 and value == &quot;computer&quot;:\n            return True\n        else:\n            context.report_error([&quot;dontKnowActor&quot;, x_who_binding.variable.name])\n\n    def unbound_variable():\n        if person == 2:\n            yield &quot;computer&quot;\n        else:\n            context.report_error([&quot;dontKnowActor&quot;, x_who_binding.variable.name])\n\n    yield from combinatorial_style_predication_1(context, state, x_who_binding, bound_variable, unbound_variable)\n\nTo find out what pronoun is being referred to by x, we use a special variable binding that Perplexity puts in state called: tree.  This is not an MRS concept or feature, it is just a convenient place to keep the fully-resolved MRS tree for predications that need to inspect it. The variables in the tree and their properties are accessed like a tree of dictionaries as shown above.\nThe 2nd person pronoun \"you\" will always refer to \"the computer\" so we represent it as a string \"computer\". That is enough for this simple example. \nNow we've implemented all the predications.  Just one final step is left.\nUsing the State Object\nTo make this run properly, we need to quit using hard-coded lists of files since we're going to be deleting them. It is time to use a real State object to track state. The built-in Perplexity State object has a very simple default mechanism for tracking objects. In most cases, we would need to derive a new class from it to manage the state of an application in a richer way, but our examples are simple enough that we can use it as-is.\nThe important parts of the class for our purposes are below. A list of objects can be passed in the constructor and State will return them from all_individuals(). It is very simple:\nclass State(object):\n    def __init__(self, objects):\n\n        ...\n\n        self.objects = objects\n\n    ...\n    \n    def all_individuals(self):\n        for item in self.objects:\n            yield item\n\n    ...\n\nWe need to change file_n_of, large_a_1 and delete_v_1_comm to use the state object instead of hard-coding the list of files:\n@Predication(vocabulary, names=[&quot;_file_n_of&quot;])\ndef file_n_of(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if value in state.all_individuals():\n            return True\n        else:\n            context.report_error([&quot;notAThing&quot;, x_binding.value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield from state.all_individuals()\n\n    yield from combinatorial_style_predication_1(context, state, x_binding, bound_variable, unbound_variable)\n\n\n\n@Predication(vocabulary,\n             names=[&quot;_large_a_1&quot;],\n             handles=[(&quot;DegreeMultiplier&quot;, EventOption.optional)])\ndef large_a_1(context, state, e_introduced_binding, x_target_binding):\n    # See if any modifiers have changed *how* large we should be\n    degree_multiplier = degree_multiplier_from_event(state, e_introduced_binding)\n\n    def criteria_bound(value):\n        if degree_multiplier &gt;= 1 and value == &quot;file2.txt&quot; and &quot;file2.txt&quot; in state.all_individuals():\n            return True\n\n        else:\n            context.report_error([&quot;adjectiveDoesntApply&quot;, &quot;large&quot;, x_target_binding.variable.name])\n            return False\n\n    def unbound_values():\n        if criteria_bound(&quot;file2.txt&quot;):\n            yield &quot;file2.txt&quot;\n\n    yield from combinatorial_style_predication_1(context, state, x_target_binding, criteria_bound, unbound_values)\n\n@Predication(vocabulary, names=[&quot;_delete_v_1&quot;])\ndef delete_v_1_comm(context, state, e_introduced_binding, x_actor_binding, x_what_binding):\n    def criteria(value):\n        # Only allow deleting files and folders that exist\n        # value will not be a tuple since individual_style_predication_1() was used\n        if value in state.all_individuals():\n            return True\n\n        else:\n            context.report_error([&quot;cantDo&quot;, &quot;delete&quot;, x_what_binding.variable.name])\n\n    def unbound_what():\n        context.report_error([&quot;cantDo&quot;, &quot;delete&quot;, x_what_binding.variable.name])\n\n    for success_state in individual_style_predication_1(context,\n                                                        state, \n                                                        x_what_binding,\n                                                        criteria, \n                                                        unbound_what,\n                                                        [&quot;cantXYTogether&quot;, &quot;delete&quot;, x_what_binding.variable.name]):\n        object_to_delete = success_state.get_binding(x_what_binding.variable.name).value[0]\n        operation = DeleteOperation(object_to_delete)\n        yield success_state.record_operations([operation])\n\n... and create our initial State object with the starting list of files:\ndef reset():\n    return State([&quot;file1.txt&quot;, &quot;file2.txt&quot;, &quot;file3.txt&quot;])\n\nWith those changes, we can now test the system:\npython hello_world.py\n? a file is large\nYes, that is true.\n\n? delete a large file\nDone!\n\n? a file is large\na file is not large\n\nThe last line confirms that the one large file in the system has been deleted.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Verb Predications", "teaser":"Action Verbs\nAll the predications we've dealt with so far have just been used to ask questions like \"Is a file large?\" or make propositions like \"A fi ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo082State", "excerpt":"Building a Custom State Object\nWe are getting to the point where the examples need to get richer and hard-coding the state of the world or using the base State object is not going to be good enough. We need to step back and think about how to model the file system state in a more robust way.  Even if you aren't building an interface to a file system, many of the concerns and solutions described below could be useful to you.  Designing how your state object works is a key design decision when building a Perplexity application.\nThe Perplexity State object\nThe default State object only has a small amount of code for manipulating application state, the rest of its implementation manipulates MRS variables. It is literally just one method: all_individuals() and we used it in the Action Verbs topic. Here it is again:\nclass State(object):\n    def __init__(self, objects):\n\n        ...\n\n        self.objects = objects\n\n    ...\n    \n    def all_individuals(self):\n        for item in self.objects:\n            yield item\n\n    ...\n\nThe only reason it even has this basic implementation is because the system implementation of in_scope needs it to determine which objects are \"proximate\" to the user. So, outside of that, we are free to implement our system state in any way we like as long as it remains immutable. Any methods we implement that make changes must follow the pattern used by set_x() and add_to_e() and return a copy with the change instead of modifying the object directly. This is key for making the solver backtracking algorithm work.\nSo, we'll need to add a notion of files and folders to State, and provide some ways to query the system about them. But all of this will only be used by the code we write to implement our custom predications.  Perplexity will completely ignore it.\nIdentity\nBecause the system is built around immutable state, we will sometimes end up with two State objects and need to be able to find the same object contained in either one. We need a way to compare objects across state objects. The easiest way is to give all the objects in the system a globally unique id that can be easily compared. We'll create a base class, UniqueObject that does this and derive everything from it:\nclass UniqueObject(object):\n    def __init__(self):\n        self.unique_id = uuid.uuid4()\n\nContainment and Location\nOne of the main concepts in a file system is \"containment\" - folders contain files, files contain text, etc. We'll want to model this in a general way so that words like \"in\" or \"contains\" can work across objects. We'll do this by having two methods that objects can implement:\n# Implement by yielding all objects that this object contains\ndef contained_items(self, variable_data):\n    ...\n\n# Implement by yielding all the places that this object &quot;is&quot; \ndef all_locations(self, variable_data):\n    ...\n\nFiles and Folders\nBecause users may talk about files or folders that don't exist yet, or that may need to be created, we need the File and Folder object to be able to represent files and folders that don't actually exist. So, these objects will have a small amount of information in them and call to a FileSystem object for the rest (we'll implement that object in the next section). \nIt is very important that these objects implement __hash__ since that allows them to be in sets and dictionaries which are required by Perplexity. __repr__ is just a method that makes debugging nicer. Checking if things are equal is also required by Perplexity, which is why __eq__ is implemented. As described above, contained_items and all_locations are implemented in both to support predications that involve containment. The rest of the methods are helpers.\n[Note that the File object also has a simplistic notion of a \"linked file\" (as in Unix) so that we can show the system answering questions about things that are in more than one place.]\nclass File(UniqueObject):\n    def __init__(self, name, size=None, file_system=None, link=None):\n        super().__init__()\n        self.name = name\n        self.size = size\n        self.file_system = file_system\n        self.link = link\n\n        # If we assume link objects always have the same name, then if we only hash the name\n        # link objects will have the same hash, but so will anything else with that name (which is OK)\n        # Any other files in the system with the same name (including raw file specifiers) will\n        # hash to the same value too.\n        # This means that there could be collisions if there are lots of files with the same name\n        # but it is unclear how else to do this\n        self._hash = hash(self.file_name())\n\n    def __repr__(self):\n        return f&quot;File(name={self.name}, size={self.size})&quot;\n\n    # The only required property is that objects which compare equal have the same hash value\n    # But: objects with the same hash aren&#x27;t required to be equal\n    # It must remain the same for the lifetime of the object\n    def __hash__(self):\n        return self._hash\n\n    def __eq__(self, obj):\n        if isinstance(obj, File) and self._hash == obj._hash:\n            if self.has_path() and obj.has_path():\n                # If they both have a path, then the entire path must be ==\n                # to make them ==\n                # Unless there is a symbolic link, in which case the links must match\n                self_name = self.name if self.link is None else self.link\n                obj_name = obj.name if obj.link is None else obj.link\n                return self_name == obj_name\n\n            else:\n                # If one or both of them doesn&#x27;t have a path specified then it is a pure filename\n                # which means it == the other object if the file name alone matches\n                return self.file_name() == obj.file_name()\n\n    def all_locations(self, variable_data):\n        if self.exists():\n            folder = self.file_system.item_from_path(str(pathlib.PurePath(self.name).parent), is_file=False)\n            yield folder\n            yield from folder.all_locations(variable_data)\n\n        else:\n            raise MessageException(&quot;notFound&quot;, [variable_data.name])\n\n    def contained_items(self, variable_data):\n        yield from self.file_system.contained_items(self, variable_data)\n\n    def exists(self):\n        return self.file_system.exists(self.name, is_file=True)\n\n    # False if there is no path specified at all\n    # including &quot;./&quot;. Indicates the object is a raw\n    # file specifier\n    def has_path(self):\n        return os.path.dirname(self.name) != &quot;&quot;\n\n    def file_name(self):\n        return pathlib.PurePath(self.name).parts[-1]\n\n    def can_interpret_as(self, value):\n        return pathlib.PurePath(self.name).match(value)\n\n    def size_measurement(self):\n        return Measurement(Megabyte(), self.size/1000000)\n\n\nclass Folder(UniqueObject):\n    def __init__(self, name, size=0, file_system=None):\n        super().__init__()\n        self.name = name\n        self.size = size\n        self.file_system = file_system\n        self._hash = hash(self.name)\n\n    def __hash__(self):\n        return self._hash\n\n    def __repr__(self):\n        return f&quot;Folder(name={self.name}, size={self.size})&quot;\n\n    def __eq__(self, obj):\n        return isinstance(obj, Folder) and str(self.name) == str(obj.name)\n\n    def contained_items(self, variable_data):\n        yield from self.file_system.contained_items(self, variable_data)\n\n    def all_locations(self, variable_data):\n        if self.exists():\n            path = pathlib.PurePath(self.name)\n            for parent_path in path.parents:\n                yield self.file_system.item_from_path(parent_path, is_file=False)\n\n        else:\n            raise MessageException(&quot;notFound&quot;, [variable_data.name])\n\n    def can_interpret_as(self, value):\n        return pathlib.PurePath(self.name).match(value)\n\n    def exists(self):\n        return self.file_system.exists(self.name, is_file=False)\n\nFileSystem\nWe'll be using a fake FileSystem object for the examples so that we can inject the files and folders that we want to test, but the class is built to allow it to be implemented on top of a real file system as well. There are a lot of implementation details in this class that aren't important for understanding how the system works -- you can see the full implementation here. For our purposes, the important parts are the constructor and the implementation of all_individuals():\n# Allows mocking up a file system for testing\nclass FileSystemMock(State):\n    # current = the user&#x27;s current directory as a string\n    #\n    # file_list must be in the form:\n    # [(True, &quot;/dir1/dir2/filename.txt&quot;, {&quot;size&quot;: 1000} # Set to True for a file\n    #  (False, &quot;/dir3/dir4&quot; # Set to False for a directory\n    # ]\n    # Adds the entire path of each directory as individual directories\n    # in the file system\n    def __init__(self, file_list, current):\n\n        ...\n\n\n    def all_individuals(self):\n\n        ...\n\nThe constructor allows us to create a mock file system with whatever files and folders we want, as well as setting a \"current\" directory.  It is used like this:\nFileSystemMock([(True, &quot;/documents/file1.txt&quot;, {&quot;size&quot;: 1000}),\n                (False, &quot;/Desktop&quot;, {&quot;size&quot;: 10000000}),\n                (True, &quot;/Desktop/file2.txt&quot;, {&quot;size&quot;: 10000000}),\n                (True, &quot;/Desktop/file3.txt&quot;, {&quot;size&quot;: 1000})],\n                &quot;/Desktop&quot;))\n\nIt takes a list of tuples that describe files and folders. The first element of the tuple is True if the item is a file, False if folder. Sizes can be provided for each.  The last argument is the folder that is the \"current\" directory.\nActor\nWe will encounter phrases that have an explicit person like \"where am I?\" as well as an implied person like \"delete a file\" (i.e. \"[you] delete a file\"). Either case generates predications that need \"actors\" to be modelled in the system:\n# Represents something that can &quot;do&quot; things, like a computer\n# or a human (or a dog, etc)\nclass Actor(UniqueObject):\n    def __init__(self, name, person, file_system=None):\n        super().__init__()\n        self.name = name\n        self.person = person\n        self.file_system = file_system\n        self._hash = hash((self.name, self.person))\n\n    def __hash__(self):\n        return self._hash\n\n    def __eq__(self, other):\n        if isinstance(other, Actor):\n            return self._hash == other._hash\n\n    def __repr__(self):\n        return f&quot;Actor(name={self.name}, person={self.person})&quot;\n\n    def all_locations(self, variable_data):\n        if self.person == 1:\n            # Return the locations for the user &quot;me&quot;\n            yield self.current_directory()\n            yield from self.current_directory().all_locations(variable_data)\n\n    def current_directory(self):\n        return self.file_system.current_directory()\n\nAn Actor has a person property that indicates what pronoun role it plays: 1 means \"first person pronoun\" like \"I\" or \"me\", 2 means second person pronoun, which is always \"the computer\" in this system, etc. It also has a FileSystem member so it can find its \"current directory\". Finally, it has the all_locations() method so we can find out where the Actor is.\nFileSystemState\nThe last step is to create a new State object that uses the FileSystem object that we'll actually use in the samples. We need to derive this from the Perplexity State object so that it can be used in the system, and we need to implement the State.all_individuals() method so that in_scope will work. Note that all individuals needs to return both actors and file system objects since they are all the objects in the system.\nNote that there is also a save() method that uses Python \"pickling\" to save the state of the world, which is a simple way of saving a simple set of objects like these.\n# The state representation used by the file system example\n# note that the core system doesn&#x27;t care at all what this object\n# looks like. It is only the predications that interact with it\nclass FileSystemState(State):\n    def __init__(self, file_system, current_user=None, actors=None):\n        super().__init__([])\n        self.file_system = file_system\n        self.current_user = file_system_example.objects.Actor(name=&quot;User&quot;, person=1, file_system=file_system) if current_user is None else current_user\n        self.actors = [self.current_user,\n                       file_system_example.objects.Actor(name=&quot;Computer&quot;, person=2, file_system=file_system)] if actors is None else actors\n\n    def save(self, file):\n        pickle.dump(self.file_system, file, 5)\n        pickle.dump(self.current_user, file, 5)\n        pickle.dump(self.actors, file, 5)\n\n    def all_individuals(self):\n        yield from self.file_system.all_individuals()\n        yield from self.actors\n\n    def user(self):\n        return self.current_user\n\nThe base State class will handle doing copies of the object when set_x or add_to_e are called. We don't need to do anything special to handle the object being copied because the objects have all been carefully built to support the Python copy.deepcopy() method. They also all derive from UniqueObject so they can be compared across objects. \nUsing FileSystemState\nTo use the object, we modify the hello_world.py reset() function to return the new FileSystemState object instead of the default State object, like this:\n... \n\nvocabulary = Vocabulary()\n\n\ndef reset():\n    # return State([])\n\n    return FileSystemState(FileSystemMock([(True, &quot;/documents/file1.txt&quot;, {&quot;size&quot;: 1000}),\n                                           (False, &quot;/Desktop&quot;, {&quot;size&quot;: 10000000}),\n                                           (True, &quot;/Desktop/file2.txt&quot;, {&quot;size&quot;: 10000000}),\n                                           (True, &quot;/Desktop/file3.txt&quot;, {&quot;size&quot;: 1000})],\n                                           &quot;/Desktop&quot;))\n\n\nThat change will ensure that our FileSystemState object is used by the solver in every call to one of our predications. That, and modifying the predications to start using the new state, is all that is needed.\nExample\nOnly the _file_n_of, _folder_n_of, _large_a_1, delete_v_1_comm and pron predications need to be updated to use the new objects.  The DeleteOperation class needs to be updated as well. These are all relatively minor changes, and the final functions are listed below:\n@Predication(vocabulary, names=[&quot;_file_n_of&quot;])\ndef file_n_of(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if isinstance(value, File):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        for item in state.all_individuals():\n            if bound_variable(item):\n                yield item\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\n\n# true for both sets and individuals as long as everything\n# in the set is a file\n@Predication(vocabulary, names=[&quot;_folder_n_of&quot;])\ndef folder_n_of(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if isinstance(value, Folder):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        for item in state.all_individuals():\n            if bound_variable(item):\n                yield item\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\n\n@Predication(vocabulary,\n             names=[&quot;_large_a_1&quot;],\n             handles=[(&quot;DegreeMultiplier&quot;, EventOption.optional)])\ndef large_a_1(context, state, e_introduced_binding, x_target_binding):\n    # See if any modifiers have changed *how* large we should be\n    degree_multiplier = degree_multiplier_from_event(context, state, e_introduced_binding)\n\n    # &quot;large&quot; is being used &quot;predicatively&quot; as in &quot;the dogs are large&quot;. This needs to force\n    # the individuals to be separate (i.e. not part of a group)\n    def criteria_bound(value):\n        if hasattr(value, &#x27;size&#x27;) and value.size &gt; degree_multiplier * 1000000:\n            return True\n\n        else:\n            context.report_error([&quot;adjectiveDoesntApply&quot;, &quot;large&quot;, x_target_binding.variable.name])\n            return False\n\n    def unbound_values():\n        # Find all large things\n        for value in state.all_individuals():\n            if hasattr(value, &#x27;size&#x27;) and value.size &gt; degree_multiplier * 1000000:\n                yield value\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_target_binding,\n                                           criteria_bound,\n                                           unbound_values)\n\n\n# Delete only works on individual values: i.e. there is no semantic for deleting\n# things &quot;together&quot; which would probably imply a transaction or something\n@Predication(vocabulary, names=[&quot;_delete_v_1&quot;])\ndef delete_v_1_comm(context, state, e_introduced_binding, x_actor_binding, x_what_binding):\n    # We only know how to delete things from the\n    # computer&#x27;s perspective\n    if x_actor_binding.value[0].name == &quot;Computer&quot;:\n        def criteria(value):\n            # Only allow deleting files and folders that exist\n            if isinstance(value, (File, Folder)) and value.exists():\n                return True\n\n            else:\n                context.report_error([&quot;cantDo&quot;, &quot;delete&quot;, x_what_binding.variable.name])\n\n        def unbound_what():\n            context.report_error([&quot;cantDo&quot;, &quot;delete&quot;, x_what_binding.variable.name])\n\n        for new_state in individual_style_predication_1(context,\n                                                        state,\n                                                        x_what_binding,\n                                                        criteria,\n                                                        unbound_what,\n                                                        [&quot;cantDeleteSet&quot;, x_what_binding.variable.name]):\n            yield new_state.record_operations([DeleteOperation(new_state.get_binding(x_what_binding.variable.name))])\n\n    else:\n        context.report_error([&quot;dontKnowActor&quot;, x_actor_binding.variable.name])\n\n\n# Delete any object in the system\nclass DeleteOperation(object):\n    def __init__(self, binding_to_delete):\n        self.binding_to_delete = binding_to_delete\n\n    def apply_to(self, state):\n        state.file_system.delete_item(self.binding_to_delete)\n\n\n@Predication(vocabulary, names=[&quot;pron&quot;])\ndef pron(context, state, x_who_binding):\n    person = int(state.get_binding(&quot;tree&quot;).value[0][&quot;Variables&quot;][x_who_binding.variable.name][&quot;PERS&quot;])\n\n    def bound_variable(value):\n        return isinstance(value, Actor) and value.person == person\n\n    def unbound_variable():\n        for item in state.all_individuals():\n            if bound_variable(item):\n                yield item\n\n    yield from combinatorial_predication_1(context, state, x_who_binding, bound_variable, unbound_variable)\n\nWith those changes, all the examples from before still work the same but now use the new objects:\npython ./hello_world.py\n? a file is large\nYes, that is true.\n\n? which file is large?\n(File(name=/documents/file2.txt, size=10000000),)\n\n? what file is very large?\na file is not large\n\n? a file is very large\na file is not large\n\n? delete a large file\nDone!\n\n? a file is large\na file is not large\n\nComprehensive source for the completed tutorial is available here\n\n", "title":"Custom State", "teaser":"Building a Custom State Object\nWe are getting to the point where the examples need to get richer and hard-coding the state of the world or using the b ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo085Place", "excerpt":"Representing Places\nTo understand what we need to properly represent places, let's go through a key predication from the ERG that represents place, loc_nonsp.\nloc_nonsp (\"nonspecific location\") is true when x_location represents a \"place\" where x_actor \"is\" or \"is at\" but doesn't get more specific than that. It shows up in phrases like:\n\"Where am I?\" -> no relationship other than I \"am\" somewhere\n\n\"Where is the stick?\" -> no relationship other than the stick \"is\" somewhere\n\n\"The dog barks every day\" -> No relationship to day other than it \"happens\" every day\n\nIt would not show up in phrases that more specifically locate something, such as:\nThe stick is on the table. -> locates the stick in a place on the location\n\nHe arrives before/at 10am. -> locates the arrival before/at a certain time\n\nMore information is available in the ERG reference.\nIn this topic, we'll implement the loc_nonsp and place_n predications to make the phrase \"Where am I?\" work. As always, we'll start by trying out the phrase, even though we know it won't work yet, and using /show to examine the MRS to see what predications it generates:\n? where am I?\nI don&#x27;t know the words: where, I\n\n? /show\nUser Input: where am I?\n1 Parses\n\n***** CHOSEN Parse #0:\nSentence Force: ques\n[ &quot;where am I?&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: ques TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ loc_nonsp&lt;0:5&gt; LBL: h1 ARG0: e2 ARG1: x3 [ x PERS: 1 NUM: sg IND: + PT: std ] ARG2: x4 [ x PERS: 3 NUM: sg ] ]\n          [ place_n&lt;0:5&gt; LBL: h5 ARG0: x4 ]\n          [ which_q&lt;0:5&gt; LBL: h6 ARG0: x4 RSTR: h7 BODY: h8 ]\n          [ pron&lt;9:10&gt; LBL: h9 ARG0: x3 ]\n          [ pronoun_q&lt;9:10&gt; LBL: h10 ARG0: x3 RSTR: h11 BODY: h12 ] &gt;\n  HCONS: &lt; h0 qeq h1 h7 qeq h5 h11 qeq h9 &gt; ]\n\n-- CHOSEN Parse #0, CHOSEN Tree #0: \n\n             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 place_n(x4)\nwhich_q(x4,RSTR,BODY)               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\n                  \u2514\u2500 pronoun_q(x3,RSTR,BODY)\n                                         \u2514\u2500 loc_nonsp(e2,x3,x4)\n\nplace_n(x)\nAs in \"Where am I?\", place_n often appears with loc_nonsp when the location being referred to is inferred by the ERG to be a place.\nWhat are the \"places\" in a file system? They are all the objects where something else can be located, some obvious ones:\nfile: text can be located in a file, \"where is the text 'summary of costs'?\"\n\nfolder: files can be in a folder, \"where is the file 'foo.txt'?\"\n\nFor this particular system, a good proxy for \"place\" might be anything that something can be \"in\", aka a \"container\". We'll want easy ways to:\nFind all the containers\n\nFind all the containers that contain a particular thing\n\nplace_n will be able to leverage the methods on the objects we built in the previous section to do this, and we'll use the same approach we've been using for other nouns introduced in the Implementing a Predication topic:\n@Predication(vocabulary)\ndef place_n(context, state, x_binding):\n    def bound_variable(value):\n        # Any object is a &quot;place&quot; as long as it can contain things\n        if hasattr(value, &quot;contained_items&quot;):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        for item in state.all_individuals():\n            if bound_variable(item):\n                yield item\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\n\nThis should all look reasonably familiar by now. If an object has a contained_items method, that means it is a container and that means it is \"a place\". Different systems will have different criteria for place depending on their scenarios. The function iterates through all objects in the system and yields any that have this method when its x argument is unbound, thus yielding all the \"places\".\nloc_nonsp(e,x,x): Representing Generic Location\nAs described above, loc_nonsp(e,x_actor,x_location) is true when x_location represents a \"place\" where x_actor \"is\" or \"is at\" but doesn't get more specific than that. Basically, it is the \"generic location\" of x_actor (x_actor does not need to be an actually be an Actor it can be anything). This means we'll need to get the \"location\" from the objects in the system. Note that a given file or folder has many \"locations\":\nIt is located in a folder\n\nIt is also located in the parent folder\n\nIt is also located in the parent of the parent folder\n\netc.\n\nWe've already implemented a method to return the locations of objects called all_locations() on the Actor, File and Folder objects which we can use:\n@Predication(vocabulary, names=[&quot;loc_nonsp&quot;])\ndef loc_nonsp(context, state, e_introduced_binding, x_actor_binding, x_location_binding):\n    def item_at_item(item1, item2):\n        if hasattr(item1, &quot;all_locations&quot;):\n            # Asking if a location of item1 is at item2\n            for location in item1.all_locations(x_actor_binding.variable):\n                if location == item2:\n                    return True\n\n        context.report_error([&quot;thingHasNoLocation&quot;, x_actor_binding.variable.name, x_location_binding.variable.name])\n        return False\n\n    def location_unbound_values(actor_value):\n        # This is a &quot;where is actor?&quot; type query since no location specified (x_location_binding was unbound)\n        # Order matters, so all_locations needs to return the best answer first\n        if hasattr(actor_value, &quot;all_locations&quot;):\n            for location in actor_value.all_locations(x_actor_binding.variable):\n                yield location\n\n        context.report_error([&quot;thingHasNoLocation&quot;, x_actor_binding.variable.name, x_location_binding.variable.name])\n\n    def actor_unbound_values(location_value):\n        # This is a &quot;what is at x?&quot; type query since no actor specified (x_actor_binding was unbound)\n        # Order matters, so all_locations needs to return the best answer first\n        if hasattr(location_value, &quot;contained_items&quot;):\n            for actor in location_value.contained_items(x_location_binding.variable):\n                yield actor\n\n        context.report_error([&quot;thingIsNotContainer&quot;, x_location_binding.variable.name])\n\n    yield from in_style_predication_2(context,\n                                      state,\n                                      x_actor_binding,\n                                      x_location_binding,\n                                      item_at_item,\n                                      actor_unbound_values,\n                                      location_unbound_values)\n\nloc_nonsp is an \"in-style\" predication because if the location of x is location1 and the location of y is location, then they are both there \"together\" or \"separately\" and it doesn't mean anything special, but also shouldn't be prohibited. This is a pretty straightforward implementation, just like the implementation of _in_p_loc in the In-Style Predications topic.\nWe've introduced two new location-based errors thingHasNoLocation and thingIsNotContainer, so we need to provide messages for them in generate_custom_message() as well (using s-strings):\ndef generate_custom_message(tree_info, error_term):\n    ...\n\n    elif error_constant == &quot;thingHasNoLocation&quot;:\n        return s(&quot;{arg1} is not in {arg2}&quot;, tree_info)\n\n    elif error_constant == &quot;thingIsNotContainer&quot;:\n        return s(&quot;{arg1} can&#x27;t contain things&quot;, tree_info)\n\n    ...\n\nExample\nIncluding the implementation of loc_nonsp and place_n, with no other changes to the code we've built so far, allows us to start interacting with place a bit:\npython hello_world.py\n? where am I?\n(Folder(name=/documents, size=0),)\n(there are more)\n\n? where are you?\nyou is not in place\n\n? where is a file?\n(Folder(name=/documents, size=0),)\n(there are more)\n\n? where is a folder?\n(Folder(name=/, size=0),)\n(there are more)\n\nBoth \"where am I?\" and \"where is a file/folder?\" give an answer and then say, \"(there are more)\". That is because the user asked for \"a place\" (singular) but most things will \"be located\" in more than one place. For example, the user is in both \"/documents\" and \"/\" (the root directory). As described in the Optimizing Solution Groups topic, we let the user know if they there is more than one thing if they ask for a singular answer, just to clarify.\nAlso note that \"you\" refers to \"the computer\" and we haven't put it anywhere, that's why the system responds with \"you is not in place\". Again, we'll fix the English on error messages soon.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Representing Places", "teaser":"Representing Places\nTo understand what we need to properly represent places, let's go through a key predication from the ERG that represents place, lo ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo090Prepositions", "excerpt":"Directional Prepositions\nLet's implement the verb \"go\" in hello_world.py to allow for moving around the file system in a simple way.\nThe phrase \"go to a folder\" yields 4 parses, one of which is:\n***** Parse #3:\nSentence Force: comm\n[ &quot;go to a folder&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ pronoun_q&lt;0:14&gt; LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n          [ pron&lt;0:14&gt; LBL: h7 ARG0: x3 ]\n          [ _go_v_1&lt;0:2&gt; LBL: h1 ARG0: e2 ARG1: x3 ]\n          [ _to_p_dir&lt;3:5&gt; LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n          [ _a_q&lt;6:7&gt; LBL: h10 ARG0: x9 RSTR: h11 BODY: h12 ]\n          [ _folder_n_of&lt;8:14&gt; LBL: h13 ARG0: x9 ARG1: i14 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\n-- CHOSEN Parse #0, CHOSEN Tree #0: \n\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _folder_n_of(x9,i14)\n_a_q(x9,RSTR,BODY)               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\n               \u2514\u2500 pronoun_q(x3,RSTR,BODY)    \u250c\u2500\u2500 _to_p_dir(e8,e2,x9)\n                                      \u2514\u2500 and(0,1)\n                                               \u2514 _go_v_1(e2,x3)\n\nIt introduces two additional predications we'll need to implement to make this work: _to_p_dir and _go_v_1.\n_to_p_dir\n_to_p_dir is a directional preposition.  Directional prepositions usually end with _dir and have the signature (e, e_verb, x_location).  x_location indicates the location the preposition is specifying, and e_verb indicates the event (often a verb) that this preposition should be attached to. They specify a particular direction in which to do something.  The fact that the predication takes an event as its second argument is a hint that the predication itself doesn't do anything except attach its information to the specified event so that something else can use it. Taking an event as an argument besides ARG0 usually indicates the predication is modifying the event. So, it can be implemented like this:\n@Predication(vocabulary, names=[&quot;_to_p_dir&quot;])\ndef to_p_dir(context, state, e_introduced, e_target_binding, x_location_binding):\n    preposition_info = {\n        &quot;EndLocation&quot;: x_location_binding\n    }\n\n    yield state.add_to_e(e_target_binding.variable.name,\n                         &quot;DirectionalPreposition&quot;,\n                         {&quot;Value&quot;: preposition_info,\n                          &quot;Originator&quot;: context.current_predication_index()})\n\nThis code just adds the location, contained in the binding x_location_binding, to the e_target event under the key DirectionalPreposition. This allows the event that introduces it to consume it, as discussed in a Event Predications topic. Perplexity will ensure that the user will get a \"don't understand\" error if the predication that introduced the event doesn't know how to handle it, as discussed in that same topic.\n_go_v_1\nNext, we need to implement _go_v_1, indicating that it does know how to handle that information, like this:\n@Predication(vocabulary, names=[&quot;_go_v_1&quot;], handles=[(&quot;DirectionalPreposition&quot;, EventOption.required)])\ndef go_v_1_comm(context, state, e_introduced_binding, x_actor_binding):\n    if x_actor_binding.value is None or len(x_actor_binding.value) &gt; 1 or x_actor_binding.value[0].name != &quot;Computer&quot;:\n        context.report_error([&quot;dontKnowActor&quot;, x_actor_binding.variable.name])\n        return\n\n    x_location_binding = e_introduced_binding.value[&quot;DirectionalPreposition&quot;][&quot;Value&quot;][&quot;EndLocation&quot;]\n\n    def bound_location(location_item):\n        # Only allow moving to folders\n        if isinstance(location_item, Folder):\n            return True\n\n        else:\n            if hasattr(x_location_binding.value, &quot;exists&quot;) and location_item.exists():\n                context.report_error([&quot;cantDo&quot;, &quot;change directory to&quot;, x_location_binding.variable.name])\n\n            else:\n                context.report_error([&quot;notFound&quot;, x_location_binding.variable.name])\n\n    def unbound_location(location_item):\n        # Location is unbound, ask them to be more specific\n        context.report_error([&quot;beMoreSpecific&quot;])\n\n    # go_v_1 effectively has two arguments since it has x_actor by default and requires x_location from a preposition\n    for new_state in individual_style_predication_1(context,\n                                                    state,\n                                                    x_location_binding,\n                                                    bound_location,\n                                                    unbound_location,\n                                                    [&quot;cantDo&quot;, &quot;go&quot;, x_location_binding.variable.name]):\n        yield new_state.apply_operations([ChangeDirectoryOperation(new_state.get_binding(x_location_binding.variable.name))])\n\nThe handles=[... EventOption.required ...] clause on Predication tells the system that this predication requires a directional predication and the system ensures that it won't get called if it isn't there. That is why the code can just assume it is there and access the EndLocation key without checking for its existence first in this line:\nx_location_binding = e_introduced_binding.value[&quot;DirectionalPreposition&quot;][&quot;Value&quot;][&quot;EndLocation&quot;]\n\nThe function starts with code for making sure the user specified an actor and didn't say \"he goes to a folder\" or \"mary and bill go to a folder\". We only support \"you\".\nNext, the bound_location() function has code to check if the object passed in actually exists so that it can return a more specialized error if the user asks to go somewhere that doesn't exist. Otherwise, they'd get the error \"I can't go to X\" if the folder doesn't exist, which is a little obtuse.\nAnd finally, we handle this as an action verb, just like we handled \"delete\" in the Action Verbs topic, with one difference: _go_v_1 only has one non-event argument which represents \"who is doing the going\" (i.e. the actor). But, because we say we handle DirectionalPreposition in the introduced event and mark it as EventOption.required, it will always be there if this function is called. Thus, the location is effectively acting like a second x argument. So, in effect, we converted the predication to look just like _delete_v_1. \nSo, for the same reasons we had there, we can just handle the actor argument directly, and only have to call individual_style_predication_1(), treating it like a single x variable predication.  We are doing individual_style instead of combinatorial_style for the same reasons _delete_v_1 did: we don't have a way to implement the semantic of \"go to folder1 and folder2\" (let alone \"together\" or \"separately\"). So, go_v_1_comm will only handle going to a single location.\nChangeDirectoryOperation\nChanging the directory, just like deleting a file in the Action Verb topic, is modifying system state. So, we need to create an Operation to do the work:\nclass ChangeDirectoryOperation(object):\n    def __init__(self, folder_binding):\n        self.folder_binding = folder_binding\n\n    def apply_to(self, state):\n        state.file_system.change_directory(self.folder_binding)\n\nThe operation uses a built-in method of the FileSystem object to change the directory.\nPutting those three objects into hello_world.py, with the following reset() function:\ndef Example23_reset():\n    return FileSystemState(FileSystemMock([(True, &quot;/documents/file1.txt&quot;, {&quot;size&quot;: 1000}),\n                                           (False, &quot;/Desktop&quot;, {&quot;size&quot;: 10000000}),\n                                           (True, &quot;/Desktop/the yearly budget.txt&quot;, {&quot;size&quot;: 10000000}),\n                                           (True, &quot;/Desktop/blue&quot;, {&quot;size&quot;: 1000})],\n                                          &quot;/Desktop&quot;))\n\n\n... allows us to do this:\npython hello_world.py\n? where am i\n(Folder(name=/Desktop, size=10000000),)\n(there are more)\n\n? go to a folder\nDone!\n(there are more)\n\n? where am i\n(Folder(name=/documents, size=0),)\n(there are more)\n\nThe system says \"(there are more)\" in response to \"where am i\" because the user is in both \"/Desktop\" and \"/\". The reasons are described in the Combinations and Proper Responses topic. The same is true for \"go to a folder\" ... there are several folders.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Directional Propositions", "teaser":"Directional Prepositions\nLet's implement the verb \"go\" in hello_world.py to allow for moving around the file system in a simple way.\nThe phrase \"go to ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo100NonlogicalMeaning", "excerpt":"Solution Group Handlers and Non-logical Meaning\nSo far, all the examples we've built have a very \"logical\" behavior.  They are literally asking about things in the world, possibly in relation to other things. We ask about their existence, where they are, etc.\n? what file is large?\n? a file is large\n? where am i\n? go to a folder\n? students are lifting a table\n? which students are lifting the table\n\nThe system \"solves\" the MRS by finding variable assignments that make it true and then gives built-in answers like \"that is true\" or lists what was requested.\nNext, we are going to walk through how to implement phrases that aren't logical in that same way.  For example, imagine we want to implement a rudimentary help system for our file system example and we'd like users to be able to ask for help using phrases too. To find out what they can do, a user might ask, \"Do you have commands?\".\nWe'll start by adding the notion of a \"command\" object into the system, creating one for each of the commands we have so far (\"copy\" and \"go\") and implementing the new predications from the MRS, which are _have_v_1 and _command_n_1:\n[ &quot;Do you have commands?&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: ques TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ pron&lt;3:6&gt; LBL: h4 ARG0: x3 [ x PERS: 2 IND: + PT: std ] ]\n          [ pronoun_q&lt;3:6&gt; LBL: h5 ARG0: x3 RSTR: h6 BODY: h7 ]\n          [ _have_v_1&lt;7:11&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x8 [ x PERS: 3 NUM: pl IND: + ] ]\n          [ udef_q&lt;12:21&gt; LBL: h9 ARG0: x8 RSTR: h10 BODY: h11 ]\n          [ _command_n_1&lt;12:20&gt; LBL: h12 ARG0: x8 ] &gt;\n  HCONS: &lt; h0 qeq h1 h6 qeq h4 h10 qeq h12 &gt; ]\n\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\npronoun_q(x3,RSTR,BODY)            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _command_n_1(x8)\n                    \u2514\u2500 udef_q(x8,RSTR,BODY)\n                                        \u2514\u2500 _have_v_1(e2,x3,x8)\n\nOnce we do that, the interaction will look like this:\n? Do you have commands?\nYes.\n\n? Which commands do you have?\ncopy\ngo\n\nYou can almost hear the user say \"Ugh! Dumb computer\" after the first phrase.  A human would interpret that as \"Tell me what commands you have, if you have them\".  This is known in linguistics as \"Pragmatics\". The area of Pragmatics concerns the meaning of phrases that can't be \"logically\" or \"mechanically\" interpreted since they require taking into account the context the phrase is uttered in and potentially taking some implied leaps to understand what is actually meant.\nMaking \"Do you have commands?\" actually say something custom and not purely logical requires customizing how Perplexity responds when it finds a Solution Group. That is where we'll finish.\nLogical Interpretation\nFirst let's create a FileCommand class which represents commands in the system, using the same pattern we used for the File and Folder classes:\nclass FileCommand(UniqueObject):\n    def __init__(self, name):\n        super().__init__()\n        self.name = name\n        self._hash = hash(self.name)\n\n    def __hash__(self):\n        return self._hash\n\n    def __repr__(self):\n        return f&quot;Command(name={self.name})&quot;\n\n    def __eq__(self, obj):\n        return isinstance(obj, FileCommand) and str(self.name) == str(obj.name)\n\nThen, we need to add all the commands in the system to our state object, so they are returned when the system iterates through \"all objects in the system\" using the State.all_individuals() method:\n\nclass FileSystemState(State):\n    def __init__(self, file_system, current_user=None, actors=None):\n        super().__init__([])\n        self.file_system = file_system\n        self.current_user = file_system_example.objects.Actor(name=&quot;User&quot;, person=1, file_system=file_system) if current_user is None else current_user\n        self.actors = [self.current_user,\n                       file_system_example.objects.Actor(name=&quot;Computer&quot;, person=2, file_system=file_system)] if actors is None else actors\n        self.commands = [file_system_example.objects.FileCommand(&quot;copy&quot;), file_system_example.objects.FileCommand(&quot;go&quot;)]\n       \n    def all_individuals(self):\n        yield from self.file_system.all_individuals()\n        yield from self.actors\n        yield from self.commands \n        \n    ...\n\nWith that in place, we implement the predication that is generated when the user utters \"command\" so the system will be able to fill variables with these objects:\n@Predication(vocabulary, names=[&quot;_command_n_1&quot;])\ndef _command_n_1(context, state, x_binding):\n    def bound_variable(value):\n        if isinstance(value, file_system_example.objects.FileCommand):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        for item in state.all_individuals():\n            if bound_variable(item):\n                yield item\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\nAnd, finally, we can implement the _have_v_1 predication, so that it is true only for 2nd person phrases like \"do you have a command\", and so that the only thing anything \"has\" are commands:\n@Predication(vocabulary, names=[&quot;_have_v_1&quot;])\ndef _have_v_1(context, state, e_introduced_binding, x_actor_binding, x_target_binding):\n    def actor_have_target(item1, item2):\n        if isinstance(item2, file_system_example.objects.FileCommand):\n            return True\n        else:\n            context.report_error([&quot;doNotHave&quot;, x_actor_binding.variable.name, x_target_binding.variable.name])\n            return False\n\n    def all_actors_having_target(item2):\n        if False:\n            yield None\n\n    def all_targets_had_by_actor(item1):\n        if False:\n            yield None\n\n    if x_actor_binding.value is not None and len(x_actor_binding.value) == 1 and x_actor_binding.value[0] == Actor(name=&quot;Computer&quot;, person=2):\n        yield from in_style_predication_2(context,\n                                          state,\n                                          x_actor_binding,\n                                          x_target_binding,\n                                          actor_have_target,\n                                          all_actors_having_target,\n                                          all_targets_had_by_actor)\n\n    else:\n        context.report_error([&quot;doNotHave&quot;, x_actor_binding.variable.name, x_target_binding.variable.name])\n        return False\n        \n\nWith that code, we can now make the first phrases work:\n? do you have commands?\nYes.\n\n? which commands do you have?\n(Command(name=copy),)(Command(name=go),\n\nPragmatic Interpretation\nAs described in the Solution Group Algorithm topic, by default, when a solution group is found for a phrase, and the phrase is a yes/no question, Perplexity responds with \"Yes.\" To give a different response, we need to customize the way the system handles solution groups for this case.\nTo do this, we implement a solution group handler. It looks very much like the have_v_1 handler above, with a few differences:\n@Predication(vocabulary,\n             names=[&quot;solution_group__have_v_1&quot;])\ndef _have_v_1_group(context, state_list, e_introduced_binding_list, x_actor_variable_group, x_target_variable_group):\n    yield state_list\n\nFirst, instead of using \"_have_v_1\" as the name, we prefix the name with \"solution_group_\" and use \"solution_group__have_v_1\" as the name. This tells the system we are implementing a solution group handler.\nIt has the same number of arguments as the \"have_v_1\" function, but, because this is handling a solution group, the arguments contain objects that return multiple items: one item for each solution in the group.\nImplementing a solution group handler allows you to inspect each solution group that Perplexity finds and write custom logic to invalidate it or respond differently than the system would.  Yielding a list of state objects from the solution group handler indicates that this list of state objects is a valid solution group.  If nothing is yielded, the incoming list of state objects is invalidated and Perplexity continues looking for alternative solution groups.\nAs written in the code above, the Perplexity behavior won't change since the code simply yields the solution group, as is. This indicates it is a valid solution group. Since the code doesn't do anything to respond in a custom way, Perplexity continues responding with its default behavior.\nIf we want a different response, we could start by doing this:\n@Predication(vocabulary,\n             names=[&quot;solution_group__have_v_1&quot;])\ndef _have_v_1_group(context, state_list, e_introduced_binding_list, x_actor_variable_group, x_target_variable_group):\n    new_solution_group = [state_list[0].record_operations([RespondOperation(&quot;You can use the following commands: &#x27;copy&#x27; and &#x27;go&#x27;.&quot;)])]\n    yield new_solution_group\n\nInstead of yielding the original solution group, we now are only yielding the first solution, after modifying it to include a built-in operation called RespondOperation.  This is just like the DeleteOperation we created in an earlier section, but this operation's job is to print text for the user.  Putting a RespondOperation in any of the state objects we yield tells the system that we want to override the default output.  \nSo, now we get this:\n? Do you have commands?\nYou can use the following commands: copy and go\n\n? Which commands do you have?\nYou can use the following commands: copy and go\n\nBecause we are overriding the output, it really doesn't matter that we are changing the list of state objects in the solution group. Since they were only used to generate the default output, Perplexity won't pay attention to them anymore. Obviously we could instead run code to look up the commands in the system and dynamically build the string instead of hard coding it.\nConcepts\nWhile that works, it seems inefficient to have to create FileCommand objects, implement them in several places, have Perplexity go through the process of solving the MRS, only to throw it all way and print out a custom message! It turns out that work was not wasted. It would be required for other phrases like \"Do you have a 'copy' command?\" and many other scenarios.  But: it really is unnecessary to build up a solution group with all the commands to only throw it away for this scenario.\nInstead, we can use another Perplexity feature called a \"Concept\" to make it more efficient.  The idea is that, sometimes, instead of Perplexity assigning actual objects to variables, we'd like the \"concept\" of them (called a referring expression in linguistics) to be assigned.  I.e. instead of assigning x8 = FileCommand('copy'), we'd like to have x8 = {representation of whatever they said before it got resolved into an actual object} so that we can look at what they said \"conceptually\" instead of dealing with the actual instances of objects that it generated. This allows the solution group handler to just see if they are were talking about \"you\" having \"the concept of commands\" and, if so, generate the custom text.  This would be much more efficient.\nTo do this, we start by adding an alternative _command_n_1 predication since that is where the instances of commands get generated.  Perplexity allows adding more than one interpretation of a predication by creating more than one function and indicating that they use the same predication name. It treats them as alternatives and attempts to solve the MRS once using the first interpretation and then again using the next. \nIn the new interpretation, instead of yielding instances, we yield a Concept(\"command\") object.  The Concept object in Perplexity literally does nothing except tell the system it is an opaque \"Concept\" object.  Here are both interpretations:\n@Predication(vocabulary, names=[&quot;_command_n_1&quot;])\ndef _command_n_1_concept(context, state, x_binding):\n    def bound_variable(value):\n        if isinstance(value, Concept) and value == Concept(&quot;command&quot;):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield Concept(&quot;command&quot;)\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n                                           \n                                               \n@Predication(vocabulary, names=[&quot;_command_n_1&quot;])\ndef _command_n_1(context, state, x_binding):\n    def bound_variable(value):\n        if isinstance(value, file_system_example.objects.FileCommand):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        for item in state.all_individuals():\n            if bound_variable(item):\n                yield item\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\nWith that in place, we'll first get a set of solution groups that have the Concept(\"command\") object assigned to variables. Perplexity will do nothing with the Concept object except recognize that it is one and disable its logic to do any collective/cumulative/distributive solution group testing.  Instead, it will still create all potential solution groups and call your solution group handler.  It is now up to you to decide if they are valid readings. For this case it will be simple since we are going to treat any phrase of the form \"Do you have {x} commands?\" as a request to see the help string. That includes any of these:\nDo you have commands?\nDo you have 2 commands?\nDo you have several commands?\nDo you have any commands?\netc.\n\nNext, recall that the implementation of _have_v_1 only succeeds if the arguments are of type FileCommand:\n**@Predication(vocabulary, names=[&quot;_have_v_1&quot;])\ndef _have_v_1(context, state, e_introduced_binding, x_actor_binding, x_target_binding):\n    def actor_have_target(item1, item2):\n        if isinstance(item2, file_system_example.objects.FileCommand):\n            return True\n        else:\n            context.report_error([&quot;doNotHave&quot;, x_actor_binding.variable.name, x_target_binding.variable.name])\n            return False\n\n    ...\n    \n    if x_actor_binding.value is not None and len(x_actor_binding.value) == 1 and x_actor_binding.value[0] == Actor(name=&quot;Computer&quot;, person=2):\n        yield from in_style_predication_2(context,\n                                          state,\n                                          x_actor_binding,\n                                          x_target_binding,\n                                          actor_have_target,\n                                          all_actors_having_target,\n                                          all_targets_had_by_actor)**\n\n    else:\n        context.report_error([&quot;doNotHave&quot;, x_actor_binding.variable.name, x_target_binding.variable.name])\n        return False                                       \n\nThis means it will fail when Perplexity attempts to solve it using the new Concept object.  So, we need a new interpretation of _have_v_1 as well:\n@Predication(vocabulary, names=[&quot;_have_v_1&quot;])\ndef _have_v_1_concept(context, state, e_introduced_binding, x_actor_binding, x_target_binding):\n    def actor_have_target(item1, item2):\n        if isinstance(item2, Concept) and item2 == Concept(&quot;command&quot;):\n            return True\n        else:\n            context.report_error([&quot;doNotHave&quot;, x_actor_binding.variable.name, x_target_binding.variable.name])\n            return False\n\n    def all_actors_having_target(item2):\n        if False:\n            yield None\n\n    def all_targets_had_by_actor(item1):\n        if False:\n            yield None\n\n    if x_actor_binding.value is not None and len(x_actor_binding.value) == 1 and x_actor_binding.value[0] == Actor(name=&quot;Computer&quot;, person=2):\n        yield from in_style_predication_2(context,\n                                          state,\n                                          x_actor_binding,\n                                          x_target_binding,\n                                          actor_have_target,\n                                          all_actors_having_target,\n                                          all_targets_had_by_actor)\n\n    else:\n        context.report_error([&quot;doNotHave&quot;, x_actor_binding.variable.name, x_target_binding.variable.name])\n        return False\n\nFinally, we want to change our solution group handler to only be used when the conceptual interpretation is used. We'll let perplexity handle the original interpretation. To do this, we set the handles_interpretation argument of the Predication class to point to the interpretation we want to pair it with, like this:\n@Predication(vocabulary,\n             names=[&quot;solution_group__have_v_1&quot;],\n             handles_interpretation=_have_v_1_concept)\ndef _have_v_1_group(context, state_list, e_introduced_binding_list, x_actor_variable_group, x_target_variable_group):\n    yield [state_list[0].record_operations([RespondOperation(&quot;You can use the following commands: copy and go&quot;)])]\n\nNow, we can try all the phrases below:\n? which commands do you have?\nYou can use the following commands: copy and go\n\n? do you have a command?\nYou can use the following commands: copy and go\n\n? do you have 2 commands?\nYou can use the following commands: copy and go\n\n? do I have a command?\nyou do not have a command\n\n? do I have a file?\nyou do not have a file\n\n? do you have a file?\nus do not have a file\n\nFinal Loose Ends\nThree things to note here:\nFirst, all those phrases end up using the conceptual interpretation. The instance-based interpretation is currently unused. The most likely use for it would be for phrases like \"Do you have a copy command?\" or \"How do I use the copy command?\", i.e. in phrases where the user is talking about a particular instance, and not the general concept of commands. \nSecond, there also a whole set of phrases that happen to work that probably shouldn't:\n? did you have a command?\nYou can use the following commands: copy and go\n\n? you are having a command?\nYou can use the following commands: copy and go\n\n? Are you having a command?\nYou can use the following commands: copy and go\n\nFinally, there are some phrases that point to another area we need to focus on, global criteria:\n? Do you have 3 commands?\nYou can use the following commands: copy and go\n\n? Do you have many commands?\nYou can use the following commands: copy and go\n\n? Do you have several commands?\nYou can use the following commands: copy and go\n\nAll of these phrases are using words like \"several\" or \"3\" which quantify how many of something the speaker is interested in. When we implement a solution group handler we take over responsibility for doing the counting, and we're not doing that.  Let's do that next.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Solution Group Handlers and Non-logical Meaning", "teaser":"Solution Group Handlers and Non-logical Meaning\nSo far, all the examples we've built have a very \"logical\" behavior.  They are literally asking about  ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo105GlobalCriteria", "excerpt":"Solution Group Handlers and Global Criteria\nIn the previous section we implemented variations of \"Do you have commands?\" by implementing a custom solution group handler, but we didn't complete it.  Since there are only two commands, we should do a better job on the following phrases that succeed, and shouldn't:\n? Do you have 3 commands?\nYou can use the following commands: copy and go\n\n? Do you have many commands?\nYou can use the following commands: copy and go\n\n? Do you have several commands?\nYou can use the following commands: copy and go\n\n? Do you have the command?\nYou can use the following commands: copy and go\n\nAll of these phrases are using words like \"several\" or \"3\" which quantify how many of something the speaker is interested in. The last uses \"the\" which implies there is just one that is so obvious the system should know which one it is. When we implement a solution group handler we take over responsibility for doing the counting, and we're not yet doing that.\nInspecting Global Criteria\nWhen a speaker uses a phrase that constrains the solution group using numeric constraints or \"the\", these constraints are tracked with the arguments in the solution group handler and can be inspected:\nLet's change our have_v_1 solution group handler to output these constraints so we can see them:\n@Predication(vocabulary,\n             names=[&quot;solution_group__have_v_1&quot;],\n             handles_interpretation=_have_v_1_concept)\ndef _have_v_1_group(context, state_list, e_introduced_binding_list, x_actor_variable_group, x_target_variable_group):\n    print(f&quot;x_actor_binding constraints: {x_actor_variable_group.variable_constraints}&quot;)\n    print(f&quot;x_target_binding constraints: {x_target_variable_group.variable_constraints}&quot;)\n    yield [state_list[0].record_operations([RespondOperation(&quot;You can use the following commands: copy and go&quot;)])]\n\nAnd then run it:\n? do you have commands\nx_actor_binding constraints: {x3: min=1, max=inf, global=None, required_values=None, pred=pronoun_q(x3)}\nx_target_binding constraints: {x8: min=2, max=inf, global=None, required_values=None, pred=udef_q(x8)}\nYou can use the following commands: copy and go\n\n? /show\nUser Input: do you have commands\n1 Parses\n\n***** CHOSEN Parse #0:\nSentence Force: ques\n[ &quot;do you have commands&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: ques TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ pron&lt;3:6&gt; LBL: h4 ARG0: x3 [ x PERS: 2 IND: + PT: std ] ]\n          [ pronoun_q&lt;3:6&gt; LBL: h5 ARG0: x3 RSTR: h6 BODY: h7 ]\n          [ _have_v_1&lt;7:11&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x8 [ x PERS: 3 NUM: pl IND: + ] ]\n          [ udef_q&lt;12:20&gt; LBL: h9 ARG0: x8 RSTR: h10 BODY: h11 ]\n          [ _command_n_1&lt;12:20&gt; LBL: h12 ARG0: x8 ] &gt;\n  HCONS: &lt; h0 qeq h1 h6 qeq h4 h10 qeq h12 &gt; ]\n\n-- CHOSEN Parse #0, CHOSEN Tree #0: \n\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\npronoun_q(x3,RSTR,BODY)            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _command_n_1(x8)\n                    \u2514\u2500 udef_q(x8,RSTR,BODY)\n                                        \u2514\u2500 _have_v_1(e2,x3,x8)\n\nYou can see from the output that the constraints on x3, which is where \"you\" is represented, are between 1 and inf (infinity):\nx_actor_binding constraints: {x3: min=1, max=inf, global=None, required_values=None, pred=pronoun_q(x3)}\n\nThat's because, if you look at the MRS, x3 doesn't indicate one way or the other if \"you\" is plural or singular \"you\", and there aren't any other predications that would constrain things.\nFor x8 we get a constraint between 2 and infinity.  Looking at the MRS you can see that x8 has the properties [ x PERS: 3 NUM: pl IND: + ] set in the have_v_1 predication, which indicates plurality.  I.e. between 2 and infinity:\nx_target_binding constraints: {x8: min=2, max=inf, global=None, required_values=None, pred=udef_q(x8)}\n\nRunning this:\n? Do you have 3 commands\nx_actor_binding constraints: {x3: min=1, max=inf, global=None, required_values=None, pred=pronoun_q(x3)}\nx_target_binding constraints: {x8: min=3, max=3, global=None, required_values=None, pred=card(3)}\nYou can use the following commands: copy and go\n\nShows how, if the speaker says \"3\", the constraints are set to a min and max of \"3\".\nLet's try:\n? Do you have the command?\nx_actor_binding constraints: {x3: min=1, max=inf, global=None, required_values=None, pred=pronoun_q(x3)}\nx_target_binding constraints: {x8: min=1, max=1, global=GlobalCriteria.all_rstr_meet_criteria, required_values=None, pred=_the_q(x8)}\nYou can use the following commands: copy and go\n\nThe word \"the\" means \"the one and only\" or \"the 1 group\" and so it has a min/max of 1 and it has global=GlobalCriteria.all_rstr_meet_criteria. all_rstr_meet_criteria is how \"the 1 group\" gets handled.  It means: all of the things that \"the\" refers to in its RSTR must be true of its BODY. Let's look at the MRS tree to understand:\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\npronoun_q(x3,RSTR,BODY)            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _command_n_1(x8)\n                    \u2514\u2500 _the_q(x8,RSTR,BODY)\n                                        \u2514\u2500 _have_v_1(e2,x3,x8)\n\nSince all_rstr_meet_criteria is set on x8, it is referring to the RSTR and BODY of: _the_q(x8,RSTR,BODY).\nThe RSTR is simply _command_n_1(x8), so all commands in the system are being referred to.  The BODY is set to _have_v_1(e2,x3,x8).  So, as long as \"you\" have \"all\" the commands in the system, this should be true.\nWhat about \"The commands are copy\".  This would put \"all commands\" in the RSTR and \"being copy\" in the BODY which is certainly not true for all of them, so it should fail.\nWhat about this:\n? Do you have the 3 commands?\nx_actor_binding constraints: {x3: min=1, max=inf, global=None, required_values=None, pred=pronoun_q(x3)}\nx_target_binding constraints: {x8: min=3, max=3, global=GlobalCriteria.all_rstr_meet_criteria, required_values=None, pred=_the_q(x8)}\nYou can use the following commands: copy and go\n\n? /show\n...\n                                               \u250c\u2500\u2500 _command_n_1(x8)\n                                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)    \u2502             \u2502\n               \u2502                   \u2502             \u2514 card(3,e14,x8)\npronoun_q(x3,RSTR,BODY)            \u2502\n                    \u2514\u2500 _the_q(x8,RSTR,BODY)\n                                        \u2514\u2500 _have_v_1(e2,x3,x8)\n\nThis one says x8 which is _the_q(x8,RSTR,BODY) must have 3 different values in it. And: all commands in the system should be true of the body. While it is certainly true that the system \"has\" all the commands, it is not true that there are 3 of them, so this is false.\nNormally, Perplexity handles checking these constraints and doesn't consider a solution group to be valid unless it meets them all. But when you build a solution group handler, you are telling the system: I am doing something custom with the solution group and thus I will also be responsible for making sure the constraints are met on it.\nDifferent Interpretations of Constraints\nTo determine if constraints are met, you first need to make a decision about what the speaker meant by the phrase. This isn't always obvious. Consider the following phrases:\nDo you have more than 2 chairs?\n\nIf Aiden walks into an office and is looking for a place to sit, he is probably asking about instances of chairs.\nIf Aiden walks into a furniture store wanting to buy a chair, he is probably asking about types of chairs ... unless he's been talking the salesman about a particular type and is wondering how many they have in stock.\nDo you have the steak?\n\nIf Elie is talking to a waiter and there is often a steak special, she probably means \"is the conceptual type of steak you usually have on the menu today?\".\nIf instead she is talking to her friend about a particular steak he bought, she probably means the instance.\nDo you have two menus?\n\nIf Zahra is in a restaurant that has several types of menus, maybe for lunch and dinner, she might be referring to types of menus.\nShe could also mean \"one menu for me and one for my Mom\".\nWhat these all have in common is that hints about what the speaker means can be found in the context, or scenario, that is occurring. It is often not obvious which is meant, a priori. So, you'll need to determine which is meant given your scenario. Note that you can also implement both as different interpretations and try each to see which works, or reorder them based on the current context.  You may also decide that the constraint doesn't matter. If there are no steaks available in your vegetarian restaurant just about any question about a steak should be met with, \"I'm so sorry, we don't have those here.\"\nThe concept_meets_constraint Helper\nRegardless of which you decide, you need to write the code to make sure the constraints are met.  As shown above, the constraints are available in the variable_constraints property of each variable group in your solution group handler. That code is repeated below:\n@Predication(vocabulary,\n             names=[&quot;solution_group__have_v_1&quot;],\n             handles_interpretation=_have_v_1_concept)\ndef _have_v_1_group(context, state_list, e_introduced_binding_list, x_actor_variable_group, x_target_variable_group):\n    print(f&quot;x_actor_binding constraints: {x_actor_variable_group.variable_constraints}&quot;)\n    print(f&quot;x_target_binding constraints: {x_target_variable_group.variable_constraints}&quot;)\n    ...\n    \n? do you have commands\nx_actor_binding constraints: {x3: min=1, max=inf, global=None, required_values=None, pred=pronoun_q(x3)}\nx_target_binding constraints: {x8: min=2, max=inf, global=None, required_values=None, pred=udef_q(x8)}\n\nHowever, very often you'll just need to decide if the intended meaning is about concepts or instances and want to see if the concepts and instances in the solution group match them. If your solution group is dealing with concepts in the variable (which is most commonly why you'd create a solution group), you can use a Perplexity function called concept_meets_constraint. This function checks a particular concept-valued variable to see if it meets the global constraints. Let's go through the implementation of this function to see how it works.\nThe function assumes the variable in question contains concepts and requires that you give it some information about the concepts in the solution group, as well as some information about the world the phrase was uttered in. Let's go through the incoming arguments first:\ndef concept_meets_constraint(context, \n                             tree_info, \n                             variable_constraints, \n                             concept_count, \n                             concept_in_scope_count, \n                             instance_count, \n                             check_concepts, \n                             variable):\n    ...\n\nThe first two arguments are the context and tree_info from the solution group handler which can be retrieved like this:\n@Predication(vocabulary,\n             names=[&quot;solution_group__have_v_1&quot;],\n             handles_interpretation=_have_v_1_concept)\ndef _have_v_1_group(context, state_list, e_introduced_binding_list, x_actor_variable_group, x_target_variable_group):\n        success = concept_meets_constraint(context,\n                                           state_list[0].get_binding(&quot;tree&quot;).value[0]\n                                           ...\n\nconcept_count refers to the number of different concepts that are in this variable in the solution group.  To gather the different concepts in a variable like x_target, we can use a Python set object like this:\ndef _have_v_1_group(context, state_list, e_introduced_binding_list, x_actor_variable_group, x_target_variable_group):\n    target_concepts = set([x.value for x in x_target_variable_group.solution_values])\n    target_concept_count = len(target_concepts)\n\nWe use a set because we want unique concepts. The solution group may have several solutions that have the same concept and we only want to count that as a single concept.\nThe next argument is concept_in_scope_count. In Perplexity, \"in-scope concepts\" are how you indicate how many of the set of concepts you just gathered are \"in-scope\", meaning that there is a particular concept that it would be appropriate to say \"the\" with.  Some examples:\n\"Please give me the menu\": there is \"one menu\" that they are obviously referring to\n\n\"Where are the girls?\": there are a particular set of girls that we are talking about\n\n\"Do you still have the chair\"\n\netc.\nHow you decide which concepts make sense to be \"in-scope\" is up to you, but is obviously very context dependent. If you have a function that determines it based on the state of the world, you'd do something like this:\n    concept_in_scope_count = 0\n    for concept in target_concepts:\n        if in_scope(context, state, concept):\n            concept_in_scope_count += 1\n\ninstance_count refers to how many instances of those concepts are in the world.  This is used for phrases like \"Do you have 2 chairs?\" interpreted as the user referring to instances (not types of) chairs.  So, you need a way to find out how many instances there are for all the concepts in the solution group.  Below we use an \".instances()\" method of Concept which you'll need to implement to generate the instances based on how you've implemented your Concept object:\n    instances = []\n    for concept in concepts:\n        this_concept_instances = list(concept.instances(context, state))\n        # If we are dealing with instances and one of the concepts generates \n        # zero, we don&#x27;t want to just count the others\n        # and succeed.  e.g. &quot;I have two ice creams and bowls&quot; should not \n        # succeed if there are no bowls\n        if len(this_concept_instances) == 0:\n            instances = None\n            break\n\n        instances += this_concept_instances\n    if instances is None:\n        # We can fail immediately\n        return\n    else:\n        instance_count = len(instances)\n\ncheck_concepts is True if you are interpreting the criteria as counting concepts, otherwise instances are checked.\nvariable is the final argument, and is simply the name of the MRS variable being checked.\nNow that we've seen all the arguments, here they are being used to check for an interpretation where the speaker is asking about having the concept of, not instances of, something. For example, \"Do you have specials?\", referring to the existence of specials, not how many are left of them. Since the implementation of most of this depends on your implementation, it isn't a library function. However, it will be the same for most of your predications so you can create one of your own:\n@Predication(vocabulary,\n             names=[&quot;solution_group__have_v_1&quot;],\n             handles_interpretation=_have_v_1_concept)\ndef _have_v_1_group(context, state_list, e_introduced_binding_list, x_actor_variable_group, x_target_variable_group):\n    # Count the concepts\n    target_concepts = set([x.value for x in x_target_variable_group.solution_values])\n    target_concept_count = len(target_concepts)\n    \n    # Count the in-scope concepts\n    concept_in_scope_count = 0\n    for concept in target_concepts:\n        if in_scope(context, state, concept):\n            concept_in_scope_count += 1\n\n    # Count the instances\n    instances = []\n    for concept in concepts:\n        this_concept_instances = list(concept.instances(context, state))\n        # If we are dealing with instances and one of the concepts generates \n        # zero, we don&#x27;t want to just count the others\n        # and succeed.  e.g. &quot;I have two ice creams and bowls&quot; should not \n        # succeed if there are no bowls\n        if len(this_concept_instances) == 0:\n            instances = None\n            break\n\n        instances += this_concept_instances\n        \n    if instances is None:\n        # We can fail immediately\n        return\n    else:\n        instance_count = len(instances)\n    \n    success = concept_meets_constraint(context=context,\n                                       tree_info=state_list[0].get_binding(&quot;tree&quot;).value[0],\n                                       variable_constraints=x_target_variable_group.variable_constraints,\n                                       concept_count=target_concept_count,\n                                       concept_in_scope_count=concept_in_scope_count,\n                                       instance_count=instance_count,\n                                       check_concepts=True,\n                                       variable=x_what_variable_group.solution_values[0].variable.name)\n    \n    if success:\n        # Your custom code here\n\nThe concept_meets_constraint Implementation\nNow let's go through how concept_meets_constraint uses these arguments to check if a solution group meets its constraints. It is useful to understand since you may need different logic for some of your predications. This function just implements the most common behavior.\nFirst, default min and max constraints are filled in the the variable doesn't have them. Then, it branches based on whether the caller asked to check concepts or instances.  First let's do concepts.  The comments in the code describe what is happening:\ndef concept_meets_constraint(context,\n                             tree_info,\n                             variable_constraints,\n                             concept_count,\n                             concept_in_scope_count,\n                             instance_count,\n                             check_concepts,\n                             variable):\n    min_size = variable_constraints.min_size if variable_constraints is not None else 1\n    max_size = variable_constraints.max_size if variable_constraints is not None else float(inf)\n    \n    if check_concepts:\n        # We are making sure the constraints succeed against the concept count\n        if variable_constraints is not None and variable_constraints.global_criteria == perplexity.plurals.GlobalCriteria.all_rstr_meet_criteria:\n            # If the user says &quot;the specials&quot; or &quot;the 2 menus&quot; they are putting a criteria\n            # on the *concept*, not the instances. I.e. there should be\n            # 2 *types* of menus in scope. Examples:\n            #\n            # &quot;Do you have the 2 menus?&quot; (interpreted as meaning classes of menus)\n            # &quot;Are the 2 specials good?&quot; (ditto)\n            # &quot;Do you have the steak?&quot; (ditto)\n            #\n            # Furthermore, because they said &quot;the&quot;, they are referring to a &quot;in-scope concept&quot;, \n            # i.e. &quot;the menu&quot;, not just any old menu. It is a special one. This is modelled as \n            # having the concept be &quot;in scope&quot;. The generic type, &quot;menu&quot; still exists, but is\n            # a type that is out of scope. If they said &quot;What is generally on a menu?&quot; they&#x27;d\n            # be referring to that generic type.\n            check_count = concept_in_scope_count\n\n        else:\n            # The user didn&#x27;t say &quot;the&quot;, so the concept doesn&#x27;t need to be &quot;in-scope&quot; and so\n            # they are talking about the generic type (as described above). Examples:\n            #\n            # &quot;How many specials do you have?&quot; (meaning classes of specials)\n            # &quot;Are 2 specials available&quot; (ditto)\n            # &quot;What chairs do you have?&quot; (ditto)\n            # &quot;specials are cheaper&quot; (ditto)\n            # &quot;Are specials available?&quot; (ditto)\n            # &quot;Can I get a table?&quot; (ditto)\n            check_count = concept_count\n\n        if check_count == 0:\n            introducing_predication = perplexity.tree.find_quantifier_from_variable(tree_info[&quot;Tree&quot;], variable)\n            context.report_error([&quot;phase2ZeroCount&quot;, [&quot;AtPredication&quot;, introducing_predication.args[2], variable]], force=True, phase=2)\n            return False\n\n        if check_count &lt; min_size:\n            context.report_error([&quot;phase2LessThan&quot;, [&quot;AfterFullPhrase&quot;, variable], min_size], force=True, phase=2)\n            return False\n\n        elif check_count &gt; max_size:\n            context.report_error([&quot;phase2MoreThanN&quot;, [&quot;AfterFullPhrase&quot;, variable], max_size], force=True, phase=2)\n            return False\n\n        return True\n    \n    ...\n\nThe real work for checking concepts is to decide whether the word \"the\" has been used. This determines whether we check the \"in-scope concept\" count or just the \"concept count\".  The rest of the code is just comparing the resulting number to the min and max sizes and reporting an error if it isn't in range.\nThe second part of the function gets run when check_concepts=False. In this case, the speaker is talking about a concept, but the ultimate thing that needs to be manipulated is an instance.  E.g. to implement \"I want a menu\", our code will need to find a menu and give it to the speaker. \nHere again the only subtlety is dealing with \"the\" and making sure we interpret phrases like, \"give me the two menus\" properly. Even if they are ultimately wanting instances, \"the two menus\" will need to be checked to make sure that we actually do have two types of menu, so that we can then give them both.\ndef concept_meets_constraint(context,\n                             tree_info,\n                             variable_constraints,\n                             concept_count,\n                             concept_in_scope_count,\n                             instance_count,\n                             check_concepts,\n                             variable):\n    \n    ...\n    \n    else:\n        # The user is talking about a concept, but, ultimately, our code will need to check if there are \n        # enough instances. Examples:\n        #   &quot;We want a menu&quot; --&gt; &quot;We want 1 instance of a menu concept&quot;\n        #   &quot;We want a table&quot; --&gt; &quot;We want 1 instance of a table concept&quot;\n        #   &quot;We want tables/menus&quot; --&gt; &quot;We want instances of the tables&quot;\n        #   &quot;We want the menu(s)&quot; --&gt; &quot;We want an undefined number of instances of \n        #                             &#x27;the one and only table concept in scope&#x27;&quot;\n        #   &quot;We want the specials&quot; --&gt; &quot;We want an undefined number of instances of \n        #                              &#x27;the (undefined number of) the special concepts in scope&#x27;&quot;\n        #\n        # First, check to make sure we the system has the right number of &quot;in scope&quot; concepts if &quot;the&quot; is used,\n        # as in &quot;I&#x27;d like the 2 menus&quot; (if there are a drink menu and a food menu)\n        if variable_constraints is not None and variable_constraints.global_criteria == perplexity.plurals.GlobalCriteria.all_rstr_meet_criteria:\n            check_count = concept_in_scope_count\n            if check_count == 0:\n                context.report_error([&quot;conceptNotFound&quot;, variable], force=True, phase=2)\n                return False\n\n            if check_count &lt; min_size:\n                context.report_error([&quot;phase2LessThan&quot;, [&quot;AfterFullPhrase&quot;, variable], min_size], force=True, phase=2)\n                return False\n\n            elif check_count &gt; max_size:\n                context.report_error([&quot;phase2MoreThanN&quot;, [&quot;AfterFullPhrase&quot;, variable], max_size], force=True, phase=2)\n                return False\n\n        # Then, regardless of whether &quot;the&quot; was used, check to make sure there are enough instances to \n        # meet the criteria since that is what we are ultimately looking for\n        check_count = instance_count\n        if check_count == 0:\n            context.report_error([&quot;conceptNotFound&quot;, variable], force=True, phase=2)\n            return False\n\n        if check_count &lt; min_size:\n            context.report_error([&quot;phase2LessThan&quot;, [&quot;AfterFullPhrase&quot;, variable], min_size], force=True, phase=2)\n            return False\n\n        # As long as the instances are &gt;= min_size, we are good because the caller is responsible\n        # for limiting the number of instances being dealt with.\n        # For example: &quot;We&#x27;d like a table for 2&quot;. If there are 20 tables, the caller\n        # is responsible for giving only 1\n        return True\n\nActually Doing Something\nThe work to actually do something in the system was not covered above.  We walked through how process a phrase like \"Give me a menu\" by interpreting it as a \"Conceptual\" menu and building a solution group handler in the section on implementing non-logical meaning, and then checking global constraints in the description above. Once all that succeeds, you still need to do the thing.  \nHow to do that is up to you.  \nComprehensive source for the completed tutorial is available here\n\n", "title":"Solution Group Handlers and Global Criteria", "teaser":"Solution Group Handlers and Global Criteria\nIn the previous section we implemented variations of \"Do you have commands?\" by implementing a custom solu ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo110HandlingTenses", "excerpt":"Handling Tenses\nIn the previous section on Non-logical Meaning, we saw how, in implementing the predications to support \"Do you have commands?\" we accidentally supported phrases like:\n? did you have a command?\nYou can use the following commands: copy and go\n\n? you are having a command?\nYou can use the following commands: copy and go\n\n? Are you having a command?\nYou can use the following commands: copy and go\n\nWhile they aren't all that likely to be uttered, they really shouldn't work.  And, it makes you wonder what other phrases might work that could be really confusing. When building predications in Perplexity it is always a good idea to be intentional about the phrases you want to support (and test them). When users get unexpected results from utterances (because they weren't anticipated), they lose faith in the ability of the system to understand them.\nSpecifying Required Properties\nTo support restricting when predications get used, and support less accidental misunderstandings like the ones above, Perplexity allows you to specify the types of phrases your predication is meant to support. It will automatically skip the predication if the phrase doesn't match. It does this by matching MRS variable properties of the MRS Index of the phrase. \nRecall that the MRS Index variable is the introduced variable for the predication that is \"the syntactic head of the phrase\". That predication represents what the phrase is \u201cabout\u201d or \u201cbuilt around\". Usually, it is just the main verb. So, for \"Do you have commands?\", it would be _have_v_1. There are variable properties specified in the MRS that indicate tense information about that verb, and you can specify which tenses your predication is meant to support using those.\nWe can see these properties by inspecting the MRS using /show:\n? Do you have commands?\nYou can use the following commands: copy and go\n\n? /show\nUser Input: Do you have commands?\n1 Parses\n\n***** CHOSEN Parse #0:\nSentence Force: ques\n[ &quot;Do you have commands?&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: ques TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ pron&lt;3:6&gt; LBL: h4 ARG0: x3 [ x PERS: 2 IND: + PT: std ] ]\n          [ pronoun_q&lt;3:6&gt; LBL: h5 ARG0: x3 RSTR: h6 BODY: h7 ]\n          [ _have_v_1&lt;7:11&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x8 [ x PERS: 3 NUM: pl IND: + ] ]\n          [ udef_q&lt;12:21&gt; LBL: h9 ARG0: x8 RSTR: h10 BODY: h11 ]\n          [ _command_n_1&lt;12:20&gt; LBL: h12 ARG0: x8 ] &gt;\n  HCONS: &lt; h0 qeq h1 h6 qeq h4 h10 qeq h12 &gt; ]\n\nThe INDEX variable of the MRS is e2, which is the introduced variable (i.e. ARG0) of _have_v_1, as expected.  You can see that e2 has some properties specified:\n  INDEX: e2 [ e SF: ques TENSE: pres MOOD: indicative PROG: - PERF: - ]\n\n... that indicate this is a question (SF: ques), it is present tense (TENSE: pres), etc.  All of the properties are described in the MRS variable properties section. If we only want our _have_v_1 predications called when the verb is in exactly that tense (which we do), we can declare those properties as the only ones supported using the properties argument of the Predication object:\n@Predication(vocabulary,\n             names=[&quot;_have_v_1&quot;],\n             properties=[{&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}]\n             )\ndef _have_v_1_concept(context, state, e_introduced_binding, x_actor_binding, x_target_binding):\n    ...\n    \n@Predication(vocabulary,\n             names=[&quot;_have_v_1&quot;],\n             properties=[{&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}]\n             )\ndef _have_v_1(context, state, e_introduced_binding, x_actor_binding, x_target_binding):\n    ...\n\nWith just that change, the follow results:\n? Do you have commands?\nYou can use the following commands: copy and go\n\n? did you have a command?\nI don&#x27;t understand the way you are using: have\n\n? you are having a command?\nI don&#x27;t understand the way you are using: have\n\n? Are you having a command?\nI don&#x27;t understand the way you are using: have\n\nThe system ignores the predication unless it matches the properties of the phrase. If it can't find one that works, it gives an \"I didn't understand\" message.\nUsing Phrases to Specify Properties\nCollecting properties manually can get annoying, and they don't provide good documentation for which phrases a predication is meant to support. So, Perplexity provides an additional approach to you help you build these: Phrases.  Instead of populating the properties argument directly, you can provide phrases and Perplexity will help you work out the properties.\nIf we instead started with this code, which specifies the phrase we want to support but doesn't supply any properties for it (i.e. specifies None where the properties should be):\n@Predication(vocabulary,\n             names=[&quot;_have_v_1&quot;],\n             phrases={&quot;What commands do you have?&quot;: None}\n             )\ndef _have_v_1_concept(context, state, e_introduced_binding, x_actor_binding, x_target_binding):\n    ...\n\n... when you run the sample, you get this failure:\nGenerating phrase properties for &lt;function _have_v_1_concept at 0x7f8364280790&gt;...\n   parsing example: &#x27;What commands do you have?&#x27; ...\n      &#x27;None&#x27; did not match properties in any of the following parses:\n      _which_q(x5,_command_n_1(x5),pronoun_q(x3,pron(x3),_have_v_1(e2,x3,x5))): {&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n      pronoun_q(x9,pron(x9),basic_free_relative_q(x3,[_command_n_1(x3), _do_v_1(e8,x3,x9)],ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      basic_free_relative_q(x3,pronoun_q(x9,pron(x9),[_command_n_1(x3), _do_v_1(e8,x3,x9)]),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      basic_free_relative_q(x3,pronoun_q(x9,pron(x9),[_command_n_1(x3), _do_v_1(e8,x3,x9)]),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x9,pron(x9),basic_free_relative_q(x2,[_command_n_1(x2), _do_v_1(e8,x2,x9)],ellipsis_ref(e15,i3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x9,basic_free_relative_q(x2,[_command_n_1(x2), _do_v_1(e8,x2,x9)],pron(x9)),ellipsis_ref(e15,i3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      basic_free_relative_q(x2,pronoun_q(x9,pron(x9),[_command_n_1(x2), _do_v_1(e8,x2,x9)]),ellipsis_ref(e15,i3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      basic_free_relative_q(x2,pronoun_q(x9,pron(x9),[_command_n_1(x2), _do_v_1(e8,x2,x9)]),ellipsis_ref(e15,i3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x10,pron(x10),basic_free_relative_q(x5,[_command_n_1(x5), _do_v_1(e9,x5,x10)],ellipsis_ref(e2,i3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x10,basic_free_relative_q(x5,[_command_n_1(x5), _do_v_1(e9,x5,x10)],pron(x10)),ellipsis_ref(e2,i3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      basic_free_relative_q(x5,pronoun_q(x10,pron(x10),[_command_n_1(x5), _do_v_1(e9,x5,x10)]),ellipsis_ref(e2,i3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      basic_free_relative_q(x5,pronoun_q(x10,pron(x10),[_command_n_1(x5), _do_v_1(e9,x5,x10)]),ellipsis_ref(e2,i3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x9,pron(x9),basic_free_relative_q(x2,[_command_n_1(x2), _do_v_1(e8,x2,x9)],ellipsis_ref(e15,i3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x9,basic_free_relative_q(x2,[_command_n_1(x2), _do_v_1(e8,x2,x9)],pron(x9)),ellipsis_ref(e15,i3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      basic_free_relative_q(x2,pronoun_q(x9,pron(x9),[_command_n_1(x2), _do_v_1(e8,x2,x9)]),ellipsis_ref(e15,i3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      basic_free_relative_q(x2,pronoun_q(x9,pron(x9),[_command_n_1(x2), _do_v_1(e8,x2,x9)]),ellipsis_ref(e15,i3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x16,pron(x16),free_relative_q(x4,udef_q(x10,_command_n_1(x10),[thing(x4), _have_v_1(e20,x16,x4), _do_v_1(e14,x10,x4)]),unknown(e2,x4))): {&#x27;SF&#x27;: &#x27;prop&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n      pronoun_q(x11,pron(x11),pronoun_q(x17,pron(x17),free_relative_q(x3,[thing(x3), _command_v_1(e8,x3,_do_v_1(e16,x11,x17))],ellipsis_ref(e2,x3)))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x11,pron(x11),free_relative_q(x3,pronoun_q(x17,pron(x17),[thing(x3), _command_v_1(e8,x3,_do_v_1(e16,x11,x17))]),ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x11,pron(x11),free_relative_q(x3,[thing(x3), _command_v_1(e8,x3,pronoun_q(x17,pron(x17),_do_v_1(e16,x11,x17)))],ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x17,pron(x17),pronoun_q(x11,pron(x11),free_relative_q(x3,[thing(x3), _command_v_1(e8,x3,_do_v_1(e16,x11,x17))],ellipsis_ref(e2,x3)))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x17,pron(x17),free_relative_q(x3,pronoun_q(x11,pron(x11),[thing(x3), _command_v_1(e8,x3,_do_v_1(e16,x11,x17))]),ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x17,pron(x17),free_relative_q(x3,[thing(x3), _command_v_1(e8,x3,pronoun_q(x11,pron(x11),_do_v_1(e16,x11,x17)))],ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      free_relative_q(x3,pronoun_q(x11,pron(x11),pronoun_q(x17,pron(x17),[thing(x3), _command_v_1(e8,x3,_do_v_1(e16,x11,x17))])),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      free_relative_q(x3,pronoun_q(x11,pron(x11),[thing(x3), _command_v_1(e8,x3,pronoun_q(x17,pron(x17),_do_v_1(e16,x11,x17)))]),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      free_relative_q(x3,pronoun_q(x17,pron(x17),pronoun_q(x11,pron(x11),[thing(x3), _command_v_1(e8,x3,_do_v_1(e16,x11,x17))])),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      free_relative_q(x3,pronoun_q(x17,pron(x17),[thing(x3), _command_v_1(e8,x3,pronoun_q(x11,pron(x11),_do_v_1(e16,x11,x17)))]),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      free_relative_q(x3,[thing(x3), _command_v_1(e8,x3,pronoun_q(x11,pron(x11),pronoun_q(x17,pron(x17),_do_v_1(e16,x11,x17))))],ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      free_relative_q(x3,[thing(x3), _command_v_1(e8,x3,pronoun_q(x17,pron(x17),pronoun_q(x11,pron(x11),_do_v_1(e16,x11,x17))))],ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      free_relative_q(x3,[thing(x3), _command_v_1(e8,x3,pronoun_q(x17,pron(x17),pronoun_q(x11,pron(x11),_do_v_1(e16,x11,x17))))],ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x14,pron(x14),free_relative_q(x3,udef_q(x9,_command_n_1(x9),[thing(x3), _do_v_1(e13,x9,x3,x14)]),ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x14,pron(x14),udef_q(x9,_command_n_1(x9),free_relative_q(x3,[thing(x3), _do_v_1(e13,x9,x3,x14)],ellipsis_ref(e2,x3)))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      free_relative_q(x3,pronoun_q(x14,pron(x14),udef_q(x9,_command_n_1(x9),[thing(x3), _do_v_1(e13,x9,x3,x14)])),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      free_relative_q(x3,udef_q(x9,_command_n_1(x9),pronoun_q(x14,pron(x14),[thing(x3), _do_v_1(e13,x9,x3,x14)])),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      udef_q(x9,_command_n_1(x9),pronoun_q(x14,pron(x14),free_relative_q(x3,[thing(x3), _do_v_1(e13,x9,x3,x14)],ellipsis_ref(e2,x3)))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      udef_q(x9,_command_n_1(x9),free_relative_q(x3,pronoun_q(x14,pron(x14),[thing(x3), _do_v_1(e13,x9,x3,x14)]),ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      udef_q(x9,_command_n_1(x9),free_relative_q(x3,pronoun_q(x14,pron(x14),[thing(x3), _do_v_1(e13,x9,x3,x14)]),ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x14,pron(x14),free_relative_q(x3,udef_q(x9,_command_n_1(x9),[thing(x3), _do_v_1(e13,x9,x14,x3)]),ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x14,pron(x14),udef_q(x9,_command_n_1(x9),free_relative_q(x3,[thing(x3), _do_v_1(e13,x9,x14,x3)],ellipsis_ref(e2,x3)))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      free_relative_q(x3,pronoun_q(x14,pron(x14),udef_q(x9,_command_n_1(x9),[thing(x3), _do_v_1(e13,x9,x14,x3)])),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      free_relative_q(x3,udef_q(x9,_command_n_1(x9),pronoun_q(x14,pron(x14),[thing(x3), _do_v_1(e13,x9,x14,x3)])),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      udef_q(x9,_command_n_1(x9),pronoun_q(x14,pron(x14),free_relative_q(x3,[thing(x3), _do_v_1(e13,x9,x14,x3)],ellipsis_ref(e2,x3)))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      udef_q(x9,_command_n_1(x9),free_relative_q(x3,pronoun_q(x14,pron(x14),[thing(x3), _do_v_1(e13,x9,x14,x3)]),ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      udef_q(x9,_command_n_1(x9),free_relative_q(x3,pronoun_q(x14,pron(x14),[thing(x3), _do_v_1(e13,x9,x14,x3)]),ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x12,pron(x12),pronoun_q(x20,pron(x20),free_relative_q(x4,[thing(x4), _have_v_1(e24,x20,x4), _command_v_1(e9,x4,_do_v_1(e17,x12,i18))],unknown(e2,x4)))): {&#x27;SF&#x27;: &#x27;prop&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n      pronoun_q(x3,pron(x3),basic_free_relative_q(x5,[_command_n_1(x5), _do_v_1(e9,x5,i10)],ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      pronoun_q(x3,basic_free_relative_q(x5,[_command_n_1(x5), _do_v_1(e9,x5,i10)],pron(x3)),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      basic_free_relative_q(x5,[_command_n_1(x5), _do_v_1(e9,x5,i10)],pronoun_q(x3,pron(x3),ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      basic_free_relative_q(x5,[_command_n_1(x5), _do_v_1(e9,x5,i10)],pronoun_q(x3,pron(x3),ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n\nExamining the output, you can see that Perplexity first parsed the example phrase \"What commands do you have?\" and then said that None, which is the properties we said we supported, didn't match the properties on any MRS parses that ACE provided, and then proceeds to list them all:\n   parsing example: &#x27;What commands do you have?&#x27; ...\n      &#x27;None&#x27; did not match properties in any of the following parses:\n      _which_q(x5,_command_n_1(x5),pronoun_q(x3,pron(x3),_have_v_1(e2,x3,x5))): {&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n      pronoun_q(x9,pron(x9),basic_free_relative_q(x3,[_command_n_1(x3), _do_v_1(e8,x3,x9)],ellipsis_ref(e2,x3))): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n      basic_free_relative_q(x3,pronoun_q(x9,pron(x9),[_command_n_1(x3), _do_v_1(e8,x3,x9)]),ellipsis_ref(e2,x3)): Did not contain predicates listed for this function: [&#x27;_have_v_1&#x27;]\n\n   ...\n\nThis allows us to examine the parses to find which is the one we meant to support and just copy the properties it has. It will usually be near the top.  In this case, it is the first one:\n      _which_q(x5,_command_n_1(x5),pronoun_q(x3,pron(x3),_have_v_1(e2,x3,x5))): {&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n\nNow we can copy those properties directly into our function definition:\n@Predication(vocabulary,\n             names=[&quot;_have_v_1&quot;],\n             phrases={&quot;What commands do you have?&quot;: {&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n                     }\n             )\ndef _have_v_1_concept(context, state, e_introduced_binding, x_actor_binding, x_target_binding):\n    ...\n\nNow we get a different error when we run it:\nGenerating phrase properties for &lt;function _have_v_1_concept at 0x7fe317098790&gt;...\n   parsing example: &#x27;What commands do you have?&#x27; ...\nThe declared properties:\nNone\n\ndon&#x27;t match the properties declared by the phrases:\n{&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n\nNow it is telling us that it understands we want to support the specified phrase, with the specified properties, but that the properties argument didn't match (since it is missing).\nFilling those in:\n@Predication(vocabulary,\n             names=[&quot;_have_v_1&quot;],\n             phrases={&quot;What commands do you have?&quot;: {&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n                     },\n             properties={&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n             )\ndef _have_v_1_concept(context, state, e_introduced_binding, x_actor_binding, x_target_binding):\n    ...\n\nThis time it works! The real goal here is to get the properties argument populated.  The phrases section is a way to document why those properties were selected and help you build them.\nNote that multiple phrases can be supported. Let's say we also want to support \"You have commands.\" Going through the same process would lead to this:\n@Predication(vocabulary,\n             names=[&quot;_have_v_1&quot;],\n             phrases={&quot;What commands do you have?&quot;: {&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;},\n                      &quot;You have commands.&quot;: {&#x27;SF&#x27;: &#x27;prop&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n                      },\n             properties=[{&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;},\n                         {&#x27;SF&#x27;: &#x27;prop&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}]\n             )\n\nTo save space, you can compress the values permitted in the properties argument for SF since it is the only difference, using a list. Like this:\n@Predication(vocabulary,\n             names=[&quot;_have_v_1&quot;],\n             phrases={&quot;What commands do you have?&quot;: {&#x27;SF&#x27;: &#x27;ques&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;},\n                      &quot;You have commands.&quot;: {&#x27;SF&#x27;: &#x27;prop&#x27;, &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n                      },\n             properties={&#x27;SF&#x27;: [&#x27;ques&#x27;, &#x27;prop&#x27;], &#x27;TENSE&#x27;: &#x27;pres&#x27;, &#x27;MOOD&#x27;: &#x27;indicative&#x27;, &#x27;PROG&#x27;: &#x27;-&#x27;, &#x27;PERF&#x27;: &#x27;-&#x27;}\n             )\n\nComprehensive source for the completed tutorial is available here\n\n", "title":"Handling Tenses", "teaser":"Handling Tenses\nIn the previous section on Non-logical Meaning, we saw how, in implementing the predications to support \"Do you have commands?\" we acc ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo120ConceptsReferringExpressions", "excerpt":"Manipulating Conceptual References\nLet's now implement something that really has to deal with a concept as a thing: creating a file.\nLet's say we want to support phrases like:\ncreate a file\ncreate a text file\ncreate a test file containing &quot;Hello World&quot;\ncreate a test file containing &quot;Hello World&quot; with read-only permissions\netc.\n\nEverything to the right of \"create a\" is a referring expression, basically an arbitrarily complex noun phrase that describes or \"refers to\" something. When that \"something\" is actually in the world, the techniques we have gone through so far are sufficient to handle it. But in creating files, we are describing something that does not yet exist, so writing predications that find objects in the world and return them won't work. We need a different approach.\nThe Perplexity Concept object gives us a direction, but we'll need to enhance it. We will create a richer kind of Concept object that can hold a representation of these \"conceptual\" referring expressions and build predications that use them.\nCreating a File\nBelow is the built-in Concept object. Its default implementation just stores a single string from the constructor called sort_of which represents the sort of concept it is.  Period. It doesn't do anything with it. As far as Perplexity is concerned, the only part of it that gets used is the value_type property which returns VariableValueType.concept.  This tells Perplexity \"I am a concept, treat me as an opaque blob\".  The rest of the methods are there to support equality and membership in dictionaries and are used by things like the Python dict object:\nclass Concept(object):\n    def __init__(self, sort_of):\n        # This is a set so it is more easily comparable since order doesn&#x27;t matter\n        self._sort_of_criteria = set([sort_of]) if sort_of is not None else set()\n        self._hash = None\n\n    def __repr__(self):\n        return f&quot;Concept({&#x27;,&#x27;.join(self._sort_of_criteria)})&quot;\n\n    # The only required property is that objects which compare equal have the same hash value\n    # But: objects with the same hash aren&#x27;t required to be equal\n    # It must remain the same for the lifetime of the object\n    def __hash__(self):\n        if self._hash is None:\n            # TODO: Make this more efficient\n            self._hash = hash(tuple(self._sort_of_criteria))\n\n        return self._hash\n\n    def __eq__(self, other):\n        if isinstance(other, Concept) and self.__hash__() == other.__hash__():\n            return True\n\n    def value_type(self):\n        return VariableValueType.concept\n\nLet's start by implementing \"create a file\" using this class.  Looking at the MRS:\n? create a file\nI don&#x27;t know the words: create\n\n? /show\nUser Input: create a file\n4 Parses\n\n***** CHOSEN Parse #0:\nSentence Force: prop-or-ques\n[ &quot;create a file&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: prop-or-ques TENSE: tensed MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ _create_v_1&lt;0:6&gt; LBL: h1 ARG0: e2 ARG1: i3 ARG2: x4 [ x PERS: 3 NUM: sg IND: + ] ]\n          [ _a_q&lt;7:8&gt; LBL: h5 ARG0: x4 RSTR: h6 BODY: h7 ]\n          [ _file_n_of&lt;9:13&gt; LBL: h8 ARG0: x4 ARG1: i9 ] &gt;\n  HCONS: &lt; h0 qeq h1 h6 qeq h8 &gt; ]\n\n... we can see that we'll need to implement a new version of _file_n_of that creates a Concept instead of actual files as the current one does. The base Concept class is enough for this. Our implementation will be an exact copy of the _command_n_1 implementation we built in the Non-logical meaning section, just replacing the string \"command\" with \"file\":\n@Predication(vocabulary, names=[&quot;_file_n_of&quot;])\ndef file_n_of_concept(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if isinstance(value, Concept) and value == Concept(&quot;file&quot;):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield Concept(&quot;file&quot;)\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\nNext we'll implement _create_v_1 exactly like we implemented _delete_v_1 in the action verbs section. It will use a new operation (which we'll implement next) called CreateOperation to do the creating.  For now, we'll just hard code the name of the file to be \"newfile\":\n@Predication(vocabulary, names=[&quot;_create_v_1&quot;])\ndef create_v_1_comm(context, state, e_introduced_binding, x_actor_binding, x_what_binding):\n    def criteria(value):\n        # Only allow creating conceptual files\n        if isinstance(value, Concept) and value == Concept(&quot;file&quot;):\n            return True\n\n        else:\n            context.report_error([&quot;cantDo&quot;, &quot;create&quot;, x_what_binding.variable.name])\n\n    def unbound_what():\n        context.report_error([&quot;cantDo&quot;, &quot;create&quot;, x_what_binding.variable.name])\n\n    for success_state in individual_style_predication_1(context,\n                                                        state,\n                                                        x_what_binding,\n                                                        criteria,\n                                                        unbound_what,\n                                                        [&quot;cantXYTogether&quot;, &quot;create&quot;, x_what_binding.variable.name]):\n        object_to_create_binding = success_state.get_binding(x_what_binding.variable.name)\n        operation = CreateOperation(object_to_create_binding, &quot;newfile&quot;)\n        yield success_state.apply_operations([operation])\n\nAnd finish by implementing CreateOperation. It does the actual creating by calling our file system object (the code for that is not shown):\nclass CreateOperation(object):\n    def __init__(self, binding_to_create, file_name):\n        self.binding_to_create = binding_to_create\n        self.file_name = file_name\n\n    def apply_to(self, state):\n        state.file_system.create_item(self.binding_to_create, self.file_name)\n\nNow we can run it:\n? create a file\nDone!\n\nNot very exciting and since we don't have a way to list files, we'll have to trust that it works or examine in the debugger.\nTo get this far, we've used concepts we've already explained in previous sections that should be relatively familiar. Next, we'll cover some new ground.\nA Richer Concept\nLet's now tackle the next phrase from our list at the beginning of this section: \"create a text file\". As always, we'll start by examining the MRS to see what predications we need to implement:\n? create a text file\nI don&#x27;t know the words: text, text file\n\n? /show\nUser Input: create a text file\n4 Parses\n\n***** CHOSEN Parse #1:\nSentence Force: comm\n[ &quot;create a text file&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ pronoun_q&lt;0:18&gt; LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n          [ pron&lt;0:18&gt; LBL: h7 ARG0: x3 ]\n          [ _create_v_1&lt;0:6&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x8 [ x PERS: 3 NUM: sg IND: + ] ]\n          [ _a_q&lt;7:8&gt; LBL: h9 ARG0: x8 RSTR: h10 BODY: h11 ]\n          [ compound&lt;9:18&gt; LBL: h12 ARG0: e13 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: x8 ARG2: x14 ]\n          [ udef_q&lt;9:13&gt; LBL: h15 ARG0: x14 RSTR: h16 BODY: h17 ]\n          [ _text_n_of&lt;9:13&gt; LBL: h18 ARG0: x14 ARG1: i19 ]\n          [ _file_n_of&lt;14:18&gt; LBL: h12 ARG0: x8 ARG1: i20 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 h10 qeq h12 h16 qeq h18 &gt; ]\n\n-- CHOSEN Parse #1, CHOSEN Tree #0: \n\n                                                                  \u250c\u2500\u2500 _file_n_of(x8,i20)\n             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _text_n_of(x14,i19)                          \u2502\n             \u2502                                        \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\nudef_q(x14,RSTR,BODY)               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)  \u2502             \u2502\n                  \u2502                 \u2502                 \u2502             \u2514 compound(e13,x8,x14)\n                  \u2514\u2500 pronoun_q(x3,RSTR,BODY)          \u2502\n                                         \u2514\u2500 _a_q(x8,RSTR,BODY)\n                                                           \u2514\u2500 _create_v_1(e2,x3,x8)\n\nThere are 2 new predications to implement: _text_n_of and compound.  Basically, the ERG is creating the concept of \"text\" and the concept of \"file\" and combining them together with the compound predication. _text_n_of will end up looking just like _file_n_of above:\n@Predication(vocabulary, names=[&quot;_text_n_of&quot;])\ndef text_n_of_concept(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if isinstance(value, Concept) and value == Concept(&quot;text&quot;):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield Concept(&quot;text&quot;)\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\nNext up is compound(e13,x8,x14). \nThe x8 in compound is always the \"base object\", i.e. \"seat\" in \"bicycle seat\", \"food\" in \"baby food\", etc. \nx14 is the modifier which filters down what kind of base object we are discussing. \nIf we were working with object instances (and not concepts) we would simply do a check to see if x8 is an \"x14 kind of object\" and succeed or not. But, because we are building up a concept, we actually need to modify the value in x8 to include that additional description so that downstream predications see a concept that is a \"text\" kind of \"file\". We need to enhance the \"Concept\" object to support this. Since Perplexity doesn't care about the Concept object, per se, and only cares that the object has the value_type method on it, we can just create our own RichConcept object and use that.\nTo do this, we need start building up a simple way of describing things. We'll describe a referred-to-thing with a list of \"criteria\", which are simply \"relationships\" and \"values\".  For example:\nDescription of &quot;text file&quot;:\n    object &quot;is_a&quot; &quot;file&quot;\n    object &quot;has_adjective&quot; &quot;text&quot;\n\nHere is the implementation of that:\nclass RichConcept:\n    def __init__(self, is_a=None):\n        self.criteria = [] if sort_of is None else [(&quot;is_a&quot;, sort_of)]\n        self._hash = None\n\n    def __repr__(self):\n        return f&quot;RichConcept({[x for x in self.criteria]})&quot;\n\n    # The only required property is that objects which compare equal have the same hash value\n    # But: objects with the same hash aren&#x27;t required to be equal\n    # It must remain the same for the lifetime of the object\n    def __hash__(self):\n        if self._hash is None:\n            self._hash = hash(tuple(self.criteria))\n\n        return self._hash\n\n    def __eq__(self, other):\n        if isinstance(other, RichConcept) and self.__hash__() == other.__hash__():\n            return True\n\n    def value_type(self):\n        return VariableValueType.concept\n\n    def add_criteria(self, relationship, value):\n        self_copy = copy.deepcopy(self)\n        self_copy.criteria.append((relationship, tuple))\n        self_copy._hash = None\n        return self_copy\n\nAnd with that in place we can tackle compound.  The way things are currently implemented, for the phrase \"create a text file\", compound will get called with its arguments set to:\ncompound(e13,x8,x14)\nx8 = RichObject(&quot;file&quot;)   # object &quot;is_a&quot; &quot;file&quot;\nx14 = RichObject(&quot;text&quot;)  # object &quot;is_a&quot; &quot;text&quot;\n\nThis isn't quite right. A text file \"is_a\" file, but it \"has\" text, it is not \"text\". \nThe problem is in how we've interpreted the predications _text_n_of and _file_n_of.  Normally, these predications should be true for objects that \"are\" (i.e. \"is_a\") that kind of thing. That is how they are implemented and that is the kind of Concept being returned by them at the moment. But when used with compound, the 2nd argument is used more like an adjective than a noun.  Consider \"baby food\". A jar of baby food is not a baby. \"Baby\" is being used as an adjective.  \nThe problem is that text_n_of (or \"baby\") get called without knowing this is how they'll be used. So, we can either write two different interpretations for all noun predications: one interpreting as \"is_a\" and one interpreting as \"has_adjective\" and then compound will always only be true for the second.  Or: we can have the compound predication do some special magic to interpret nouns as adjectives.\nSince we don't have other predications that need to treat nouns as adjectives, for now we'll centralize the code in compound to save work. We will add a method to our RichConcept class called add_adjective_concept. This method will simply convert \"is_a\" relationships to \"has_adjective\" relationships and then add to the base object:\nclass RichConcept:\n    \n    ...\n    \n    def add_criteria(self, relationship, value):\n        self_copy = copy.deepcopy(self)\n        self_copy.criteria.append((relationship, tuple))\n        self_copy._hash = None\n        return self_copy\n\n    def add_adjective_concept(self, other_concept):\n        self_copy = copy.deepcopy(self)\n        for criteria in other_concept.criteria:\n            if criteria[0] == &quot;is_a&quot;:\n                self_copy.criteria.append((&quot;has_adjective&quot;, criteria[1]))\n            else:\n                self_copy.criteria.append(criteria)\n        self_copy._hash = None\n        return self_copy\n\nThis makes compound easy to write. Due to the way it is used in English, it will always have both arguments bound: there isn't a way to make a compound word where you are asking what the first part is that will generate this predication. So, all we need to do is use our new method to combine the second argument into the first and yield that as the new first argument:\n@Predication(vocabulary,\n             names=[&quot;compound&quot;])\ndef compound_concept(context, state, e_introduced_binding, x_base_binding, x_modifier_binding):\n    # Only support concepts\n    # Both arguments will always be bound for compound \n    # so we don&#x27;t need to check unbound cases. Furthermore, the value will always be\n    # a single value due to the way it is parsed, so we only need to check the first value\n    if not isinstance(x_base_binding.value[0], RichConcept) or not isinstance(x_modifier_binding.value[0], RichConcept):\n        context.report_error([&quot;formNotUnderstood&quot;])\n        return\n    \n    compound_value = x_base_binding.value[0].add_adjective_concept(x_modifier_binding.value[0])\n    yield state.set_x(x_base_binding.variable.name, (compound_value, ))   \n\nNote the use of the special error \"formNotUnderstood\" if the predication is called with a value that is not a RichConcept. This tells the system, \"this predication is not appropriate for these values\". It is neither true nor false. It allows the system to give better errors.\nThe final code we need to write is in the CreateOperation and underlying filesystem objects that actually do the work.\nCreateOperation doesn't need to change since it just passes along the values:\nclass CreateOperation(object):\n    def __init__(self, binding_to_create, file_name):\n        self.binding_to_create = binding_to_create\n        self.file_name = file_name\n\n    def apply_to(self, state):\n        state.file_system.create_item(self.binding_to_create, self.file_name)\n\nThe real work happens in the FileSystem object that haven't really gone through.  The pertinent code is below.  It does the work of finding the one adjective that describes the type of file to creating and failing if there is none or more than one.  Obviously this code could be made more robust, but that isn't what we're focused on here. This is just a simple implementation:\nclass FileSystem:\n    ...\n    \n    def get_file_type(self, concept):\n        file_type = None\n        for criteria in concept.criteria:\n            if criteria[0] == &quot;has_adjective&quot;:\n                if file_type is None:\n                    file_type = criteria[1]\n                else:\n                    # More than one type described, fail\n                    return None\n        \n        return file_type\n\nIf we now run a test, we get this:\n? create a text file\n[7, [&#x27;cantDo&#x27;, &#x27;create&#x27;, &#x27;x8&#x27;], 0]\n\n(We haven't added to code to make a nice error yet ...)\nHmmm. What happened here? Let's dig in.\nLogical Entailment\nThe problem is in the implementation of _create_v_1.  It checks to see if its argument == RichConcept(\"file\"), but the Concept is no longer simply a file, it is a RichConcept([('is_a', 'file'), ('has_adjective', 'text')]), so it fails:\n@Predication(vocabulary, names=[&quot;_create_v_1&quot;])\ndef create_v_1_comm(context, state, e_introduced_binding, x_actor_binding, x_what_binding):\n    def criteria(value):\n        # Only allow creating conceptual files\n        if isinstance(value, RichConcept) and value == RichConcept(&quot;file&quot;):\n            return True\n\n        else:\n            context.report_error([&quot;cantDo&quot;, &quot;create&quot;, x_what_binding.variable.name])\n    \n    ...\n\nAs far as this predication is concerned, we don't care what type of file the user asked to create, that will be dealt with elsewhere.  We just care that it is, at its core, a file.  Here, we can appeal to a concept from logic called \"logical consequence\" or \"logical entailment\".  Really, you can think of it as \"implies\".  Being a \"text file\" will always mean it is also a \"file\". So, \"text file\" entails \"file\" or \"text file\" implies \"file\". In this function we want to check for entailment of \"file\", not equality.\nNow, proving entailment is an active area of research. It is a hard problem in the general case. But we don't have the general case here, we have a very limited vocabulary and set of scenarios.  We can therefore just say that something entails something else as long as they both \"is_a\" the same thing:\nLet's add a method to our Concept object to do that (the last method below):\nclass RichConcept:\n    def __init__(self, is_a=None):\n        self.criteria = [] if is_a is None else [(&quot;is_a&quot;, is_a)]\n        self._hash = None\n\n    def __repr__(self):\n        return f&quot;RichConcept({[x for x in self.criteria]})&quot;\n\n    # The only required property is that objects which compare equal have the same hash value\n    # But: objects with the same hash aren&#x27;t required to be equal\n    # It must remain the same for the lifetime of the object\n    def __hash__(self):\n        if self._hash is None:\n            self._hash = hash(tuple(self.criteria))\n\n        return self._hash\n\n    def __eq__(self, other):\n        if isinstance(other, RichConcept) and self.__hash__() == other.__hash__():\n            return True\n\n    def value_type(self):\n        return VariableValueType.concept\n\n    def add_criteria(self, relationship, value):\n        self_copy = copy.deepcopy(self)\n        self_copy.criteria.append((relationship, tuple))\n        self_copy._hash = None\n        return self_copy\n\n    def add_adjective_concept(self, other_concept):\n        self_copy = copy.deepcopy(self)\n        for criteria in other_concept.criteria:\n            if criteria[0] == &quot;is_a&quot;:\n                self_copy.criteria.append((&quot;has_adjective&quot;, criteria[1]))\n            else:\n                self_copy.criteria.append(criteria)\n        self_copy._hash = None\n        return self_copy\n\n    def entails(self, other_concept):\n        for criteria in self.criteria:\n            if criteria[0] == &quot;is_a&quot;:\n                for other_criteria in other_concept.criteria:\n                    if other_criteria[0] == &quot;is_a&quot; and other_criteria[1] == criteria[1]:\n                        return True\n\n        return False\n\nThen, fix up our _create_v_1 predication to use entails instead of ==:\n@Predication(vocabulary, names=[&quot;_create_v_1&quot;])\ndef create_v_1_comm(context, state, e_introduced_binding, x_actor_binding, x_what_binding):\n    def criteria(value):\n        # Only allow creating conceptual files\n        if isinstance(value, RichConcept) and value.entails(RichConcept(&quot;file&quot;)):\n            return True\n\n        else:\n            context.report_error([&quot;cantDo&quot;, &quot;create&quot;, x_what_binding.variable.name])\n\n    def unbound_what():\n        context.report_error([&quot;cantDo&quot;, &quot;create&quot;, x_what_binding.variable.name])\n\n    for success_state in individual_style_predication_1(context,\n                                                        state,\n                                                        x_what_binding,\n                                                        criteria,\n                                                        unbound_what,\n                                                        [&quot;cantXYTogether&quot;, &quot;create&quot;, x_what_binding.variable.name]):\n        object_to_create_binding = success_state.get_binding(x_what_binding.variable.name)\n        operation = CreateOperation(object_to_create_binding, &quot;newfile&quot;)\n        yield success_state.apply_operations([operation])\n\nNow if we run our test:\n? create a text file\nDone!\n\nOther Referring Expressions\nLet's go back to our example phrases from the beginning:\ncreate a file\ncreate a text file\ncreate a test file containing &quot;Hello World&quot;\ncreate a test file containing &quot;Hello World&quot; with read-only permissions\netc.\n\nWe got through the first 2. Hopefully, now you can see how the others are simply adding more and more criteria onto the Conceptobject and then implementing them when it is time to do the file creation.\nBecause we've done a lot in this section, here is all the new code we had to write:\n@Predication(vocabulary, names=[&quot;_file_n_of&quot;])\ndef file_n_of_concept(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if isinstance(value, RichConcept) and value == RichConcept(&quot;file&quot;):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield RichConcept(&quot;file&quot;)\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n                                           \n                                           \n@Predication(vocabulary, names=[&quot;_text_n_of&quot;])\ndef text_n_of_concept(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if isinstance(value, RichConcept) and value == RichConcept(&quot;text&quot;):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield RichConcept(&quot;text&quot;)\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\n\n@Predication(vocabulary,\n             names=[&quot;compound&quot;])\ndef compound_concept(context, state, e_introduced_binding, x_base_binding, x_modifier_binding):\n    # Only support concepts\n    # Both arguments will always be bound for compound\n    # so we don&#x27;t need to check unbound cases. Furthermore, the value will always be\n    # a single value due to the way it is parsed, so we only need to check the first value\n    if not isinstance(x_base_binding.value[0], RichConcept) or not isinstance(x_modifier_binding.value[0], RichConcept):\n        context.report_error([&quot;formNotUnderstood&quot;])\n        return\n\n    compound_value = x_base_binding.value[0].add_adjective_concept(x_modifier_binding.value[0])\n    yield state.set_x(x_base_binding.variable.name, (compound_value, ))\n    \n\n@Predication(vocabulary, names=[&quot;_create_v_1&quot;])\ndef create_v_1_comm(context, state, e_introduced_binding, x_actor_binding, x_what_binding):\n    def criteria(value):\n        # Only allow creating conceptual files\n        if isinstance(value, RichConcept) and value.entails(RichConcept(&quot;file&quot;)):\n            return True\n\n        else:\n            context.report_error([&quot;cantDo&quot;, &quot;create&quot;, x_what_binding.variable.name])\n\n    def unbound_what():\n        context.report_error([&quot;cantDo&quot;, &quot;create&quot;, x_what_binding.variable.name])\n\n    for success_state in individual_style_predication_1(context,\n                                                        state,\n                                                        x_what_binding,\n                                                        criteria,\n                                                        unbound_what,\n                                                        [&quot;cantXYTogether&quot;, &quot;create&quot;, x_what_binding.variable.name]):\n        object_to_create_binding = success_state.get_binding(x_what_binding.variable.name)\n        operation = CreateOperation(object_to_create_binding, &quot;newfile&quot;)\n        yield success_state.apply_operations([operation])\n        \n        \nclass CreateOperation(object):\n    def __init__(self, binding_to_create, file_name):\n        self.binding_to_create = binding_to_create\n        self.file_name = file_name\n\n    def apply_to(self, state):\n        state.file_system.create_item(self.binding_to_create, self.file_name)\n        \n        \nclass RichConcept:\n    def __init__(self, is_a=None):\n        self.criteria = [] if is_a is None else [(&quot;is_a&quot;, is_a)]\n        self._hash = None\n\n    def __repr__(self):\n        return f&quot;RichConcept({[x for x in self.criteria]})&quot;\n\n    # The only required property is that objects which compare equal have the same hash value\n    # But: objects with the same hash aren&#x27;t required to be equal\n    # It must remain the same for the lifetime of the object\n    def __hash__(self):\n        if self._hash is None:\n            self._hash = hash(tuple(self.criteria))\n\n        return self._hash\n\n    def __eq__(self, other):\n        if isinstance(other, RichConcept) and self.__hash__() == other.__hash__():\n            return True\n\n    def value_type(self):\n        return VariableValueType.concept\n\n    def add_criteria(self, relationship, value):\n        self_copy = copy.deepcopy(self)\n        self_copy.criteria.append((relationship, tuple))\n        self_copy._hash = None\n        return self_copy\n\n    def add_adjective_concept(self, other_concept):\n        self_copy = copy.deepcopy(self)\n        for criteria in other_concept.criteria:\n            if criteria[0] == &quot;is_a&quot;:\n                self_copy.criteria.append((&quot;has_adjective&quot;, criteria[1]))\n            else:\n                self_copy.criteria.append(criteria)\n        self_copy._hash = None\n        return self_copy\n\n    def entails(self, other_concept):\n        for criteria in self.criteria:\n            if criteria[0] == &quot;is_a&quot;:\n                for other_criteria in other_concept.criteria:\n                    if other_criteria[0] == &quot;is_a&quot; and other_criteria[1] == criteria[1]:\n                        return True\n\n        return False\n        \nclass FileSysem:\n    ...\n    \n    def get_file_type(self, concept):\n        file_type = None\n        for criteria in concept.criteria:\n            if criteria[0] == &quot;has_adjective&quot;:\n                if file_type is None:\n                    file_type = criteria[1]\n                else:\n                    # More than one type described, fail\n                    return None\n\n        return file_type\n\nComprehensive source for the completed tutorial is available here\n\n", "title":"Conceptual References", "teaser":"Manipulating Conceptual References\nLet's now implement something that really has to deal with a concept as a thing: creating a file.\nLet's say we want ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo080QuantifiersAndDeterminers", "excerpt":"Quantifiers and Determiners\nAll of the examples we've used so far have produced quantifiers in their MRS, and all have been implemented automatically by the system:\n\"A file is large\": a_q\n\n\"Which files are large?\": which_q\n\n\"Delete a file\": pronoun_q\n\netc.\nThis will almost always be the case because quantifiers are not usually application specific. As described in the Solution Group Algorithm topic, quantifers do two things, neither of which is usually application specific:\nscope variables\n\nconstrain their variables to be a certain count\n\nSo, the system can manage them automatically across applications.\nThe same is true for determiners that count like \"a few\", \"less than 3\", \"both\", etc.\nTODO: describe how to build one that isn't in the system like \"this\"\nComprehensive source for the completed tutorial is available here\n\n", "title":"Quantifiers and Determiners", "teaser":"Quantifiers and Determiners\nAll of the examples we've used so far have produced quantifiers in their MRS, and all have been implemented automatically  ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo130OpenClassWords", "excerpt":"Centralizing Nouns and Adjectives\nAs we've built our vocabulary, there are certain types of words that are basically the same function with small differences.  Look at the code for _file_n_of and _folder_n_of (both nouns):\n\n@Predication(vocabulary, names=[&quot;_file_n_of&quot;])\ndef file_n_of(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if isinstance(value, File):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        for item in state.all_individuals():\n            if bound_variable(item):\n                yield item\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\n\n# true for both sets and individuals as long as everything\n# in the set is a file\n@Predication(vocabulary, names=[&quot;_folder_n_of&quot;])\ndef folder_n_of(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if isinstance(value, Folder):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        for item in state.all_individuals():\n            if bound_variable(item):\n                yield item\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\nThey are identical except for the name of the predication (_file_n_of vs. _folder_n_of) and one line of code:\n        if isinstance(value, File):\nor\n        if isinstance(value, Folder):\n\nIn many applications, whether an object is a noun of a particular type is a very simple check and repeating the code over and over would be a lot of wasted work. Of course, you could create a helper function and only have to write the function headers, like this:\n@Predication(vocabulary, names=[&quot;_folder_n_of&quot;])\ndef folder_n_of(context, state, x_binding, i_binding):\n    yield from noun_helper(noun=&quot;folder&quot;, object_type=folder)\n    \n@Predication(vocabulary, names=[&quot;_file_n_of&quot;])\ndef file_n_of(context, state, x_binding, i_binding):\n    yield from noun_helper(noun=&quot;folder&quot;, object_type=folder)\n\nBut that is still a lot of typing and what if all of your nouns are just listed in a data file? Or if you want to return special errors for words you don't know? This alternative also doesn't allow for a data driven approach.\nmatch_all predications\nA more general approach is to implement a single function that matches all predications of a certain part-of-speech. Perplexity supports this by allowing you to specify a special predicate called match_all_n. It will be called for any noun predication that matches its arguments.  The \"lemma\" for the predicate will be passed in as an additional first argument (\"file\" is the lemma for _file_n_of).  Then, your code can dynamically determine if the binding is of that type.\nFor the code below, there are two functions helperr functions shown:\nimplemented_nouns() just returns a list of all nouns the application supports\n\nsort_of(state, value, noun_type) returns true if value is something of type noun_type (which would be a lemma like \"file\")\n\nHow these work is very application specific and we've implemented the in a very simplistic way below.  Here's the code:\ndef implemented_nouns():\n    yield &quot;file&quot;\n    yield &quot;folder&quot;\n\n\ndef sort_of(state, value, noun_type):\n    if noun_type == &quot;file&quot; and isinstance(value, File):\n        return True\n    elif noun_type == &quot;folder&quot; and isinstance(value, Folder):\n        return True\n    else:\n        return False\n        \n\n# Returns True if it is a lemma we have modelled in the system\ndef understood_noun(state, noun_lemma):\n    return noun_lemma in implemented_nouns()\n\n\n@Predication(vocabulary, names=[&quot;match_all_n&quot;], matches_lemma_function=understood_noun)\ndef match_all_n_instances(noun_type, context, state, x_binding):\n    def bound_variable(value):\n        if sort_of(state, value, noun_type):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        for item in state.all_individuals():\n            if bound_variable(item):\n                yield item\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)                                        \n\nAll the code above replaces the original code for _file_n_of and _folder_n_of. It then requires updating those helper functions as new words are added.  In a system that models objects in some kind of logical ontology, this could be a simple database lookup.\nSince the signatures of \"file\" and \"folder\" are actually _file_n_of(x, i) and _folder_n_of(x, i), and thus have an extra i argument compared to what is implemented above, this new function won't actually be called for them.  Instead, we need to build a wrapper that has, but ignores, this i argument since it is acting as unused for these predicates:\n@Predication(vocabulary, names=[&quot;match_all_n&quot;], matches_lemma_function=understood_noun)\ndef match_all_n_i_instances(noun_type, context, state, x_binding, i_binding):\n    yield from match_all_n_instances(noun_type, context, state, x_binding):\n\nmatch_all conceptual predications\nIf you go this route, you'll also probably want to implement the conceptual versions of the nouns, as discussed in the section on Conceptual Expressions.  Currently, the conceptual implementation of _file_n_of looks like this:\n@Predication(vocabulary, names=[&quot;_file_n_of&quot;])\ndef file_n_of_concept(context, state, x_binding, i_binding):\n    def bound_variable(value):\n        if isinstance(value, RichConcept) and value == RichConcept(&quot;file&quot;):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield RichConcept(&quot;file&quot;)\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\nTurning this into the template for any type of conceptual object (and using the RichConcept object we implemented in Conceptual Expressions) would look like this:\n@Predication(vocabulary, names=[&quot;match_all_n&quot;], matches_lemma_function=understood_noun)\ndef match_all_n_concepts(noun_type, context, state, x_binding):\n    def bound_variable(value):\n        if isinstance(value, RichConcept) and value.entails(RichConcept(noun_type)):\n            return True\n        else:\n            context.report_error([&quot;valueIsNotX&quot;, value, x_binding.variable.name])\n            return False\n\n    def unbound_variable():\n        yield RichConcept(noun_type)\n\n    yield from combinatorial_predication_1(context,\n                                           state,\n                                           x_binding,\n                                           bound_variable,\n                                           unbound_variable)\n\n\n@Predication(vocabulary, names=[&quot;match_all_n&quot;], matches_lemma_function=understood_noun)\ndef match_all_n_i_concepts(noun_type, context, state, x_binding, i_binding):\n    yield from match_all_n_concepts(noun_type, context, state, x_binding)\n\nNote that we are using the entails function, not testing equality. As described in  Conceptual Expressions, entailment means \"implies\" and MRS predications really test for entailment. Thus, anything that entails file should be true: \"large file\", \"empty file\", \"slimy pink file\", \"file I saw yesterday\", etc. As long as it is, at its root, a \"file\", this should be true.\nMatching Other Parts of Speech\nmatch_all predications can be used for any part of speech that the grammar supports.  Adjectives can also be very repetitive since they might just check for a particular property on an object. A match_all_a predication could be built like this:\ndef handles_adjective(state, adjective_lemma):\n    return True\n    \n@Predication(vocabulary, names=[&quot;match_all_a&quot;], matches_lemma_function=handles_adjective)\ndef match_all_a_concepts(adjective_type, context, state, e_introduced, x_binding):\n    ...\n\nAny part of speech can be tacked on to the base match_all_ to create a predication that will match all predicates of that part-of-speech.  Just remember that the arguments need to match too. Normally, though, nouns and adjectives are the only parts of speech that end up templatized like this.\nInterpretations and match_all\nOften you will have some words that need a special implementation, your match_all function won't work. Just like any normal predication, you can create other interpretations (alternatives) by just creating more functions. They get run in the order they are in the file.  So, if we wanted the \"command\" word to have another way it might get interpreted, we'd add this to the file that contains the other match_all functions:\n@Predication(vocabulary, names=[&quot;_command_n_1&quot;])\ndef _command_n_1(context, state, x_binding):\n    ...\n\nIf you only want this new predication to run, then you'd also return False from the understood_noun function written above that tells the system when to call match_all_n.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Centralizing Nouns/Adjectives", "teaser":"Centralizing Nouns and Adjectives\nAs we've built our vocabulary, there are certain types of words that are basically the same function with small diff ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxhowto/pxHowTo025SStrings", "excerpt":"S-String Overview\nAs described in the Words in Failures topic, errors or messages to the user often need to include a representation of some noun that the user said. For example, a user might say, \"give me a long brown towel\".  Here's one tree for that phrase:\n                                             \u250c\u2500\u2500\u2500\u2500 _towel_n_1(x8)\n                                             \u2502 \u250c\u2500\u2500 _brown_a_1(e19,x8)\n                                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1,2)\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x9)  \u2502               \u2514 _long_a_2(e18,x8)\npronoun_q(x9,RSTR,BODY)          \u2502\n                    \u2514\u2500 _a_q(x8,RSTR,BODY)\n                                      \u2502                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\n                                      \u2514\u2500 pronoun_q(x3,RSTR,BODY)\n                                                             \u2514\u2500 _give_v_1(e2,x3,x8,x9)\n\nWe'd like to have the code for _give_v_1 be able to say \"There isn't {whatever x8 is} in the system\" without having to write a bunch of non-trivial code to decode the tree and turn it into English. To help, Perplexity has a built-in way to do this. In fact, it provides a very general way to build responses by providing a template. It is called an \"s-string\" and works analogously to f-strings in Python.\nAt its most basic level, s-strings can be used like an f-strings to do replacement of variables in a string like this:\n&gt;&gt;&gt; value1 = &quot;hello&quot;\n&gt;&gt;&gt; print(\n          s(&quot;The value is {*value1}&quot;)\n          )\n\nThe value is hello\n\ns() is the s-string function and it takes a string that will be processed. Anything enclosed in {} in the string will be converted to text by the system. Above we've used *value1 as the value to be replaced.  The * means \"put whatever is in value1 in the string as-is\".\nS-strings also understand how MRS trees work and can convert a DELPH-IN variable like x8 in the above example into the English that represents it. To do this it also requires passing the MRS tree that should be decoded. This is always available in a special 'tree' variable in the state argument of a predication. It can be accessed by calling state.get_binding('tree').value[0]. \nSo, we could print a message from the _give_v_1 predication above like this:\n@Predication(vocabulary, names=[&quot;_give_v_1&quot;])\ndef give_v_1(state, e_introduced, x_giver_binding, x_what_binding, x_receiver_binding):\n   print(\n        s(&quot;There isn&#x27;t {x_what_binding.variable.name} in the system&quot;, state.get_binding(&#x27;tree&#x27;).value[0])\n    )\n\nA term in {} without a * in front like: {x_variable_binding.variable.name} tells the system to interpret the expression as containing a DELPH-IN variable name. The system will convert the DELPH-IN variable to English by decoding the tree passed to s(), and looking for all the terms that modify the variable. Then it will put that English representation in the string.\nUsing our example of \"Give me a long brown towel\" with the code for give_v_1() above, the system will print out:\nThere isn&#x27;t a long brown towel in the system\n\nNote that the system includes the quantifier the user used for x8, which is \"a\" in this case, because we didn't specify one inside the {}.  That means if the user said \"give me the beautiful towels\", we'd get this printed out:\nThere isn&#x27;t the beautiful towels in the system\n\nWhich isn't quite right. We really want something like \"There aren't any beautiful towels\", which we can generate like this:\n@Predication(vocabulary, names=[&quot;_give_v_1&quot;])\ndef give_v_1(state, e_introduced, x_giver_binding, x_what_binding, x_receiver_binding):\n   print(\n        s(&quot;There aren&#x27;t any {bare x_what_binding.variable.name:pl}&quot;, state.get_binding(&#x27;tree&#x27;).value[0])\n    )\n\nBy using {bare x_what_binding.variable.name:pl}, we've told the system to get rid of the quantifier (by using bare) and to put it into plural form (by using :pl).  Now, we get a better result:\n&quot;give me the beautiful towels&quot; -&gt; There aren&#x27;t any beautiful towels\n&quot;give me a towel on the chair&quot; -&gt; There aren&#x27;t any towels on the chair\n\nSometimes you need a word in the phrase to match the plurality of a word in the MRS. Let's say we want to print the message, \"[what the user said] is in the cupboard\". We could do that by writing this code:\n@Predication(vocabulary, names=[&quot;_give_v_1&quot;])\ndef give_v_1(state, e_introduced, x_giver_binding, x_what_binding, x_receiver_binding):\n   print(\n        s(&quot;{x_what_binding.variable.name} {&#x27;is&#x27;:&lt;x_what_binding.variable.name} in the cupboard&quot;, state.get_binding(&#x27;tree&#x27;).value[0])\n    )\n\nFor this version:\n{x_what_binding.variable.name} says \"use the existing quantifier and plurality as the user said it\" like our first example.\n\n{'is':<x_what_binding.variable.name} says \"make the word 'is' match the English represented by the DELPH-IN variable in x_what_binding.variable.name\"\n\nHere are some examples of it in use:\ngive me the towels        -&gt; the towels are in the cupboard\ngive me a towel           -&gt; a towel is in the cupboard\ngive me some clean towels -&gt; some clean towels are in the cupboard\n\nS-String Reference\nElements in an s-string have the format {determiner value:pluralization@meaning_at_index}. The below sections go through each section of the format and describe all of the valid values.\nValue\ns-string format: {determiner value:pluralization@meaning_at_index}\n\nThe only required part of an s-string is: value:\nvalue is interpreted as a Python variable that contains a string representing a DELPH-IN variable such as \"x8\"\n\n*value is interpreted as a Python variable that can contain any text such as \"dog\", \"is\" or \"the frying pan from my room\"\n\n\"value\" or 'value' is interpreted as a raw string\n\nNote: When using the *value or \"value\" forms, any text can be used and will be inserted into the string. However, if pluralization is also being used (see below) to get the word transformed into a specific plural form, the text must be a singular noun form.\nDeterminer\ns-string format: {determiner value:pluralization@meaning_at_index}\n\nPut one of the following as determiner to force that type of article to be used instead of what the user said:\na or an to include an indefinite article. Either works and will be changed to match the text when the string is evaluated.\n\nthe to include a definite article\n\nbare to remove all articles\n\nProviding no determiner uses the determiner (if any) that was in the user's phrase.\nExamples:\nUser says &#x27;the lively party&#x27;:\n\n{value}      -&gt; &quot;the lively party&quot;\n{an value}   -&gt; &quot;a lively party&quot;\n{bare value} -&gt; &quot;lively party\n\nCapitalization\ns-string format: {determiner value:pluralization@meaning_at_index}\n\nTo capitalize the generated text, capitalize determiner, like {The value} or {Bare value}\nUser says &#x27;the lively party&#x27;:\n\n{An value} -&gt; &quot;A lively party&quot;\n{Bare value} -&gt; &quot;Lively party&quot;\n\nPluralization\ns-string format: {determiner value:pluralization@meaning_at_index}\n\npluralization specifies how to shape the plural of the item represented by value. To force the item into plural or singular form, use : followed by:\nsg : singular\n\npl : plural\n\n(no text) : leave as-is\n\n<delphin_variable: match the singular or plural of whatever the DELPH-IN variable in delphin_variable represents\n\n<*noun_variable: match the singular or plural of whatever noun is contained directly in noun_variable\n\n<\"noun value\": match the singular or plural of a noun string literal\n\nNote that for pluralization to work when value is not a DELPH-IN variable:\n*value must be a singular form word such as \"dog\" or \"is\"\n\n\"value\" or 'value' must be a raw string that is similarly in singular form\n\nMeaning at Index\ns-string format: {determiner value:pluralization@meaning_at_index}\n\nThe meaning of a DELPH-IN variable in an MRS tree depends on where in the tree it gets evaluated.  @meaning_at_index tells the system to convert a DELPH-IN variable to what its meaning would be after evaluating all the predications up to, but not including, the predication at that index. The index represents the depth-first evaluation order the system uses, starting at zero.\nmeaning_after_index can be a numeric literal like 5, or it can be a local variable like x.\nFor example, the tree below for, \"The dirty car is yellow\" has the predication indexes represented before each predication:\n                         \u250c\u2500\u2500 1:_car_n_1(x3)\n             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n             \u2502             \u2514 2:_dirty_a_1(e8,x3)\n0:_the_q(x3,RSTR,BODY)\n                  \u2514\u2500 3:_yellow_a_1(e2,x3)\n\nAssuming a variable x3_variable = 'x3' then we can generate the value of x3 at each point in the tree like this:\n0. {x3_variable:@0} means before the tree starts: \"thing\"\n{x3_variable:@1} means after _the_q: \"the thing\"\n\n{x3_variable:@2} means after _car_n_1 is: \"the car\"\n\n{x3_variable:@3} means after __dirty_a_1 is: \"the dirty car\"\n\n{x3_variable:@4} means after the tree is finished: \"the dirty yellow car\"\n\nIf no @meaning_at_index is provided, the default is to generate the tree only to the point right after where the variable is introduced. That would be @2 above. \nTo facilitate generating errors when predications are being executed, @meaning_at_index can also be set automatically if special values of value are used. The special values must be a Python list in one of these forms:\n[\"AtPredication\", TreePredication, variable]: Evaluate variable's English meaning at the index from the predication object in TreePredication\n\n[\"AfterFullPhrase\", variable]: Evaluate variable's English meaning after the whole tree is evaluated\n\nFor example, if we have the following code:\n@Predication(vocabulary, names=[&quot;_give_v_1&quot;])\ndef give_v_1(context, state, e_introduced, x_giver_binding, x_what_binding, x_receiver_binding):\n  after_tree = [&quot;AfterFullPhrase&quot;, x_what_binding.variable.name]\n  print(\n        s(&quot;{after_tree} in the cupboard&quot;, state.get_binding(&#x27;tree&#x27;).value[0])\n        )\n\nAnd say the phrase \"give me the blue dog\", the code would print:\nthe blue dog is in the cupboard\n\nSince that is what x means after the entire phrase is done.\nIf we instead implement the _the_q predication like this:\n@Predication(vocabulary, names=[&quot;_the_q&quot;])\ndef the_q(context, state, x_variable_binding, h_rstr, h_body):\n  at_predication = [&quot;AtPredication&quot;, h_rstr[1], x_variable_binding.variable.name]\n  print(\n        s(&quot;{at_predication} is in the cupboard&quot;, state.get_binding(&#x27;tree&#x27;).value[0])\n        )\n\nAnd say the phrase \"give me the blue dog\", we would get:\nthe dog is in the cupboard\n\nSince we have chosen to get the representation of the variable after only the first item in the _the_q RSTR has been evaluated.  The RSTR for \"the blue dog\" would be a conjunction of [_dog_n_1(x8), _blue_a_1(e18,x8)] like this:\n                                               \u250c\u2500\u2500 _dog_n_1(x8)\n                                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x9)    \u2502             \u2514 _blue_a_1(e18,x8)\npronoun_q(x9,RSTR,BODY)            \u2502\n                    \u2514\u2500 _the_q(x8,RSTR,BODY)\n                                        \u2502                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\n                                        \u2514\u2500 pronoun_q(x3,RSTR,BODY)\n                                                               \u2514\u2500 _give_v_1(e2,x3,x8,x9)\n\nSo asking for [\"AtPredication\", h_rstr[1], x_variable_binding.variable.name] sets the second element of the RSTR to be the @meaning_at_index, which skips _blue_a_1.\nComprehensive source for the completed tutorial is available here\n\n", "title":"A. Generating English with S-strings", "teaser":"S-String Overview\nAs described in the Words in Failures topic, errors or messages to the user often need to include a representation of some noun that ...", "site":"Perplexity", "section":"Using Perplexity", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0000Overview", "excerpt":"Perplexity Internals\nThis section walks through the details of implementing the concepts described in the MRS Solver Conceptual section in a Python application.  It is assumed that the concepts from that section are understood (and links are always provided).\nThis section describes, in detail, how to build a solver like Perplexity. It is simplified, however, from the actual Perplexity code. It is designed to describe the basic architecture for someone who wants to understand the system more deeply without getting lost in the details, or for someone that wants to build a similar system.\nIf you just want to use the Perplexity system to build a natural language interface to a program, you can also just jump right to the \"Using Perplexity\" section. If you want to understand how it all works, you're in the right place.\n", "title":"Overview", "teaser":"Perplexity Internals\nThis section walks through the details of implementing the concepts described in the MRS Solver Conceptual section in a Python ap ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0010PredicationContract", "excerpt":"The Predication Contract\nIt is important to understand what MRS is and what a scope-resolved MRS is before reading this section. Visit those links first to understand the basic concepts.\n\nAs discussed in the \"Backtracking\" conceptual topic, we'll be solving MRS scope-resolved mrss using a backtracking approach. That topic discusses \"calling\" or \"evaluating\" predications without discussing exactly how this happens. This section will get specific.\nAs discussed previously, a scope-resolved MRS can be thought of as an equation that can be solved against a certain state of the world. One approach to solving an MRS is to walk the scope-resolved mrs in depth-first order and iteratively find assignments of variables that make the MRS true, using backtracking to try alternatives when they exist. This is the approach we'll be using. To solve an MRS tree using the backtracking approach, we need to code the predications to meet a specific contract that our backtracking solver will rely on. This is the \"predication contract\".\nRecall that predications are of the form: _table_n_1(x) or compound(e,x,x). Just like functions in mathematics or programming languages, they have a name and a set of arguments. We'll be treating the predications as classic programming language functions that can be \"called\" or \"invoked\".\nFor the purpose of defining the contract, we'll group predications into two types:\nRegular Predications: Declare something that must be true about their arguments. For example: _table_n_1(x) says that x must be a \"table\"\n\nQuantifier Predications: Act like a Regular Predication but also define the scope of a variable x. For example: a_q(x, rstr, body) declares a variable x that can now be used in its arguments. It also says that x must be an arbitrary, single object (since the quantifier is \"a\") that is true for the predications in the rstr and the body\n\nIdealized Contract\nWe'll start with an \"idealized contract\" because it clarifies how the backtracking solver works. It is \"idealized\" because it has relatively poor performance characteristics for large worlds. We'll tackle those characteristics with our \"practical contract\" next, but it is important to understand the fundamental approach first.\nThe contract is designed to \"solve\" an MRS for the variables defined in it, such as x1, x2, or e1. Our goal is to find all values of the variables that are True within a given world (i.e. find the \"solutions\"). The approach will be to call predications as functions and so we'll define the contract in terms of what these calls must look like. In the contract, the term bound means a variable is \"set\" or \"provided\", and unbound means it doesn't yet have a value:\nA Regular Predication is called with its arguments bound. If the predication's meaning is true given those arguments, it returns True. Otherwise, it returns False.\nA Quantifier Predication is called with its arguments bound except the variable it provides scope for (its first argument). \nIt must then iteratively set its unbound first argument to every possible object in the world and call its other arguments with each binding. \n\nIt then returns each solution (i.e. assignment of variables) for which the Quantifier Predication itself is true, given what was returned by its arguments and the quantification it is doing.\n\nThe \"solution\" to an MRS is the set of all variable assignments that resulted in the entire MRS tree being true\n\nA few observations about the contract:\nWhat the variables are -- i.e. how the world is represented in the program -- is not defined in the contract. It doesn't care.\n\nQuantifier Predications only scope x variables. These are the only variables that represent \"things in the world\" (aka \"individuals\"), that we are solving for. Event (e) variables are handled differently since they are an implementation detail of the MRS that gets used by the predications. They are not relevant here and get described in a another section.\n\nThis \"idealized contract\" has different requirements for Regular and Quantifier Predications. Regular Predications simply return True or False. Quantifier Predications return a set of answers consisting of variable assignments, iteratively. \n\nLet's walk through an example of each to clarify:\nA Regular Predication example: If table_n_1(x) is called with x set to a value that is:\na big red table, it should return True (it only verifies that it is a table, its other characteristics are ignored) \n\na persian cat, it should return False\n\nA Quantifier Predication example: When a_q(x, large_a_1(x), file(x)) is called, x will be unbound. It will internally set x to every object in the world and then call its arguments, applying the logic of the quantifier itself to the results. Each value of x for which that process is true should be returned, iteratively. \nSo, if the world is:\na folder\na small file\na large file\n\n... and we are solving:\na_q(x, large_a_1(x), file(x))\n\na_q would be called by the system with x unbound, and it would:\nSet x to a folder (the first item in the world).\n\nCall its first argument, large_a_1(x) using the contract. This will return False.\n\nSince this attempt failed, try the next value: Set x to a small file.\n\nCall its first argument, large_a_1(x) using the contract. This will return False.\n\nSince this attempt failed, try the next value: Set x to a large file.\n\nCall its first argument, large_a_1(x) using the contract. This will return True.\n\nSince that succeeded, call the second argument file(x) using the contract. This will return True.\n\nSince the quantifier \"a\" means \"a single arbitrary item\", the quantifier itself succeeds and it returns the first solution: {x=a large file}\n\nThis approach to solving an MRS works because every x variable in an MRS is scoped by a Quantifier Predication. It effectively tries every combination of objects in the world in every x variable. This is also why it is \"idealized\": the performance of this approach quickly becomes impractical.\nAs mentioned in the \"Representing Together\" conceptual topic, the values bound to all of the variables in these examples are actually sets represented as a tuple in Python, but the examples above and below gloss over this to keep things simple. \nPractical Contract\nThe performance of the contract can be greatly improved. Let's imagine a world with thousands of files and folders. In this world, a user says:\nA large file is in the folder.\n\nWhich results in this as one of the scope-resolved MRS predication trees:\n             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _folder_n_of(x10,i15) \n             \u2502                             \u250c\u2500\u2500 _large_a_1(e8,x3)\n             \u2502                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n             \u2502                 \u2502             \u2502\n_the_q(x10,RSTR,BODY)          \u2502             \u2514 _file_n_of(x3,i9)\n                  \u2514\u2500 _a_q(x3,RSTR,BODY)\n                                    \u2514\u2500 _in_p_loc(e2,x3,x10)\n\n\nUsing the idealized contract, x10 would be set to every one of the objects in the system by the_q, and, within that, x3 would again be set to every one of the objects in the system by _a_q, resulting in a worst-case performance of n^2, where n is the number of objects in the system.\nOne optimization we can perform is to notice that the first thing a quantifier predication does is to iteratively set its scoped variable and call its first argument (RSTR)  like this pseudo-code:\nfor item in &lt;everything in the world&gt;:\n    if rstr(item) is True:\n        ...\n\nSo the RSTR predication of _the_q (which is _folder_n_of in this case) has to check every single object to see if it is \"a folder\". Given that any regular predication could end up in the RSTR of a quantifier predication, we can instead change the contract to allow regular predications to do the iteration themselves, possibly using indices or knowledge of how the world is represented to do it much more quickly, like this:\nfor item in rstr():\n    ...\n\nThe RSTR regular predication can now be called with unbound arguments, and if so, it is responsible for finding the objects in the world that make it true, which it should be able to do much more efficiently.  This change effectively makes the contract the same for all predications at the cost of complicating the logic for regular predications a little. It is worth it for the performance improvement. \nSo, the contract we'll use in the rest of the tutorial is the \"practical contract\":\nCalling any predication with unbound variables should return the unbound variables bound to values from the world that, together, make it true. Calling it again should return a different set of bindings that also make it true. Eventually, the predication will run out of things that can be true and should then stop returning bindings (i.e. fail). \nCalling any predication with bound variables should simply return the same values if True or fail if not. In other words, it should iterate at most once.\n\nLet's go through our same example with the new contract. The world has these objects:\n`a folder`\n`a small file`\n`a large file`\n\nA Regular Predication example: \nIf _file_n_of(x) is called with x bound to:\na folder: it \"fails\" by not returning a solution\n\na small file: it \"succeeds\" by returning a solution with the variable bound as it already is: {x=a small file}\n\nIf _file_n_of(x) is called with an unbound x, it:\nSets x to the first \"file\" in the world using whatever algorithm is most efficient, finding: a small file and returns {x = a small file}\n\nSets x to the next \"file\" in the world using whatever algorithm is most efficient, finding: a large file and returns {x = a large file}\n\nRuns out of files and thus fails, meaning: stop returning solutions\n\nThe Quantifier Predication example is the same as before since we have simply started applying its contract to all predications now.\nTo help with performance of the system, the \"practical contract\" is the contract we will use for each predication we want the system to understand. \nFinal Performance Thoughts\nEven with this optimization, the example MRS for something like \"a large file is in the folder\" will need to check each \"large file\" in the system to see if it is in \"the\" folder (where \"the folder\" might mean \"current folder\"), which could still be a lot of iterations. There are further optimizations that can be done by the solver and many will depend on the particular world you execute against. Optimizing performance of a system like this is an ongoing task.\nThere are other ways to solve an MRS for the variables that make it true. For example, some MRS's can be converted to classic logic statements \"There exists an x such that...\" and various solvers can be used to solve for the variables in it: TODO: List references here. In addition, there are many uses for MRS that don't involve solving for the variables at all TODO: List references here. However, the backtracking approach is relatively straightforward and can be used for constrained worlds. It  allows us to explain the various aspects of DELPH-IN without getting too deep in complicated mathematics or logic.\nConclusion\nWe've talked through the contract required on functions that implement a predication, but aren't yet ready to implement one. First, we need to describe a key object used in the implementation: the State object.\nComprehensive source for the completed tutorial is available here\n\n", "title":"The Predication Contract", "teaser":"The Predication Contract\nIt is important to understand what MRS is and what a scope-resolved MRS is before reading this section. Visit those links fir ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0020PythonBasics", "excerpt":"The State object (and a Python Primer)\nPython Basics - Generator Functions\nThe predication contract can be implemented in any programming language, but we'll be using Python. This section should give enough background so that even readers not familiar with Python can read the code and understand the examples. Even if you know Python, skim through this section since we will be implementing a key class (State) used elsewhere in the documentation.\nThe Python language has functions, classes, methods, variables, operators, statements, and other elements shared by many imperative programming languages such as C++, Java, Javascript, Go, etc. How these work will be described as we go along and should be relatively straightforward to understand if you are proficient in an existing imperative programming language. \nPython also has a notion of \"iterators\" which needs a bit more attention. Iterators are objects that can be \"iterated\" or \"listed\" or \"looped through\". These can be lists represented in square brackets like [item1, item2] or read-only lists called \"tuples\" represented in parentheses as (item1, item2). They can also be special functions called \"generators\" which act like a list but allow code to dynamically generate the items that are returned.    \nYou iterate over an iterator of any type using the for ... in ... construct like this:\n# &#x27;#&quot; in Python starts a line with a comment\nfor item in iterator:\n\n    # Indenting in Python indicates the code that\n    # &quot;belongs&quot; to the thing above. Everything indented\n    # here will get looped over\n\n    # Now &quot;item&quot; has the first value from iterator\n    # and we can print it\n    print(item)\n\nIf you want to write code to dynamically build an iterator (called a \"generator\"), you simply write a fuction that calls yield to return each item. yield returns the value and then continues on the next line when the next value is asked for. If the function exits without a yield, the iteration stops (this is what we've been calling \"fail\" in the predication contract):\n# &quot;def&quot; defines a function in Python\n# Everything indented below it is in the function\ndef MyIterator1():\n    yield 1\n    yield 2\n    yield 3\n\n# Here&#x27;s another function that does\n# the same thing differently\ndef MyIterator2():\n    # A list in Python is surrounded by []\n    my_list = [1, 2, 3]\n    for index in my_list:\n        yield index\n\n\ndef OutputResults():\n    for item in MyIterator1():\n        print(item)\n    for item in MyIterator2():\n        print(item)\n\n# Calling OutputResults() prints:\n# 1\n# 2\n# 3\n# 1\n# 2\n# 3\n\nGiven the predication contract, we'll be doing lots of iteration and this syntactic sugar from Python makes it easier. \nThe State Class\nLet's work through how to implement a class in Python by creating the class that will hold the state of the world: State. The current state of all MRS variables and the state of everything in the world will be accessed through this class. Because we want the state to be changed by predications, we will include an instance of it as the first argument when calling them. \nThe implementation of the State object can be very simple for now. We will define two helper classes, VariableData and VariableBinding that can eventually hold other metadata but for now are simple containers for the variable name and value:\n# Use None in variable_data to represent a value\n# That is not bound to an actual variable\nclass VariableBinding(object):\n    def __init__(self, variable_data, value):\n        self.value = value\n        self.variable = variable_data\n\n    def __repr__(self):\n        return f&quot;{self.variable}={self.value}&quot;\n\n\nclass VariableData(object):\n    def __init__(self, name):\n        self.name = name\n\n    def __repr__(self):\n        return f&quot;{self.name}&quot;\n\nAnd then the State class will use these to store the state of the world and the MRS:\n# &quot;class&quot; declares an object-oriented class in Python\n# The parenthesis after the &quot;State&quot; class name surround\n# the object the class derives from (object)\nclass State(object):\n    # All class methods are indented under the\n    # class and take &quot;self&quot; as their first argument.\n    # &quot;self&quot; represents the class instance.\n\n    # &quot;__init__&quot; is a special method name that\n    # indicates the constructor, which is called to create\n    # a new instance of the class. Arguments beyond &quot;self&quot;\n    # get passed to the function when the instance is created\n    def __init__(self, objects):\n        # Class member variables are created by\n        # simply assigning to them\n        self.variables = dict()  # an empty dictionary\n\n        # &quot;objects&quot; are passed to us as an argument\n        # by whoever creates an instance of the class\n        self.objects = objects\n\n    # A standard &quot;class method&quot; is just a function definition,\n    # indented properly, with &quot;self&quot; as the first argument\n\n    # This is how predications will access the current value\n    # of MRS variables like &quot;x1&quot; and &quot;e1&quot;\n    def get_binding(self, variable_name):\n        # &quot;get()&quot; is one way to access a value in a dictionary.\n        # The second argument is what to return if the\n        # key doesn&#x27;t exist.  &quot;VariableBinding&quot; is the class that \n        # represents a variable binding in Perplexity\n        return self.variables.get(variable_name, VariableBinding(VariableData(variable_name), None))\n\n    # This is how predications will set the value\n    # of an &quot;x&quot; variable (or another type of variable\n    # that is acting like an unquantified &quot;x&quot; variable)\n    def set_x(self, variable_name, item):\n        # Make a *copy* of the entire object using the built-in Python\n        # class called &quot;copy&quot;, we pass it &quot;self&quot; so it copies this\n        # instance of the object\n        new_state = copy.deepcopy(self)\n\n        # Now we have a new &quot;State&quot; object with the same\n        # world state that we can modify.\n\n        # Find a common mistakes early: item must always be a tuple\n        # since x values are sets\n        assert item is None or isinstance(item, tuple)\n\n        if variable_name in new_state.variables:\n            # Need to copy the item so that if the list is changed it won&#x27;t affect\n            # the state which is supposed to be immutable\n            variable_data = copy.deepcopy(new_state.variables[variable_name].variable)\n        else:\n            variable_data = VariableData(variable_name, combinatoric)\n\n        new_state.variables[variable_name] = VariableBinding(variable_data, copy.deepcopy(item))\n\n        # &quot;return&quot; returns to the caller the new state with\n        # that one variable set to a new value\n        return new_state\n\n    def add_to_e(self, event_name, key, value):\n        newState = copy.deepcopy(self)\n        e_binding = newState.get_binding(event_name)\n        if e_binding.value is None:\n            e_binding = VariableBinding(VariableData(event_name), dict())\n            newState.variables[event_name] = e_binding\n\n        e_binding.value[key] = value\n        return newState\n\n    # This is an iterator (described above) that returns\n    # all the objects in the world bound to the specified variable\n    def all_individuals(self):\n        for item in self.objects:\n            yield item\n\nThe set_x() is how code changes the value of an x variable. It requires the value to be a set (as described in the \"Representing Together\" topic) and this is represented as tuple in Python. tuples are read-only lists. When this method is called, the state that is returned has the MRS value specified set to the new value, the old value is replaced.\nNote that the set_x() method does not actually \"set\" a value in the State object, it creates a copy of the current State object and sets the value in that.  This ensures that variables set for a given State object are never changed (they are immutable). Immutability allows our solver to reuse the same state object multiple times when calling a predication in order to get fresh values bound to the variables. And this, in turn, is important to allow backtracking through possible solutions to the MRS. The fact that the entire state object (not just the variables) gets copied will be important when we get to verbs that change the world (e.g. deleting a file). \nNote: There are much more efficient ways to isolate the data than copying the entire world, but we're doing a copy to keep the code simple. For example, database engines like MySQL have transactions to isolate different parts of code from changes until they should be seen. We could improve our simple implementation by keeping a difference list and not copying the entire state for every copy, but for now we'll keep it simple.\n\nThe add_to_e() method is used for adding information to an event (or e) variable. Instead of replacing the value of the variable, it represents each e variable as a Python dict and allows the caller to set or replace key/value pairs in it. Event variables have a very different semantic than x variables, as described in the Event section of the \"MRS\" topic. This behavior implements that semantic.\nTo create a State object that represents a file system, we'll need to create some simple objects to represent files and folders. These are going to be really simplistic so we don't get caught up in the file system code since that's not what we're focused on.  In these examples, we are really just using them as two kinds of objects in the system.  Files will not be in folders, folders will not contain files.  Our system will just have files and folders, on their own. No nesting, etc.\nclass File:\n    def __init__(self, name):\n        self.name = name\n\n\nclass Folder:\n    def __init__(self, name):\n        self.name = name\n\nNow we can create a state object for a simple world that has to folders and two files:\ndef Example0():\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;),\n                   File(name=&quot;file2.txt&quot;)])\n\nNote that an instance of the State object is created by calling it like a function. This really calls the __init__ function of State and passes the supplied argument (a list) to __init__. Each object in the list is created just like State was: by calling it as a function.\nNow you've seen some of the basic Python you'll see throughout the tutorial and we've defined the core State class we'll use in our predications.  Next, we'll implement a predication.\nComprehensive source for the completed tutorial is available here\n\n", "title":"State and Python Basics", "teaser":"The State object (and a Python Primer)\nPython Basics - Generator Functions\nThe predication contract can be implemented in any programming language, bu ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0030ImplementPredication", "excerpt":"Implementing a Predication\nWith that Python background and overview of the State object, we can now implement the predication contract for a predication to see how it all works. Let's implement the _folder_n_of predication in Python.  \nWe will be passing an instance of the State object as the first argument to every predication so that it can access its arguments and the world state. The variables will be passed in as strings like \"x1\" or \"e12\". To get their values, the code will look them up in the State object as shown below:\ndef folder_n_of(state, x):\n    x_value = state.get_binding(x).value\n    if x_value is None:\n        # Variable is unbound:\n        # iterate over all individuals in the world\n        # using the iterator returned by state.AllIndividuals()\n        iterator = state.all_individuals()\n    else:\n        # Variable is bound: create an iterator that will iterate\n        # over just that one by creating a list and adding it as\n        # the only element\n        # Remember that we are ignoring the fact that bindings are tuples\n        # in these examples so we assume there is only one value, and\n        # just retrieve it\n        iterator = [x_value[0]]\n\n    # By converting both cases to an iterator, the code that\n    # checks if x is &quot;a folder&quot; can be shared\n    for item in iterator:\n        # &quot;isinstance&quot; is a built-in function in Python that\n        # checks if a variable is an\n        # instance of the specified class\n        if isinstance(item, Folder):\n            # state.SetX() returns a *new* state that\n            # is a copy of the old one with just that one\n            # variable set to a new value\n            # Variable bindings are always tuples so we set\n            # this one using the tuple syntax: (item, )\n            new_state = state.set_x(x, (item, ))\n            yield new_state\n\nFirst notice that we are not really taking advantage of our \"practical predication contract\" in this code: we are literally just iterating through every object in the system. We can fix that later, but for the moment the examples are so small that it won't really matter.\nFurther on in the code, notice that the folder_n_of yields the new instance of the state object returned from setting x to a value.  This behavior (enforced by theState object) will allow our solver to pass around the same state object to a predication multiple times and get fresh values bound to the variables. Since we always make copies when setting a value, the solver can rely on a particular State object not being changed, even after it has been passed to a predication.\nNow we can write a simple test to call our first predication:\ndef Example1():\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;),\n                   File(name=&quot;file2.txt&quot;)])\n\n    for item in folder_n_of(state, &quot;x1&quot;):\n        print(item.variables)\n\n    print(&quot;\\nThe original `state` object is not changed:&quot;)\n    print(state.variables)\n\n# calling Example1() prints:\n{&#x27;x1&#x27;: x1=(Folder(Desktop),)}\n{&#x27;x1&#x27;: x1=(Folder(Documents),)}\n\nThe original `state` object is not changed:\n{}\n\nAgain, it is important to note that the initial state variable will not actually be changed at the end of the Example1() function. In order to print out the folders that were found by the predication, we need to print the value of x1 in the state returned from the predication. This is key to allowing us to call the same predication multiple times with the same State object to get different answers.\nNow we have one predication that implements the predication contract: it will iteratively return all the \"folders\" in the world when called with an unbound variable as we did here. This is the basic pattern we'll use for all predications from here on out. \nImplementing an adjective works the same way, let's implement _large_a_1 which is the predication for the adjective \"large\". We'll need to have a way to represent file sizes to do this first. We'll add an optional size to our File object:\nclass File:\n    def __init__(self, name, size=0):\n        self.name = name\n        self.size = size\n\n    def __repr__(self):\n        return f&quot;File({self.name}, {self.size})&quot;\n\nWe can almost use an exact copy of our _folder_n_of code for _large_a_1 because they both do the same thing: yield a value if they are true, and they are both just checking for a single thing on an object (or yielding all objects that \"are\" that thing). For \"large\", we'll arbitrarily decide that > 1000 bytes is \"large\", and that only files can be large:\n@Predication(vocabulary, name=&quot;_large_a_1&quot;)\ndef large_a_1(state, e, x):\n    x_value = state.get_binding(x).value\n    if x_value is None:\n        # Variable is unbound:\n        # iterate over all individuals in the world\n        # using the iterator returned by state.AllIndividuals()\n        iterator = state.all_individuals()\n    else:\n        # Variable is bound: create an iterator that will iterate\n        # over just that one by creating a list and adding it as\n        # the only element\n        # Remember that we are ignoring the fact that bindings are tuples\n        # in these examples so we assume there is only one value, and\n        # just retrieve it\n        iterator = [x_value[0]]\n\n    # By converting both cases to an iterator, the code that\n    # checks if x is &quot;a folder&quot; can be shared\n    for item in iterator:\n        # &quot;isinstance&quot; is a built-in function in Python that\n        # checks if a variable is an\n        # instance of the specified class\n        if isinstance(item, File) and item.size &gt; 1000:\n            # state.SetX() returns a *new* state that\n            # is a copy of the old one with just that one\n            # variable set to a new value\n            # Variable bindings are always tuples so we set\n            # this one using the tuple syntax: (item, )\n            new_state = state.set_x(x, (item, ))\n            yield new_state\n\nNote that we are ignoring the e event variable. That only comes into play when other predications want to modify the behavior of \"large\" like \"very large\". We can safely ignore it for now.\nNow we can run the same example that we used for folders, but call large_a_1 instead:\ndef Example1a():\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=1000),\n                   File(name=&quot;file2.txt&quot;, size=2000)])\n\n    for item in large_a_1(state, &quot;e1&quot;, &quot;x1&quot;):\n        print(item.variables)\n        \n# Running Example1a results in:\n{&#x27;x1&#x27;: x1=(File(file2.txt, 2000),)}\n\nSince the arguments to the predication are again unbound, this shows that the only large files in the world are \"file2.txt\".\nWith two predications implemented, We can start calling more than one predication and eventually deal with a whole scope-resolved MRS. But first we need to write the code that actually calls the predications by building the solver.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Implementing a Predication", "teaser":"Implementing a Predication\nWith that Python background and overview of the State object, we can now implement the predication contract for a predicati ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0040BuildSolver", "excerpt":"Converting MRS Text to Python Function Calls\nNow it is time to start working through the code that calls the Predication Contract: the solver.  The algorithm we'll use was described in the \"Backtracking\" conceptual topic.\nTo be able to solve an MRS, we first need a way to convert from the MRS predicate names to actual Python function calls. This section describes how.\nWe'll use a simple Python representation that allows easy conversion from a raw MRS document: each predication will be represented by a Python class called TreePredication that just records the basic information about the predication:\nclass TreePredication(object):\n    def __init__(self, index, name, args):\n        self.index = index\n        self.name = name\n        self.args = args\n\nindex is a number representing the order that the predication is called when solving the MRS using a depth-first search. All the rest of the arguments are pulled directly from the MRS formalism.\nTo convert this representation into a Python function and call it, we need a mapping from the string predication name (e.g. \"_folder_n_of\") to the function and module that implements the logic for it. \nWe'll start by building a Vocabulary class that will store all of the mappings. You add a mapping with add_predication() and find a mapping with predication(). Note that both the name and the arguments of a predicate that have to match to get a proper mapping:\nclass Vocabulary(object):\n    def __init__(self):\n        self.name_function_map = {}\n\n    def get_signature(self, name, args):\n        return f&quot;{name}({&#x27;,&#x27;.join(args)})&quot;\n\n    def add_predication(self, name, args, module, function):\n        signature = self.get_signature(name, arg_types_from_names(args))\n        self.name_function_map[signature] = (module, function)\n\n    def predication(self, tree_predication):\n        signature = self.get_signature(tree_predication.name, arg_types_from_names(tree_predication.args))\n        return self.name_function_map.get(signature, None)\n\nThen we need to find a way to populate the mappings. We'll do this using a Python feature called \"decorators\". It isn't important to understand how it works (but if you want to: read this section). For our purposes, just understand that by writing the code below:\ndef arg_types_from_names(args):\n    type_list = []\n    for arg_name in args:\n        # Allow single character arguments like &quot;x&quot; and &quot;e&quot;\n        # OR the format: &quot;x_actor&quot;, &quot;xActor&quot;, etc\n        arg_type = arg_name[0]\n        if arg_type not in [&quot;u&quot;, &quot;i&quot;, &quot;p&quot;, &quot;e&quot;, &quot;x&quot;, &quot;h&quot;, &quot;c&quot;]:\n            raise Exception(\n                f&quot;unknown argument type of {arg_type}&#x27;&quot;)\n\n        type_list.append(arg_type)\n\n    return type_list\n\n\n# Decorator that adds maps a DELPH-IN predicate to a Python function\ndef Predication(vocabulary, name=None):\n\n    def arg_types_from_function(function):\n        arg_spec = inspect.getfullargspec(function)\n\n        # Skip the first arg since it should always be &quot;state&quot;\n        arg_list = arg_types_from_names(arg_spec.args[1:])\n\n        return arg_list\n\n    def predication_decorator(function_to_decorate):\n        arg_list = arg_types_from_function(function_to_decorate)\n\n        vocabulary.add_predication(name,\n                                   arg_list,\n                                   function_to_decorate.__module__,\n                                   function_to_decorate.__name__)\n\n        return function_to_decorate\n\n    return predication_decorator\n\nWe can now write code like this:\n# You can create global variables in Python\n# by just setting their values outside the scope\n# of any function, like this:\nvocabulary = Vocabulary()\n\n@Predication(vocabulary, name=&quot;_folder_n_of&quot;)\ndef folder_n_of(state, x_target, i_ignored):\n    # ... implementation of folder_n_of goes here ...\n\nThe @Predication(...) \"decoration\" above the function runs code at file load time that sticks the Python function (i.e. def folder_n_of(...)) and the predication name (i.e. _folder_n_of) into the global instance of the Vocabulary class it is passed. \nThe global vocabulary instance will record the mapping between all the functions decorated with @Predication(vocabulary, name=...) and the predications they are implementing. With that, we can now build a call_predication() function that uses vocabulary to map the name of the predicate, plus the list of arguments, to an actual Python function and call it:\n# Takes a TreePredication object, maps it to a Python function and calls it\ndef call_predication(vocabulary, state, predication):\n    # Look up the actual Python module and\n    # function name given a string like &quot;folder_n_of&quot;.\n    # &quot;vocabulary.Predication&quot; returns a two-item list,\n    # where item[0] is the module and item[1] is the function\n    module_function = vocabulary.predication(predication)\n\n    # sys.modules[] is a built-in Python list that allows you\n    # to access actual Python Modules given a string name\n    module = sys.modules[module_function[0]]\n\n    # Functions are modeled as properties of modules in Python\n    # and getattr() allows you to retrieve a property.\n    # So: this is how we get the &quot;function pointer&quot; to the\n    # predication function we wrote in Python\n    function = getattr(module, module_function[1])\n\n    # [list] + [list] will return a new, combined list\n    # in Python. This is how we add the state object\n    # onto the front of the argument list\n    predication_args = predication.args\n    function_args = [state] + predication_args\n\n    # You call a function &quot;pointer&quot; and pass it arguments\n    # that are a list by using &quot;function(*function_args)&quot;\n    # So: this is actually calling our function (which\n    # returns an iterator and thus we can iterate over it)\n    for next_state in function(*function_args):\n        yield next_state\n\nNow we can write an example and run it:\n# List folders using call_predication\ndef Example2():\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;),\n                   File(name=&quot;file2.txt&quot;)])\n\n    for item in call_predication(vocabulary,\n                                 state,\n                                 TreePredication(0, &quot;_folder_n_of&quot;, [&quot;x1&quot;, &quot;i1&quot;])):\n        print(item.variables)\n        \n# calling Example2() prints:\n{&#x27;x1&#x27;: x1=(Folder(Desktop),)}\n{&#x27;x1&#x27;: x1=(Folder(Documents),)}\n\nExample2 calls call_predication() with the vocabulary object we've built and populated using the Predication decorator along with a State object.  call_predication then does the mapping of the predication name _folder_n_of to the actual Python function we've written, and performs the \"contract\" on it.  I.e. calls it with the specified arguments and expects that it will yield values that are true.\nThe reason it prints out the two folders in our world is that we left all the arguments to _folder_n_of unbound. The contract says that, in that case, it should yield all the things in the world that \"are a folder\", thus the behavior.\nWith this in place, we can tackle more complicated groups of predications such as conjunctions in the next section.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Initial Solver", "teaser":"Converting MRS Text to Python Function Calls\nNow it is time to start working through the code that calls the Predication Contract: the solver.  The al ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0050Conjunctions", "excerpt":"Solving Conjuctions of Predications\nThere are two ways to group predications together in an MRS: as a \"conjunction\" (i.e. a logical \"and\") or by using \"scopal arguments\". Scopal arguments allow passing a predication as an argument to another predication, much like lambda functions do in many programming languages. This is how you built up a tree of predications in a scope-resolved mrs. Now that we have a textual representation and a way to execute it, we can start resolving these more complex structures.\nTo handle a logical \"and\" or \"conjunction\" of predications, we'll perform a depth-first search of the scope-resolved MRS and call each predication in turn, if they succeed. We'll pass the state yielded by one predication to the next one. Once you've iterated through all of them, you have the set of things that are true for all the predications in the conjunction for that world.\nFor an example such as: _large_a_1(e,x) and _file_n_of(x) (to indicate a \"large file\"):\nStart with unbound variables and call the first predication using our predication contract: _large_a_1. \n\nIf it succeeds, take the resulting variable assignments that were yielded and call _file_n_of with those assignments. Since there are no more predications, if it succeeds, that result is the first answer.\n\nThen \"backtrack\" by going to step 2 and call _file_n_of again to get the next answer. \n\nWhen _file_n_of finally fails, backtrack to step 1 and call _large_a_1 for its next value and do it all again. \n\nWhen you have exhausted them all, you have a set of answers (in this case values for x and e) that represent all the \"large files\" in that world.\n\nThis works because the first predication (_large_a_1(e,x)) is called with unbound variables, and because of our predication contract, this means it will iterate through all the \"large\" things in the world, whether they are files, folders, beach balls, or whatever. When it returns, x is set to whatever it selected and the next predication (file_n_of) will only succeed if the item is a file, So, if we get all the way through, we have a \"large file\".  The \"backtracking\" behavior allows us to iterate through all the objects in the world to find all the \"large files\".\nWe'll implement this logic generally by creating a call() function. It will take the new TreePredication class, either as a single predication or a list of predications, and call the predications using the call_predication() function we defined in the previous section. \nIn the code for call() below, note that there is a new Python construct: yield from.  Where yield expects an actual object to yield as its argument, yield from says \"call the function I'm giving you and yield whatever that function yields\".\ndef call(vocabulary, state, term):\n    # If &quot;term&quot; is an empty list, we have solved all\n    # predications in the conjunction, return the final answer.\n    # &quot;len()&quot; is a built-in Python function that returns the\n    # length of a list\n    if len(term) == 0:\n        yield state\n    else:\n        # See if the first thing in the list is actually a list\n        # If so, we have a conjunction\n        if isinstance(term[0], list):\n            # This is a list of predications, so they should\n            # be treated as a conjunction.\n            # call each one and pass the state it returns\n            # to the next one, recursively\n            for nextState in call(vocabulary, state, term[0]):\n                # Note the [1:] syntax which means &quot;return a list\n                # of everything but the first item&quot;\n                yield from call(vocabulary, nextState, term[1:])\n\n        else:\n            # The first thing in the list was not a list\n            # so we assume it is just a TreePredication term.\n            # Evaluate it using call_predication\n            yield from call_predication(vocabulary, state, term)\n\nIt is worth making sure you understand how this function works since it is the core of our evaluator:\nWhen a list is passed to call, it is treated as a conjunction (i.e. \"and\"), and so each predication in the conjunction gets passed to call again, one after the other. If one fails, we stop iterating and check if there are other states yielded from the first predication and try again. If they all fail, the function stops searching. That is how \"and\" gets implemented, they all must succeed for the search to succeed.\nWhen a single predication is passed to call, it just gets directly passed on to call_predication().  Once it fails, we stop.\nNow, a scope-resolved MRS has a tree of predications, so to solve it, we do a single call to call() and pass the whole tree as term. But: this function only evaluates either single predications or conjunctions, what makes it able to solve a tree? The trick is that predications can have other predications as arguments (i.e. \"scopal arguments\"). The scopal arguments build the tree.  And: the predications with scopal arguments are themselves responsible for solving the scopal arguments. How scopal arguments do this is described in the next topic.\nTo finish this up, let's implement the last predication needed to make the example run and run it: file_n_of. It is an almost exact copy of _folder_n_of:\n@Predication(vocabulary, name=&quot;_file_n_of&quot;)\ndef _file_n_of(state, x, i):\n    x_value = state.get_binding(x).value\n    if x_value is None:\n        # Variable is unbound:\n        # iterate over all individuals in the world\n        # using the iterator returned by state.AllIndividuals()\n        iterator = state.all_individuals()\n    else:\n        # Variable is bound: create an iterator that will iterate\n        # over just that one by creating a list and adding it as\n        # the only element\n        # Remember that we are ignoring the fact that bindings are tuples\n        # in these examples so we assume there is only one value, and\n        # just retrieve it\n        iterator = [x_value[0]]\n\n    # By converting both cases to an iterator, the code that\n    # checks if x is &quot;a folder&quot; can be shared\n    for item in iterator:\n        # &quot;isinstance&quot; is a built-in function in Python that\n        # checks if a variable is an\n        # instance of the specified class\n        if isinstance(item, File):\n            # state.SetX() returns a *new* state that\n            # is a copy of the old one with just that one\n            # variable set to a new value\n            # Variable bindings are always tuples so we set\n            # this one using the tuple syntax: (item, )\n            new_state = state.set_x(x, (item, ))\n            yield new_state\n\nNow we can run an example with \"large files\" in conjunction, by putting _large_a_1 and _file_n_of in a list (indicating conjunction) and calling the call() method:\ndef Example3():\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=100),\n                   File(name=&quot;file2.txt&quot;, size=2000000)])\n\n    tree = [TreePredication(0, &quot;_large_a_1&quot;, [&quot;e1&quot;, &quot;x1&quot;]),\n            TreePredication(1, &quot;_file_n_of&quot;, [&quot;x1&quot;, &quot;i1&quot;])]\n\n    for item in call(vocabulary, state, tree):\n        print(item.variables)\n        \n# Running Example3 results in:\n{&#x27;x1&#x27;: x1=(File(file2.txt, 2000000),)}\n\nThis shows that the only \"large file\" in the world is \"file2.txt\".\nNow we have evaluated our first (very small) MRS document. Once we implement scopal arguments in the next topic, we'll be able to handle full scope-resolved mrss.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Solving Conjunctions", "teaser":"Solving Conjuctions of Predications\nThere are two ways to group predications together in an MRS: as a \"conjunction\" (i.e. a logical \"and\") or by using ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0060ScopalArguments", "excerpt":"Solving Scopal Arguments\n\"Scopal arguments\" are arguments to a predication that hold other predications, much like lambda functions can pass around functions as arguments in some programming languages.  They indicate that the predication should do its job using the results of the whole \"branch\" it is given. Exactly what job depends on the predication. The most common scopal arguments are seen in quantifiers like \"a, the, every, some\" etc. The job of a quantifier in a natural language is to limit (i.e. \"quantify\") the number of answers in some way. They do that by taking a RSTR argument that indicates what the quantifier is about (e.g. \"a folder\"), and a BODY argument that says what we are restricting the quantification to (e.g. \"something large\"). \nFor example, take the phrase: \"a file is large\". One of the scope-resolved MRSs for it is:\n           \u250c\u2500\u2500\u2500\u2500\u2500 _file_n_of(x3)\n_a_q(x3, RSTR,BODY)\n                \u2514 _large_a_1(e2,x3)\n\nWe can ignore for the moment variables of type e. We'll handle those later, they don't matter for this example.\n\nIf we convert this into text, it would be something like:\n _a_q(x3, _file_n_of(x3), _large_a_1(e2, x3))\n\nAnd finally, using our PredicationTree object, you get:\nTreePredication(0, &quot;_a_q&quot;, [&quot;x3&quot;,\n                                 TreePredication(1, &quot;_file_n_of&quot;, [&quot;x3&quot;, &quot;i1&quot;]),\n                                 TreePredication(2, &quot;_large_a_1&quot;, [&quot;e2&quot;, &quot;x3&quot;])])\n\nThis tree says, \"from all the files in the world model, return a single (arbitrary) one that is large\". It is indicating that we want the answer to be \"a\" (i.e. an arbitrary single) large file, whereas _large_a_1(e,x) and _file_n_of(x) would give us all large files.\nIf you look at the resolved tree, it really is just one predication with the other two as arguments. So, the call() solver we built is only going to call the function that implements _a_q. The work of implementing the rest of the tree goes to that predication itself. It works this way because the job of predications with scopal arguments is to handle how those trees get resolved. That is their whole point. Thus, they need control over the resolution behavior for those arguments.\nTo implement _a_q using our predication contract, we conceptually:\nFind the first set of variable assignments returned from the first argument (called RSTR), _file_n_of(x3), using call()\n\nUse those variable assignments to find a solution to the second argument (called BODY), _large_a_1(e2,x3), again using call()\n\nIf there was at least one answer, this is true. So: return each of the BODY solutions that worked from a_q, one by one.  Don't \"backtrack\" to find another \"file\" since a_q should only return \"one, arbitrary thing\". Other quantifiers like \"every\" will behave differently.\n\nIf there was not an answer from the first \"file\", go back to #1 and try again (remember that our contract says these predications will keep returning values until there are no more)\n\nIf there were no large files, a_q fails instead of returning any assignments, as per the predication contract. Here's the Python code that does all this:\n@Predication(vocabulary, name=&quot;_a_q&quot;)\ndef a_q(state, x, h_rstr, h_body):\n    for rstr_solution in call(vocabulary, state, h_rstr):\n        for body_solution in call(vocabulary, rstr_solution, h_body):\n            yield body_solution\n            return\n\nSince that is the only new predication required, we can run \"a large file\" now:\ndef Example4():\n    # Note that both files are &quot;large&quot; now\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=2000000),\n                   File(name=&quot;file2.txt&quot;, size=2000000)])\n\n    tree = TreePredication(0, &quot;_a_q&quot;, [&quot;x3&quot;,\n                                       TreePredication(1, &quot;_file_n_of&quot;, [&quot;x3&quot;, &quot;i1&quot;]),\n                                       TreePredication(2, &quot;_large_a_1&quot;, [&quot;e2&quot;, &quot;x3&quot;])])\n\n    for item in call(vocabulary, state, tree):\n        print(item.variables)\n        \n# Running Example4() results in:\n{&#x27;x3&#x27;: x3=(File(file1.txt, 2000000),)}\n\nNote that, even though we have made both files \"large\" for this example, only one, arbitrary, file is returned since the phrase is \"a large file\".\nAt this point we have a fully functional evaluator. Next we'll go through how to formulate a proper response to a proposition.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Solving Scopal Arguments", "teaser":"Solving Scopal Arguments\n\"Scopal arguments\" are arguments to a predication that hold other predications, much like lambda functions can pass around fu ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0080SimplePropositions", "excerpt":"Responding to Simple Propositions\nThe examples we've seen so far respond by printing out all the solutions that were found. It is time to start responding more like a human would. Here we'll walk through how to implement a better response to one type of phrase: the proposition. The next sections will walk through how to do the same for questions and commands.\n\"Propositions\" are sentences that declare something to be true like, \"A file is very large\". If true, a human would expect something like \"yep, you are right\" or \"correct!\" or \"yes, this is true\" as a response (error cases will be handled later). As described in the Sentence Types section, the English Resource Grammar helps us identify the type of phrase we received by providing a property called SF or \"Sentence Force\". A phrase is a proposition if the SF property of its index variable is prop.\nBelow is the MRS for \"A file is large\". e2 is the INDEX of the MRS, which represents the \"syntactic head\" or \"main point\" of the phrase.  It has a sentence force of \"proposition\": SF: prop.\n[ &quot;a file is large&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ _a_q&lt;0:1&gt; LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n          [ _file_n_of&lt;2:6&gt; LBL: h7 ARG0: x3 ARG1: i8 ]\n          [ _large_a_1&lt;10:15&gt; LBL: h1 ARG0: e2 ARG1: x3 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\nIn order to start responding to user phrases properly, we need to give the solver a dictionary of variable properties in addition to the predications. In fact, we can make it easier to read using the Python JSON format. The JSON format is basically a way of building up an object out of base types (strings, integers, etc) and lists and dictionaries, in a big tree. \nIn a JSON declaration:\nDictionaries are surrounded by {} with key/value pairs represented by \"key\":\"value\"\n\nLists are surrounded by [], with items in the list separated by ,\n\nStrings are surrounded by \"\"\n\nNumbers are just bare\n\nNote that a list can contain dicts, dicts can have lists as the value of a key value pair, etc.\nAs always, you can set the key of a dict using the syntax dict[\"key\"] = <value>. \n# Start with an empty dictionary\nmrs = {}\n\n# Set its &quot;index&quot; key to the value &quot;e2&quot;\nmrs[&quot;Index&quot;] = &quot;e2&quot;\n\n# Set its &quot;Variables&quot; key to *another* dictionary with\n# keys that represent the variables. Each of those has a &quot;value&quot; of\n# yet another dictionary that holds the properties of the variables\n# For now we&#x27;ll just fill in the SF property\nmrs[&quot;Variables&quot;] = {&quot;x3&quot;: {},\n                    &quot;i1&quot;: {},\n                    &quot;e2&quot;: {&quot;SF&quot;: &quot;prop&quot;}}\n\n# Set the &quot;RELS&quot; key to the scope-resolved MRS predications\nmrs[&quot;RELS&quot;] = TreePredication(0, &quot;_a_q&quot;, [&quot;x3&quot;,\n                                          TreePredication(1, &quot;_file_n_of&quot;, [&quot;x3&quot;, &quot;i1&quot;]),\n                                          TreePredication(2, &quot;_large_a_1&quot;, [&quot;e2&quot;, &quot;x3&quot;])])\n\nrespond_to_mrs(state, mrs)\n\nThus, the mrs variable ends up being a single json object that has the MRS definition (that we understand so far) in it.\nNow we can create a new function called respond_to_mrs() that inspects the MRS and uses the handy sentence_force() function to properly respond to a proposition:\n# Get the SF property of the Index of the MRS\ndef sentence_force(mrs):\n    if &quot;Index&quot; in mrs:\n        if mrs[&quot;Index&quot;] in mrs[&quot;Variables&quot;]:\n            if &quot;SF&quot; in mrs[&quot;Variables&quot;][mrs[&quot;Index&quot;]]:\n                return mrs[&quot;Variables&quot;][mrs[&quot;Index&quot;]][&quot;SF&quot;]\n\n\ndef respond_to_mrs(state, mrs):\n    # Collect all the solutions to the MRS against the\n    # current world state\n    solution = []\n    for item in call(vocabulary, state, mrs[&quot;RELS&quot;]):\n        solution.append(item)\n\n    force = sentence_force(mrs)\n    if force == &quot;prop&quot;:\n        # This was a proposition, so the user only expects\n        # a confirmation or denial of what they said.\n        # The phrase was &quot;true&quot; if there was at least one answer\n        if len(solution) &gt; 0:\n            print(&quot;Yes, that is true.&quot;)\n        else:\n            print(&quot;No, that isn&#x27;t correct.&quot;)\n\nNow we can run an example:\n# Evaluate the proposition: &quot;a file is large&quot;\ndef Example7():\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=2000000),\n                   File(name=&quot;file2.txt&quot;, size=2000000)])\n\n    # Start with an empty dictionary\n    mrs = {}\n\n    # Set its &quot;index&quot; key to the value &quot;e2&quot;\n    mrs[&quot;Index&quot;] = &quot;e2&quot;\n\n    # Set its &quot;Variables&quot; key to *another* dictionary with\n    # keys that represent the variables. Each of those has a &quot;value&quot; of\n    # yet another dictionary that holds the properties of the variables\n    # For now we&#x27;ll just fill in the SF property\n    mrs[&quot;Variables&quot;] = {&quot;x3&quot;: {},\n                        &quot;i1&quot;: {},\n                        &quot;e2&quot;: {&quot;SF&quot;: &quot;prop&quot;}}\n\n    # Set the &quot;RELS&quot; key to the scope-resolved MRS predication tree\n    mrs[&quot;RELS&quot;] = TreePredication(0, &quot;_a_q&quot;, [&quot;x3&quot;,\n                                              TreePredication(1, &quot;_file_n_of&quot;, [&quot;x3&quot;, &quot;i1&quot;]),\n                                              TreePredication(2, &quot;_large_a_1&quot;, [&quot;e2&quot;, &quot;x3&quot;])])\n\n    respond_to_mrs(state, mrs)\n    \n# Outputs:\nYes, that is true.\n\nIn the next section, we'll respond to questions.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Propositions", "teaser":"Responding to Simple Propositions\nThe examples we've seen so far respond by printing out all the solutions that were found. It is time to start respon ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0090SimpleQuestions", "excerpt":"Simple Questions\nNote that the MRS for, \"Is a file large?\" is identical to the proposition, \"A file is large.\" except that it has a different sentence force of SF: ques:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _a_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _file_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _large_a_1 LBL: h1 ARG0: e2 [ e SF: ques TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _file_n_of(x3,i8)\n_a_q(x3,RSTR,BODY)\n               \u2514\u2500 _large_a_1(e2,x3)\n\nHandling this can be as simple as responding \"yes\" or \"no\". We can add an elif clause to our respond_to_mrs() function to respond properly:\ndef respond_to_mrs(state, mrs):\n    # Collect all the solutions to the MRS against the\n    # current world state\n    solution = []\n    for item in call(vocabulary, state, mrs[&quot;RELS&quot;]):\n        solution.append(item)\n\n    force = sentence_force(mrs)\n    if force == &quot;prop&quot;:\n        # This was a proposition, so the user only expects\n        # a confirmation or denial of what they said.\n        # The phrase was &quot;true&quot; if there was at least one answer\n        if len(solution) &gt; 0:\n            print(&quot;Yes, that is true.&quot;)\n        else:\n            print(&quot;No, that isn&#x27;t correct.&quot;)\n            \n    elif sentence_force == &quot;ques&quot;:\n        # This was a question, so the user only expects\n        # a yes or no.\n        # The phrase was &quot;true&quot; if there was at least one answer\n        if len(solution) &gt; 0:\n            print(&quot;Yes.&quot;)\n        else:\n            print(&quot;No.&quot;)\n            \n\nSo far, so good. But what if the user says \"Which file is large?\":\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _which_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _file_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _large_a_1 LBL: h1 ARG0: e2 [ e SF: ques TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\nThe MRS looks very similar and still has a SF: ques sentence force. However, it used a new quantifier: _which_q. _which_q is simply a way for the MRS to indicate which variable the user is expecting an answer to. In this case: x3. These are called \"wh\" questions in linguistics (i.e. which, what, where, when, who). The quantifier itself doesn't quantify anything, it simply evaluates all the RSTR answers against the BODY and returns whatever worked. The ERG has several quantifiers that are just \"markers\"  like this. So, we're going to build a function they can share, called default_quantifier():\n@Predication(vocabulary, name=&quot;_which_q&quot;)\ndef which_q(state, x_variable, h_rstr, h_body):\n    yield from default_quantifier(state, x_variable, h_rstr, h_body)\n\n\ndef default_quantifier(state, x_variable, h_rstr, h_body):\n    # Find every solution to RSTR\n    for solution in Call(vocabulary, state, h_rstr):\n        # And return it if it is true in the BODY\n        for body_solution in Call(vocabulary, solution, h_body):\n            yield body_solution\n\nWhen _which_q is in a sentence, we should answer the question with all the values of the variable that it quantifies (x3 in this case). To do that, We need to build a function that finds the _which_q predication, if it exists. Since searching through the scope-resolved MRS predication tree is something we'll do often, we'll build another helper function called walk_tree_predications_until and then use it to build find_predication which will find one or more predications in a tree:\n# walk_tree_predications_until() is a helper function that just walks\n# the tree represented by &quot;term&quot;. For every predication found,\n# it calls func(found_predication)\n# If func returns anything besides &quot;None&quot;, it quits and\n# returns that value\ndef walk_tree_predications_until(term, func):\n    if isinstance(term, list):\n        # This is a conjunction, recurse through the\n        # items in it\n        for item in term:\n            result = walk_tree_predications_until(item, func)\n            if result is not None:\n                return result\n\n    else:\n        # This is a single term, call func with it if it is a predication\n        if isinstance(term, TreePredication):\n            result = func(term)\n            if result is not None:\n                return result\n\n            # If func didn&#x27;t say to quit, see if any of its terms are scopal\n            # i.e. are predications themselves\n            for arg in term.args:\n                if not isinstance(arg, str):\n                    result = walk_tree_predications_until(arg, func)\n                    if result is not None:\n                        return result\n\n    return None\n\n\n# Walk the tree represented by &quot;term&quot; and\n# return the predication that matches\n# &quot;predicate_name&quot; or &quot;None&quot; if none is found\ndef find_predication(term, predication_name):\n    if isinstance(predication_name, list):\n        predication_names = predication_name\n    else:\n        predication_names = [predication_name]\n\n    # This function gets called for every predication\n    # in the tree. It is a private function since it is\n    # only used here\n    def match_predication_name(predication):\n        if predication.name in predication_names:\n            return predication\n        else:\n            return None\n\n    # Pass our private function to WalkTreeUntil as\n    # a way to filter through the tree to find\n    # predication_name\n    return walk_tree_predications_until(term, match_predication_name)\n\nNow we can update the respond_to_mrs() function to answer \"which\" questions with actual values:\ndef respond_to_mrs(state, mrs):\n    # Collect all the solutions to the MRS against the\n    # current world state\n    solutions = []\n    for item in call(vocabulary, state, mrs[&quot;RELS&quot;]):\n        solutions.append(item)\n\n    force = sentence_force(mrs)\n    if force == &quot;prop&quot;:\n        # This was a proposition, so the user only expects\n        # a confirmation or denial of what they said.\n        # The phrase was &quot;true&quot; if there was at least one answer\n        if len(solutions) &gt; 0:\n            print(&quot;Yes, that is true.&quot;)\n        else:\n            print(&quot;No, that isn&#x27;t correct.&quot;)\n\n    elif force == &quot;ques&quot;:\n        # See if this is a &quot;WH&quot; type question\n        wh_predication = find_predication(mrs[&quot;RELS&quot;], &quot;_which_q&quot;)\n        if wh_predication is None:\n            # This was a simple question, so the user only expects\n            # a yes or no.\n            # The phrase was &quot;true&quot; if there was at least one answer\n            if len(solutions) &gt; 0:\n                print(&quot;Yes.&quot;)\n            else:\n                print(&quot;No.&quot;)\n        else:\n            # This was a &quot;WH&quot; question\n            # return the values of the variable asked about\n            # from the solution\n            # The phrase was &quot;true&quot; if there was at least one answer\n            if len(solutions) &gt; 0:\n                wh_variable = wh_predication.args[0]\n                for solutions in solutions:\n                    print(solutions.get_binding(wh_variable).value)\n            else:\n                print(&quot;I don&#x27;t know&quot;)\n\n... and run an example:\ndef Example8():\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=2000000),\n                   File(name=&quot;file2.txt&quot;, size=100)])\n\n    # Start with an empty dictionary\n    mrs = {}\n\n    # Set its &quot;index&quot; key to the value &quot;e2&quot;\n    mrs[&quot;Index&quot;] = &quot;e2&quot;\n\n    # Set its &quot;Variables&quot; key to *another* dictionary with\n    # keys that represent the variables. Each of those has a &quot;value&quot; of\n    # yet another dictionary that holds the properties of the variables\n    # For now we&#x27;ll just fill in the SF property\n    mrs[&quot;Variables&quot;] = {&quot;x3&quot;: {},\n                        &quot;i1&quot;: {},\n                        &quot;e2&quot;: {&quot;SF&quot;: &quot;ques&quot;}}\n\n    # Set the &quot;RELS&quot; key to the scope-resolved MRS tree\n    mrs[&quot;RELS&quot;] = TreePredication(0, &quot;_which_q&quot;, [&quot;x3&quot;,\n                                                 TreePredication(1, &quot;_file_n_of&quot;, [&quot;x3&quot;, &quot;i1&quot;]),\n                                                 TreePredication(2, &quot;_large_a_1&quot;, [&quot;e2&quot;, &quot;x3&quot;])])\n\n    respond_to_mrs(state, mrs)\n    \n# Prints:\n(File(file1.txt, 2000000),)\n\nNote that we have a subtle bug in our implementation of default_quantifier: we are not yet paying attention to NUM: sg.  If there were two large files, they would both get returned in this implementation. Really, they should return a failure since the premise of \"which file\" is wrong (since there are multiple of them). We'll address that once we get to the section on how to handle plurals.\nNext up is the \"command\" sentence force, which is a bit trickier.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Questions", "teaser":"Simple Questions\nNote that the MRS for, \"Is a file large?\" is identical to the proposition, \"A file is large.\" except that it has a different sentence ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0100SimpleCommands", "excerpt":"Simple Commands\nIt is finally time to implement a \"command\" so that users can actually do something with the system we are building. We're going to implement the \"delete\" command.\nWe'll start with the MRS for \"delete a large file\", which has a few new predications to deal with:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _a_q LBL: h9 ARG0: x8 [ x PERS: 3 NUM: sg IND: + ] RSTR: h10 BODY: h11 ]\n[ _large_a_1 LBL: h12 ARG0: e13 [ e SF: prop TENSE: untensed MOOD: indicative PROG: bool PERF: - ] ARG1: x8 ]\n[ _file_n_of LBL: h12 ARG0: x8 [ x PERS: 3 NUM: sg IND: + ] ARG1: i14 ]\n[ _delete_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ARG2: x8 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h10 qeq h12 &gt; ]\n\n                                               \u250c\u2500\u2500 _large_a_1(e13,x8)\n                                   \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)    \u2502             \u2502\n               \u2502                   \u2502             \u2514 _file_n_of(x8,i14)\npronoun_q(x3,RSTR,BODY)            \u2502\n                    \u2514\u2500 _a_q(x8,RSTR,BODY)\n                                        \u2514\u2500 _delete_v_1(e2,x3,x8)\n\nThe sentence force for this sentence is SF: comm meaning \"command\", determined the same way we described in a previous section.\nPronouns: pron and pronoun_q\nThe first two new predicates we encounter are: pron(x3) and pronoun_q(x3,RSTR,BODY) and they often work together as they do here. \npron(x) needs to fill x with an object that represents what the specified pronoun is referring to. It does this by looking at the properties for the x variable to determine if the pronoun is \"you\" (PERS: 2 -- second person), \"him/her\"(PERS: 3 -- third person), etc. and sets the variable to be whatever make sense in the current context and matches the properties.\nThere were not any pronouns in our command, \"delete a large file\", so where did the pron predication come from? In this case, the pronoun is an implied \"you\" since it is a command. I.e \"(You) delete a large file\".  Because we are not including the notion of other people in the file system, the only pronouns we probably care to understand are \"you\" (\"can you delete the file?\" or the implied case above) and maybe \"I\" (\"I want to delete a file\"). For now, let's just do \"you\" and fail otherwise. \nTo implement it, we'll need to create a new class to represent \"actors\" in the system, and then create an instance of it that represents the computer by adding it to the State object. We'll say that \"the computer\" is who should be returned when the user says \"You\" (second person) by setting the Actor object's person property to 2. The example below has the new Actor object and  the State object filled with one:\n# Represents something that can &quot;do&quot; things, like a computer\n# or a human (or a dog, etc)\nclass Actor(UniqueObject):\n    def __init__(self, name, person):\n        super().__init__()\n        self.name = name\n        self.person = person\n\n    def __repr__(self):\n        return f&quot;Actor(name={self.name}, person={self.person})&quot;\n        \n        \ndef Example9():\n    state = State([Actor(name=&quot;Computer&quot;, person=2),\n                   Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=2000000),\n                   File(name=&quot;file2.txt&quot;, size=1000000)])\n\n...\n\n(Why Actor derives from UniqueObject will be explained later in this topic.)\nThe pron implementation will look for an Actor object in the system with the same person value as the pron predication's x variable. To make sure the MRS is available for pron to inspect, we will create a \"fake\" mrs variable called mrs that is set to the MRS. Then any predication can inspect it. pron will retrieve it to do its work:\n@Predication(vocabulary, name=&quot;pron&quot;)\ndef pron(state, x_who):\n    mrs = state.get_binding(&quot;mrs&quot;).value[0]\n    person = mrs[&quot;Variables&quot;][x_who][&quot;PERS&quot;]\n    for item in state.all_individuals():\n        if isinstance(item, Actor) and item.person == person:\n            yield state.set_x(x_who, (item, ))\n            break\n\npronoun_q is just a simple, default quantifier predication that doesn't do anything except introduce the variable that pron uses. It acts just like which_q did in the Simple Questions topic  . So, pronoun_q will use the default_quantifer we defined in that topic:\n# This is just used as a way to provide a scope for a\n# pronoun, so it only needs the default behavior\n@Predication(vocabulary, name=&quot;pronoun_q&quot;)\ndef pronoun_q(state, x, h_rstr, h_body):\n    yield from default_quantifier(state, x, h_rstr, h_body)\n\nVerbs and State Changes: delete_v_1\nThe last new predication is _delete_v_1. _delete_v_1 is the first \"real\" verb we've dealt with. The others so far have been \"implied\" \"to be\" verbs for a phrase like \"a file is large\", and they don't show up in the MRS as described previously. A verb looks like every other predication: it has a name and arguments. And, because verbs can be modified by words like adverbs (e.g. \"permanently delete the file\"), it introduces an event to hang modifiers on. Like many verbs, the second argument represents the \"actor\": the person or thing doing the deleting. The final argument is what to delete.\nBecause our world state is simply a list of Python objects, the logic for deleting something is going to be trivial: remove the thing from the list. We can safely do this, even though other predications may still be iterating over them, because our State object is immutable (as described previously) and we will keep it that way by returning a new State object when something is deleted, just like we already do for setting variables.\nWe do have a problem, though. As you'll see later, we will encounter phrases like \"delete every file\", which have a different solution (i.e. state object) for each file that gets deleted. Each solution will have only one of the files deleted.  In order to end up with a single world state that has all the files deleted, we'll have to merge them together at the end somehow.\nThe solution is to create the concept of an Operation class which does \"something\" to the state. We will build different Operation classes that do different things over time (rename, copy, etc). If a command succeeds with multiple solutions, we can collect all of the operations from the solutions apply all of them to a single state object at the end. In fact, this is a good way to implement our system in general: build up a set of operations based on what the user says and, when we have the final, solved MRS, actually apply them to the file system. We won't be taking that final step here, but we would need to in order to handle all quantifiers. More on that in the section on Plurals.\nWe'll start by building some new mechanics into the State object to handle operations and create the DeleteOperation class:\nclass State(object):\n    def __init__(self, objects):\n        \n        ...\n        \n        # Remember all the operations applied to the state object\n        self.operations = []\n    \n    ...\n    \n    # Call to apply a list of operations to\n    # a new State object\n    def apply_operations(self, operation_list):\n        newState = copy.deepcopy(self)\n        for operation in operation_list:\n            operation.apply_to(newState)\n            newState.operations.append(operation)\n\n        return newState\n\n    def get_operations(self):\n        return copy.deepcopy(self.operations)\n        \n        \n# Delete any object in the system\nclass DeleteOperation(object):\n    def __init__(self, object_to_delete):\n        self.object_to_delete = object_to_delete\n\n    def apply_to(self, state):\n        for index in range(0, len(state.objects)):\n            # Use the `unique_id` property to compare objects since they\n            # may have come from different `State` objects and will thus be copies\n            if state.objects[index].unique_id == self.object_to_delete.unique_id:\n                state.objects.pop(index)\n                break\n\nThis is a case where our \"immutable\" State class is actually being changed. That's OK, though, because only the State class will be asking it to do this, and only on a fresh State object that isn't in use yet.\n\nAn \"operation\" in our system is simply an object that has an apply_to() method that does something to the State object it is passed. The DeleteOperation operation class deletes any object in the system by removing it from the State object's list of objects. It uses a unique_id property to compare objects since they may have come from different State objects and will thus be copies and just comparing the objects will fail. This could be implemented in many ways and one approach is described at the very end of this section.\nWhen an operation is applied to the State class, we'll remember what happened by adding the operation to the new State object's list of operations.  Then, once we've collected all the solutions to a problem like \"delete every file\", we can gather the operations from each of the solutions using the get_operations() method, and apply them, as a group, to the original state. This will give us a new state object that combines them all. You'll see this at the end of this section.\nSo now we can finally implement the verb delete_v_1:\n@Predication(vocabulary, name=&quot;_delete_v_1&quot;)\ndef delete_v_1(state, e_introduced, x_actor, x_what):\n    # We only know how to delete things from the\n    # computer&#x27;s perspective\n    x_actor_value = state.get_binding(x_actor).value\n    if x_actor_value is not None and len(x_actor_value) == 1 and isinstance(x_actor_value[0], Actor) and x_actor_value[0].name == &quot;Computer&quot;:\n        x_what_value = state.get_binding(x_what).value\n        \n        # Only handle deleting one object at a time, don&#x27;t support &quot;together&quot;\n        if len(x_what_value) == 1:\n            yield state.apply_operations([DeleteOperation(x_what_value[0])])\n\ndelete_v_1 first checks to make sure the actor is \"Computer\". That's because the user could have said \"Bill deletes a file\" and we'd prefer the system to say \"I don't know who Bill is\" than to just delete the file. We should only delete the file when the computer is told to delete it. \nThen, we use our new apply_operations() method to do the deleting and return the new state object with the object gone.\nFinally, we need to add a new clause to respond_to_mrs() to handle commands. It will simply say \"Done!\" if the command worked. It will also collect up all of the operations that happened and apply them to a single state object. This isn't really necessary for this example since we are only deleting one file, but is necessary for phrases like \"delete every file\":\ndef respond_to_mrs(state, mrs):    \n    ...\n    \n    elif force == &quot;comm&quot;:\n        # This was a command so, if it works, just say so\n        # We&#x27;ll get better errors and messages in upcoming sections\n        if len(solutions) &gt; 0:\n            # Collect all the operations that were done\n            all_operations = []\n            for solution in solutions:\n                all_operations += solution.get_operations()\n\n            # Now apply all the operations to the original state object and\n            # print it to prove it happened\n            final_state = state.apply_operations(all_operations)\n\n            print(&quot;Done!&quot;)\n            print(final_state.objects)\n        else:\n            print(&quot;Couldn&#x27;t do that.&quot;)\n\nNow we can run an example for \"delete a large file\":\ndef Example9():\n    state = State([Actor(name=&quot;Computer&quot;, person=2),\n                   Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=2000000),\n                   File(name=&quot;file2.txt&quot;, size=1000000)])\n\n    mrs = {}\n    mrs[&quot;Index&quot;] = &quot;e2&quot;\n    mrs[&quot;Variables&quot;] = {&quot;x3&quot;: {&quot;PERS&quot;: 2},\n                        &quot;x8&quot;: {},\n                        &quot;e2&quot;: {&quot;SF&quot;: &quot;comm&quot;},\n                        &quot;e13&quot;: {}}\n\n    mrs[&quot;RELS&quot;] = TreePredication(0, &quot;pronoun_q&quot;, [&quot;x3&quot;,\n                                                   TreePredication(1, &quot;pron&quot;, [&quot;x3&quot;]),\n                                                   TreePredication(0, &quot;_a_q&quot;, [&quot;x8&quot;,\n                                                                               [TreePredication(1, &quot;_file_n_of&quot;, [&quot;x8&quot;, &quot;i1&quot;]), TreePredication(2, &quot;_large_a_1&quot;, [&quot;e1&quot;, &quot;x8&quot;])],\n                                                                               TreePredication(3, &quot;_delete_v_1&quot;, [&quot;e2&quot;, &quot;x3&quot;, &quot;x8&quot;])])]\n                                     )\n\n    state = state.set_x(&quot;mrs&quot;, (mrs,))\n    respond_to_mrs(state, mrs)\n    \n# Outputs:\nDone!\n[Actor(name=Computer, person=2), Folder(Desktop), Folder(Documents), File(file2.txt, 1000000)]\n\nYou can see by the output that the only large file in the system was deleted: \"file1.txt\".\nThere are a couple of interesting things about what we've done. The code for delete_v_1 will delete anything, so the phrase \"delete you\" will actually work! Of course, it will then mess up the system because every command after that will not be able to find the implied \"you\". This is part of the magic and the challenge of implementing MRS predications, if you implement them right, they can be very general and allow constructions that you hadn't thought of.\nFootnote: Identity\nBecause the system is built around immutable state, we will sometimes end up with two State objects and need to be able to find the same object contained in either one.  This happened in the implementation of the DeleteOperation. We need a way to compare objects across state objects. The easiest way is to give all the objects in the system a globally unique id that can be easily compared. In the example above, we created a base class, UniqueObject that does this and derived everything from it:\nclass UniqueObject(object):\n    def __init__(self):\n        self.unique_id = uuid.uuid4()\n        \nclass File(UniqueObject):\n    def __init__(self, name, size=0):\n        super().__init__()\n        self.name = name\n        self.size = size\n\n    def __repr__(self):\n        return f&quot;File({self.name}, {self.size})&quot;\n\n\nclass Folder(UniqueObject):\n    def __init__(self, name):\n        super().__init__()\n        self.name = name\n\n    def __repr__(self):\n        return f&quot;Folder({self.name})&quot;\n\nThen the caller can just compare the .unique_id property, like we did in DeleteOperation:\nclass DeleteOperation(object):\n    def __init__(self, object_to_delete):\n        self.object_to_delete = object_to_delete\n\n    def apply_to(self, state):\n        for index in range(0, len(state.objects)):\n            # Use the `unique_id` property to compare objects since they\n            # may have come from different `State` objects and will thus be copies\n            if state.objects[index].unique_id == self.object_to_delete.unique_id:\n                state.objects.pop(index)\n                break\n\nComprehensive source for the completed tutorial is available here\n\n", "title":"Commands", "teaser":"Simple Commands\nIt is finally time to implement a \"command\" so that users can actually do something with the system we are building. We're going to im ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0105ErrorsChoosingWhichFailure", "excerpt":"Reporting Failures\nSo far, we've only dealt with successful examples: examples where the phrase has a solution.  Let's see what happens when we say a phrase that has no solution:\n# &quot;a file is large&quot; in a world with no large files\ndef Example10():\n    # Note neither file is &quot;large&quot; now\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=100),\n                   File(name=&quot;file2.txt&quot;, size=100)])\n\n    # Start with an empty dictionary\n    mrs = {}\n\n    # Set its &quot;index&quot; key to the value &quot;e2&quot;\n    mrs[&quot;Index&quot;] = &quot;e2&quot;\n\n    # Set its &quot;Variables&quot; key to *another* dictionary with\n    # keys that represent the variables. Each of those has a &quot;value&quot; of\n    # yet another dictionary that holds the properties of the variables\n    # For now we&#x27;ll just fill in the SF property\n    mrs[&quot;Variables&quot;] = {&quot;x3&quot;: {},\n                        &quot;i1&quot;: {},\n                        &quot;e2&quot;: {&quot;SF&quot;: &quot;prop&quot;}}\n\n    mrs[&quot;RELS&quot;] = TreePredication(0, &quot;_a_q&quot;, [&quot;x3&quot;,\n                                       TreePredication(1, &quot;_file_n_of&quot;, [&quot;x3&quot;, &quot;i1&quot;]),\n                                       TreePredication(2, &quot;_large_a_1&quot;, [&quot;e2&quot;, &quot;x3&quot;])])\n\n    respond_to_mrs(state, mrs)\n        \n# Outputs:\n\n\nNothing gets printed out because we haven't implemented a way to report errors from the system. Now it is time to dig into failures.\nFailure Codes and Data\nTo centralize error reporting and make the code easy to maintain, we will separate the notion of the error code from the actual text that gets shown to the user. That way, we can report the same error in multiple places but change the wording shown to the user in one place.\nThe format will be a simple list. The first list item is a string representing the error code, and the rest of the list is whatever information is needed to generate the string later.  For example:\n[&quot;notAThing&quot;, &quot;dog&quot;, &quot;car&quot;]\n\n... could later be used to generate the string:\nA &quot;dog&quot; is not a &quot;car&quot;\n\nRecording Errors\nRecall from the conceptual section on reporting errors that the best error is usually the deepest error, the one which was generated at the deepest part of the predication tree when traversing it in a depth-first manner. To track current depth, and allow for reporting errors, we'll build a new class called ExecutionContext and create a single global instance of it.  Our MRS solver code will be modified to use it to record the current depth as the tree is traversed, and the predication implementations will record their errors in it. ExecutionContext will use the current depth to only remember the \"deepest\" error.  \nHere's the class, along with its global instance and a helper to retrieve it. It doesn't yet include the changes to call() needed to record the current predication index, we'll do that next:\nclass ExecutionContext(object):\n    def __init__(self):\n        self._error = None\n        self._error_predication_index = -1\n        self._predication_index = -1\n\n    def deepest_error(self):\n        return self._error\n        \n    def report_error(self, error):\n        if self._error_predication_index &lt; self._predication_index:\n            self._error = error\n            self._error_predication_index = self._predication_index\n\n\n# Create a global execution context\nexecution_context = ExecutionContext()\n\n\n# Helper to access the global context so code is isolated from\n# how we manage it\ndef context():\n    return execution_context\n\nNow we can modify our main entry point, respond_to_mrs to start using this.  It will retrieve the error string if there were no solutions and use it for each sentence type in the failure case. Here we can see the changes for the 'prop' sentence type:\n    ...\n    \n    error = generate_message(state, context().deepest_error()) if len(solutions) == 0 else None\n    \n    ...\n    \n    if force == &quot;prop&quot;:\n        ...\n        if len(solutions) &gt; 0:\n            print(&quot;Yes, that is true.&quot;)\n        else:\n            print(f&quot;No, that isn&#x27;t correct:{error}&quot;)\n            \n    etc.\n\n... and here is the full code:\ndef respond_to_mrs(state, mrs):\n    # Collect all the solutions to the MRS against the\n    # current world state\n    solutions = []\n    for item in call(vocabulary, state, mrs[&quot;RELS&quot;]):\n        solutions.append(item)\n\n    error = generate_message(state, context().deepest_error()) if len(solutions) == 0 else None\n    force = sentence_force(mrs)\n    if force == &quot;prop&quot;:\n        # This was a proposition, so the user only expects\n        # a confirmation or denial of what they said.\n        # The phrase was &quot;true&quot; if there was at least one answer\n        if len(solutions) &gt; 0:\n            print(&quot;Yes, that is true.&quot;)\n        else:\n            print(f&quot;No, that isn&#x27;t correct:{error}&quot;)\n\n    elif force == &quot;ques&quot;:\n        # See if this is a &quot;WH&quot; type question\n        wh_predication = find_predication(mrs[&quot;RELS&quot;], &quot;_which_q&quot;)\n        if wh_predication is None:\n            # This was a simple question, so the user only expects\n            # a yes or no.\n            # The phrase was &quot;true&quot; if there was at least one answer\n            if len(solutions) &gt; 0:\n                print(&quot;Yes.&quot;)\n            else:\n                print(f&quot;No, {error}&quot;)\n        else:\n            # This was a &quot;WH&quot; question\n            # return the values of the variable asked about\n            # from the solution\n            # The phrase was &quot;true&quot; if there was at least one answer\n            if len(solutions) &gt; 0:\n                wh_variable = wh_predication.args[0]\n                for solutions in solutions:\n                    print(solutions.get_binding(wh_variable).value)\n            else:\n                print(f&quot;{error}&quot;)\n\n    elif force == &quot;comm&quot;:\n        # This was a command so, if it works, just say so\n        # We&#x27;ll get better errors and messages in upcoming sections\n        if len(solutions) &gt; 0:\n            # Collect all the operations that were done\n            all_operations = []\n            for solution in solutions:\n                all_operations += solution.get_operations()\n\n            # Now apply all the operations to the original state object and\n            # print it to prove it happened\n            final_state = state.apply_operations(all_operations)\n\n            print(&quot;Done!&quot;)\n            print(final_state.objects)\n        else:\n            print(f&quot;Couldn&#x27;t do that: {error}&quot;)\n\n\nNext, we'll need to update our functions that traverse the tree to record the current predication index. We'll do this by moving the call() and call_predication() functions to be members of the ExecutionContext class and update call() to set the predication index.  Here is the only change to call():\nclass ExecutionContext(object):\n    ...\n\n    def call(self, vocabulary, state, term):\n        # See if the first thing in the list is actually a list\n        # If so, we have a conjunction\n        if isinstance(term, list):\n            \n            ...\n            \n        else:\n            # The first thing in the list was not a list\n            # so we assume it is just a TreePredication term.\n            # Evaluate it using call_predication\n            last_predication_index = self._predication_index\n            self._predication_index += 1\n\n            yield from self.call_predication(vocabulary, state, term)\n\n            # Restore it since we are recursing\n            self._predication_index = last_predication_index\n        \n        ...\n\n... and here is the full code of ExecutionContext now:\nclass ExecutionContext(object):\n    def __init__(self):\n        self._error = None\n        self._error_predication_index = -1\n        self._predication_index = -1\n\n    def deepest_error(self):\n        return self._error\n\n    def report_error(self, error):\n        if self._error_predication_index &lt; self._predication_index:\n            self._error = error\n            self._error_predication_index = self._predication_index\n\n    def call(self, vocabulary, state, term):\n        # See if the first thing in the list is actually a list\n        # If so, we have a conjunction\n        if isinstance(term, list):\n            # If &quot;term&quot; is an empty list, we have solved all\n            # predications in the conjunction, return the final answer.\n            # &quot;len()&quot; is a built-in Python function that returns the\n            # length of a list\n            if len(term) == 0:\n                yield state\n            else:\n                # This is a list of predications, so they should\n                # be treated as a conjunction.\n                # call each one and pass the state it returns\n                # to the next one, recursively\n                for nextState in self.call(vocabulary, state, term[0]):\n                    # Note the [1:] syntax which means &quot;return a list\n                    # of everything but the first item&quot;\n                    yield from self.call(vocabulary, nextState, term[1:])\n\n        else:\n            # The first thing in the list was not a list\n            # so we assume it is just a TreePredication term.\n            # Evaluate it using call_predication\n            last_predication_index = self._predication_index\n            self._predication_index += 1\n\n            yield from self.call_predication(vocabulary, state, term)\n\n            # Restore it since we are recursing\n            self._predication_index = last_predication_index\n\n    # Takes a TreePredication object, maps it to a Python function and calls it\n    def call_predication(self, vocabulary, state, predication):\n        # Look up the actual Python module and\n        # function name given a string like &quot;folder_n_of&quot;.\n        # &quot;vocabulary.Predication&quot; returns a two-item list,\n        # where item[0] is the module and item[1] is the function\n        module_function = vocabulary.predication(predication)\n\n        if module_function is None:\n            raise NotImplementedError(f&quot;Implementation for Predication {predication} not found&quot;)\n\n        # sys.modules[] is a built-in Python list that allows you\n        # to access actual Python Modules given a string name\n        module = sys.modules[module_function[0]]\n\n        # Functions are modeled as properties of modules in Python\n        # and getattr() allows you to retrieve a property.\n        # So: this is how we get the &quot;function pointer&quot; to the\n        # predication function we wrote in Python\n        function = getattr(module, module_function[1])\n\n        # [list] + [list] will return a new, combined list\n        # in Python. This is how we add the state object\n        # onto the front of the argument list\n        predication_args = predication.args\n        function_args = [state] + predication_args\n\n        # You call a function &quot;pointer&quot; and pass it arguments\n        # that are a list by using &quot;function(*function_args)&quot;\n        # So: this is actually calling our function (which\n        # returns an iterator and thus we can iterate over it)\n        for next_state in function(*function_args):\n            yield next_state\n\nThe system will now remember which is the right (\"deepest\") error to report. The next section will describe what the error should say. This is not as obvious as it might seem. \nComprehensive source for the completed tutorial is available here\n\n", "title":"Choosing a Failure", "teaser":"Reporting Failures\nSo far, we've only dealt with successful examples: examples where the phrase has a solution.  Let's see what happens when we say a  ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0110ErrorsReportingAFailure", "excerpt":"Reporting a Failure Naively\nIn the previous section we updated our code to support reporting errors (via ExecutionContext.report_error()) and updated the ExecutionContext.call() method to record the index of our currently executing predication.  This allowed us to keep track of the \"deepest\" error.\nWith that in place, we can now start reporting errors from predications. As outlined in the predication contract, \"failure\" is when the predication is not true for its arguments. So, let's add code at the end of large_a_1 to record an error when there is a failure. We'll call the new report_error() method and pass it what seems like the right error given the code:\n@Predication(vocabulary, name=&quot;_large_a_1&quot;)\ndef large_a_1(state, e, x):\n        ...\n    \n        if isinstance(item, File):\n            if item.size &gt; 1000:\n                # state.SetX() returns a *new* state that\n                # is a copy of the old one with just that one\n                # variable set to a new value\n                # Variable bindings are always tuples so we set\n                # this one using the tuple syntax: (item, )\n                new_state = state.set_x(x, (item, ))\n                yield new_state\n            else:\n                context().report_error([&quot;notLarge&quot;, item])\n\nlarge_a_1 looks at an object, checks if it has a size at all, and if so, checks if it is \"large\" and succeeds if it is. If not, a logical error to report would be \"'this thing I was passed' is not large\", which is what the code does.\nWe finish by updating generate_message() to convert the error to a string:\ndef generate_message(state, error):\n    ... \n    \n    elif error_constant == &quot;notLarge&quot;:\n        return f&quot;&#x27;{arg1}&#x27; is not large&quot;\n\n    ...\n\n... and then run the sample:\n# &quot;a file is large&quot; in a world with no large files\ndef Example10():\n    # Note neither file is &quot;large&quot; now\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=100),\n                   File(name=&quot;file2.txt&quot;, size=100)])\n\n    # Start with an empty dictionary\n    mrs = {}\n\n    # Set its &quot;index&quot; key to the value &quot;e2&quot;\n    mrs[&quot;Index&quot;] = &quot;e2&quot;\n\n    # Set its &quot;Variables&quot; key to *another* dictionary with\n    # keys that represent the variables. Each of those has a &quot;value&quot; of\n    # yet another dictionary that holds the properties of the variables\n    # For now we&#x27;ll just fill in the SF property\n    mrs[&quot;Variables&quot;] = {&quot;x3&quot;: {},\n                        &quot;i1&quot;: {},\n                        &quot;e2&quot;: {&quot;SF&quot;: &quot;prop&quot;}}\n\n    mrs[&quot;RELS&quot;] = TreePredication(0, &quot;_a_q&quot;, [&quot;x3&quot;,\n                                       TreePredication(1, &quot;_file_n_of&quot;, [&quot;x3&quot;, &quot;i1&quot;]),\n                                       TreePredication(2, &quot;_large_a_1&quot;, [&quot;e2&quot;, &quot;x3&quot;])])\n\n    respond_to_mrs(state, mrs)\n    \n# Outputs:\nNo, that isn&#x27;t correct:&#x27;File(file1.txt, 100)&#x27; is not large\n\nWhile the code is all working correctly, it isn't responding the way a user would expect. If nothing is large, a human would say something like \"No, nothing is large\", \"No, a file isn't large\" or maybe: \"No files are large\".  Our code is picking the first thing that appeared and saying \"the [first file that was checked] is not large\", which is pretty random. \nWe can correct it by remembering what is going on at the abstract level: The user will only see this error if there ends up being no large files. If there are large files, the system will report, \"That is true!\".  So, what should get reported is, \"[whatever domain is being checked] is not large\".  In this case the \"domain being checked\" is \"a file\". So it should say \"a file is not large\" (or \"no files are large\"). We need a way to get a textual description of \"the domain that is being checked\".\nRight now, all that large_a_1 knows about the domain of x is that it is a variable that could hold anything. It doesn't know that x represents a file (we'll fix this next). So, the best we can do at the moment is to say \"a thing\":\n@Predication(vocabulary, name=&quot;_large_a_1&quot;)\ndef large_a_1(state, e_introduced, x_target):\n    \n    ...\n    \n            ReportError([&quot;thingNotLarge&quot;])\n\nWith that (and the appropriate changes to generate_message(), if we run \"A file is large\" through the system with no large files, we'll get: \"A thing is not large\".  This is the best we can do for now. \nThe next section will improve it to say \"A file is not large\" which is more clear.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Naive Failure Text", "teaser":"Reporting a Failure Naively\nIn the previous section we updated our code to support reporting errors (via ExecutionContext.report_error()) and updated  ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0120ErrorsConceptualFailures", "excerpt":"Converting Variable Domains to English\nSo far, the error reporting code for large_a_1 looks like this:\n@Predication(vocabulary, name=&quot;_large_a_1&quot;)\ndef large_a_1(state, e_introduced, x_target):\n            \n    ...\n            # &quot;A thing is not large&quot;\n            context().report_error([&quot;thingNotLarge&quot;)\n\nIn a world with no large files, it responds to: \"A file is large\" with: \"A thing is not large\". This is because, in the previous section, we didn't know how to describe the \"domain\" that x is restricted to. Remember that the large_a_1 predication will be used for anything the user references as \"large\", so it will need to be flexible about how it reports its failures.  x won't always contain files.\nFor example, here is a scope-resolved mrs for \"A file is large\":\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _file_n_of(x3,i8)\n_a_q(x3,RSTR,BODY)    \n               \u2514\u2500 _large_a_1(e2,x3)\n\nThe error in that MRS from _large_a_1 should say \"A file is not large\" since the only things that can be in x by the time it gets to _large_a_1 have been restricted to files. \nFor \"A dog is large\":\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _dog_n_1(x3)\n_a_q(x3,RSTR,BODY)    \n               \u2514\u2500 _large_a_1(e2,x3)\n\nThe error in that MRS from _large_a_1 should say \"A dog is not large\". \netc. \nIf we can get a description of the domain of x, we can write one error message and have it work no matter how the predication is used.\nDetermining What to Call the Domain of \"x\"\nWe can figure out what the variable x has been restricted to by taking advantage of some things we know:\nWe know the tree is executed depth-first\n\nWe know the predications in the tree\n\nWe know which predication reported the error \n\nThus: We know where the failed predication is in the execution order.\nSo, in the scope-resolved mrs for \"a dog is large\":\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _dog_n_1(x3)\n_a_q(x3,RSTR,BODY)    \n               \u2514\u2500 _large_a_1(e2,x3)\n\n... if the error came from _large_a_1, we must have finished _dog_n_1 but be in the middle of resolving _a_q.  At that point, the variable x3 contains something that is restricted to dog things (not even *a* dog yet).  In this way, we can write code which gives the English description of a variable at a certain point in the tree's execution. We can use that to build failure messages that have the proper \"domain\" for any phrase we encounter.\nTo do this, let's create a function, english_for_delphin_variable(), which takes:\nThe variable we want an English representation of \n\nThe MRS\n\nThe predication index (i.e. the place in the tree) for which we want the English\n\nIt will walk the tree in execution order, using the function we've written in a previous section called walk_tree_predications_until(). This function will pass each predication, in execution order, to a different function called refine_NLG_with_predication() (\"NLG\" stands for \"Natural Language Generation\"). That function will determine if the predication is restricting the domain of the variable somehow. If so, it will add some data to a structure called nlg_data that records what the English description of the restriction is. At the end, we'll call a function (convert_to_english()) that takes all the gathered data and turns it into English:\n# Given the index where an error happened and a variable,\n# return what that variable &quot;is&quot; up to that point (i.e. its &quot;domain&quot;)\n# in English\ndef english_for_delphin_variable(failure_index, variable, mrs):\n    # Integers can&#x27;t be passed by reference in Python, so we need to pass\n    # the current index in a list so it can be changed as we iterate\n    current_predication_index = [0]\n\n    # This function will be called for every predication in the MRS\n    # as we walk it in execution order\n    def RecordPredicationsUntilFailureIndex(predication):\n        # Once we have hit the index where the failure happened, stop\n        if current_predication_index[0] == failure_index:\n            return False\n        else:\n            # See if this predication can contribute anything to the\n            # description of the variable we are describing. If so,\n            # collect it in nlg_data\n            refine_NLG_with_predication(variable, predication, nlg_data)\n            current_predication_index[0] = current_predication_index[0] + 1\n            return None\n\n    nlg_data = {}\n\n    # WalkTreeUntil() walks the predications in mrs[&quot;RELS&quot;] and calls\n    # the function RecordPredicationsUntilFailureIndex(), until hits the\n    # failure_index position\n    walk_tree_predications_until(mrs[&quot;RELS&quot;], RecordPredicationsUntilFailureIndex)\n\n    # Take the data we gathered and convert to English\n    return convert_to_english(nlg_data)\n\nFor now, refine_NLG_with_predication() takes a very simple approach to seeing if a predication is restricting the variable: Predications which introduce a variable (as described in a the MRS conceptual section) are, in some sense, the base \"thing\" that the variable is. They should clearly be part of its description. Quantifiers for that variable describe \"how much\" of it there is, so they should be included as well. There is lots more we could add (and we will later) but keeping it simple is fine for now:\n# See if this predication in any way contributes words to\n# the variable specified. Put whatever it contributes in nlg_data\ndef refine_NLG_with_predication(variable, predication, nlg_data):\n    # Parse the name of the predication to find out its\n    # part of speech (POS) which could be a noun (&quot;n&quot;),\n    # quantifier (&quot;q&quot;), etc.\n    parsed_predication = parse_predication_name(predication.name)\n\n    # If the predication has this variable as its first argument,\n    # it either *introduces* it, or is quantifying it\n    if predication.args[0] == variable:\n        if parsed_predication[&quot;Pos&quot;] == &quot;q&quot;:\n            # It is quantifying it\n            nlg_data[&quot;Quantifier&quot;] = parsed_predication[&quot;Lemma&quot;]\n        else:\n            # It is introducing it, thus it is the &quot;main&quot; description\n            # of the variable, usually a noun predication\n            nlg_data[&quot;Topic&quot;] = parsed_predication[&quot;Lemma&quot;]\n\nNote: The code for parse_predication_name() is available in the main Perplexity tree\n\nFinally, we can take the information we gathered and convert it (in a very simple way) to English. Note that generating proper English is much more complicated than this, and we'll tackle doing it \"more right\" later. For now, our naive approach will illustrate the ideas:\n# Takes the information gathered in the nlg_data dictionary\n# and converts it, in a very simplistic way, to English\ndef convert_to_english(nlg_data):\n    phrase = &quot;&quot;\n\n    if &quot;Quantifier&quot; in nlg_data:\n        phrase += nlg_data[&quot;Quantifier&quot;] + &quot; &quot;\n    else:\n        phrase += &quot;a &quot;\n\n    if &quot;Topic&quot; in nlg_data:\n        phrase += nlg_data[&quot;Topic&quot;]\n    else:\n        phrase += &quot;thing&quot;\n\n    return phrase\n\nThose functions will provide the start of a system that converts a variable into English, given a spot in the MRS. \nUsing the MRS from \"A file is large\", we can test it out by calling it with different indices to see what it thinks x3 is at that point:\n# Generating English for &quot;a file is large&quot;\ndef Example11():\n    # Note neither file is &quot;large&quot; now\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=100),\n                   File(name=&quot;file2.txt&quot;, size=100)])\n\n    # Start with an empty dictionary\n    mrs = {}\n\n    # Set its &quot;index&quot; key to the value &quot;e2&quot;\n    mrs[&quot;Index&quot;] = &quot;e2&quot;\n\n    # Set its &quot;Variables&quot; key to *another* dictionary with\n    # keys that represent the variables. Each of those has a &quot;value&quot; of\n    # yet another dictionary that holds the properties of the variables\n    # For now we&#x27;ll just fill in the SF property\n    mrs[&quot;Variables&quot;] = {&quot;x3&quot;: {},\n                        &quot;i1&quot;: {},\n                        &quot;e2&quot;: {&quot;SF&quot;: &quot;prop&quot;}}\n\n    mrs[&quot;RELS&quot;] = TreePredication(0, &quot;_a_q&quot;, [&quot;x3&quot;,\n                                              TreePredication(1, &quot;_file_n_of&quot;, [&quot;x3&quot;, &quot;i1&quot;]),\n                                              TreePredication(2, &quot;_large_a_1&quot;, [&quot;e2&quot;, &quot;x3&quot;])])\n\n    # Set index to failure in _a_q\n    print(english_for_delphin_variable(0, &quot;x3&quot;, mrs))\n\n    # Set index to failure in _file_n_of\n    print(english_for_delphin_variable(1, &quot;x3&quot;, mrs))\n\n    # Set index to failure in _large_a_1\n    print(english_for_delphin_variable(2, &quot;x3&quot;, mrs))\n    \n    \n# Outputs:\na thing\na thing\na file\n\nYou can see that, until predication #3 has succeeded (_file_n_of), x8 is described as \"a thing\" since nothing has restricted it yet. Once it gets past predication #3, it now holds \"a file\". We could easily beef up our code so that after _large_a_1 it is described as \"a large file\" and we will, eventually.\nTo enable our code to use english_for_delphin_variable(), we need to know what predication reported the error.  We'll add a helper to ExecutionContext to retrieve it:\nclass ExecutionContext(object):\n    def __init__(self):\n        self._error = None\n        self._error_predication_index = -1\n        self._predication_index = -1\n\n    ...\n    \n    def deepest_error_predication_index(self):\n        return self._error_predication_index\n    \n    ...\n\n... and pass it to generate_message_with_index in respond_to_mrs. generate_message_with_index is a renamed generate_message that now has an extra argument for the failed predication index:\ndef respond_to_mrs(state, mrs):\n    ...\n    \n    error = generate_message_with_index(state,\n                                        context().deepest_error_predication_index(),\n                                        context().deepest_error()) if len(solutions) == 0 else None\n\nFixing _large_a_1 to Use Domains\nRecall from the beginning that, running an example, \"a file is large\" in a world with no large files resulted in \"a thing is not large\". Once we use the work above, we will get a better result. We'll report a new error code (notLargeDomain) from large_a_1 that will have the MRS variable as data:\n@Predication(vocabulary, name=&quot;_large_a_1&quot;)\ndef large_a_1(state, e, x):\n        ... \n        \n        if isinstance(item, File):\n            if item.size &gt; 1000:\n                # state.SetX() returns a *new* state that\n                # is a copy of the old one with just that one\n                # variable set to a new value\n                # Variable bindings are always tuples so we set\n                # this one using the tuple syntax: (item, )\n                new_state = state.set_x(x, (item, ))\n                yield new_state\n                \n        context().report_error([&quot;notLargeDomain&quot;, x])\n\nThen we can convert this to a string in generate_message using our new english_for_delphin_variable, which gives us the domain of the variable:\ndef generate_message_with_index(state, predication_index, error):\n    ...\n\n    elif error_constant == &quot;notLargeDomain&quot;:\n        mrs = state.get_binding(&quot;mrs&quot;).value[0]\n        domain = english_for_delphin_variable(predication_index, arg1, mrs)\n        return f&quot;{domain} is not large&quot;\n\nRunning the example now gives:\ndef Example10():\n    # Note neither file is &quot;large&quot; now\n    state = State([Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=100),\n                   File(name=&quot;file2.txt&quot;, size=100)])\n\n    # Start with an empty dictionary\n    mrs = {}\n\n    # Set its &quot;index&quot; key to the value &quot;e2&quot;\n    mrs[&quot;Index&quot;] = &quot;e2&quot;\n\n    # Set its &quot;Variables&quot; key to *another* dictionary with\n    # keys that represent the variables. Each of those has a &quot;value&quot; of\n    # yet another dictionary that holds the properties of the variables\n    # For now we&#x27;ll just fill in the SF property\n    mrs[&quot;Variables&quot;] = {&quot;x3&quot;: {},\n                        &quot;i1&quot;: {},\n                        &quot;e2&quot;: {&quot;SF&quot;: &quot;prop&quot;}}\n\n    mrs[&quot;RELS&quot;] = TreePredication(0, &quot;_a_q&quot;, [&quot;x3&quot;,\n                                       TreePredication(1, &quot;_file_n_of&quot;, [&quot;x3&quot;, &quot;i1&quot;]),\n                                       TreePredication(2, &quot;_large_a_1&quot;, [&quot;e2&quot;, &quot;x3&quot;])])\n\n    state = state.set_x(&quot;mrs&quot;, (mrs,))\n    respond_to_mrs(state, mrs)\n    \n# Outputs:\nNo, that isn&#x27;t correct: a file is not large\n\nMuch better!\nComprehensive source for the completed tutorial is available here\n\n", "title":"English Variable Domains", "teaser":"Converting Variable Domains to English\nSo far, the error reporting code for large_a_1 looks like this:\n@Predication(vocabulary, name=&quot;_large_a_1& ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0070GenerateMRSAndTrees", "excerpt":"Converting Phrases to MRS and Scope-Resolved Mrss\nTo complete our backtracking solver, we need to write the code that will convert a human phrase into TreePredications and call the solver with them. Up to this point, we have been hand-coding this. It is now time to have the system generate all the MRS documents for the phrase and all the scope-resolved mrss for each MRS document.  Then we will have an end-to-end working system that starts from text like \"a file is large\" and responds to it.\nTo do this, we'll write code that uses the ACE parser (via the ACEParser class from pydelphin) to convert a phrase into an MRS document. The only trick is that we need to supply a grammar file to tell ACE which language we are speaking. It is platform dependent, so we'll create a helper function that determines which one to return for the current platform. The function assumes the grammar files are all in the directory that the function is contained in. The names of the grammar files in the /perplexity folder of the Perplexity repository are used, and the function is actually imported from a file in that same directory. Here is the code for that function:\ndef erg_file(self):\n    if sys.platform == &quot;linux&quot;:\n        ergFile = &quot;erg-2024-daily-ubuntu-perplexity.dat&quot;\n\n    elif sys.platform == &quot;darwin&quot;:\n        # Mac returns darwin for both M1 and Intel silicon, need to dig deeper\n        unameResult = platform.uname()\n\n        if &quot;ARM&quot; in unameResult.version:\n            # M1 silicon\n            ergFile = &quot;erg-2023-osx-m1-perplexity.dat&quot;\n\n        else:\n            # Intel silicon\n            ergFile = &quot;erg-2024-daily-osx-perplexity.dat&quot;\n\n    else:\n        ergFile = &quot;erg-2024-daily-ubuntu-perplexity.dat&quot;\n\n    return os.path.join(os.path.dirname(os.path.realpath(__file__)), ergFile)\n\nUsing that function, we can now call ACE to get the MRS documents for a phrase:\ndef mrss_from_phrase(phrase):\n    # Don&#x27;t print errors to the screen\n    f = open(os.devnull, &#x27;w&#x27;)\n\n    # Create an instance of the ACE parser and ask to give &lt;= 25 MRS documents\n    with ace.ACEParser(erg_file(), cmdargs=[&#x27;-n&#x27;, &#x27;25&#x27;], stderr=f) as parser:\n        ace_response = parser.interact(phrase)\n\n    for parse_result in ace_response.results():\n        yield parse_result.mrs()\n\n... and run this sample:\ndef Example5():\n    for mrs in mrss_from_phrase(&quot;2 files are large&quot;):\n        print(mrs)\n\n# Running Example5() results in:\n&lt;MRS object (udef_q card _file_n_of _large_a_1) at 140517206087936&gt;\n&lt;MRS object (udef_q compound number_q card _file_n_of _large_a_1) at 140517208584080&gt;\n&lt;MRS object (loc_nonsp number_q card udef_q _file_n_of _large_a_1) at 140517206087936&gt;\n&lt;MRS object (appos generic_entity udef_q card proper_q named _large_a_1) at 140517208584080&gt;\n&lt;MRS object (number_q card udef_q _file_n_of _be_v_id subord _large_a_1) at 140517206087936&gt;\n&lt;MRS object (loc_nonsp number_q card udef_q _file_n_of subord _large_a_1) at 140517208584080&gt;\n&lt;MRS object (generic_entity udef_q card udef_q _file_n_of _be_v_id subord _large_a_1) at 140517206087936&gt;\n&lt;MRS object (unknown generic_entity udef_q card udef_q _file_n_of _be_v_id subord _large_a_1) at 140517208584080&gt;\n&lt;MRS object (unknown udef_q generic_entity card udef_q _file_n_of _be_v_id subord _large_a_1) at 140517206087824&gt;\n\nThus, there were 9 parses for the phrase \"2 files are large\". The delphin Python library returns its own representation of MRS, and that's what you see printed. \nNext, we need to take the MRS documents returned from this function and turn them into scope-resolved mrss. For this, we'll create a function called trees_from_mrs(). It uses the function written in the section on scope-resolved mrss called valid_hole_assignments() (available here) that does the assignments of predication labels to \"holes\" as discussed in that section.  It will then call the tree_from_assignments() function (included below) that actually builds a tree from those assignments. It represents the tree using the TreePredication object we designed in the Initial Solver topic:\ndef trees_from_mrs(mrs):\n    # Create a dict of predications using their labels as each key\n    # for easy access when building trees\n    # Note that a single label could represent multiple predications\n    # in conjunction so we need a list for each label\n    mrs_predication_dict = {}\n    for predication in mrs.predications:\n        if predication.label not in mrs_predication_dict.keys():\n            mrs_predication_dict[predication.label] = []\n        mrs_predication_dict[predication.label].append(predication)\n\n    # Iteratively return scope-resolved mrss from the MRS\n    for new_mrs, holes_assignments in valid_hole_assignments(mrs, max_holes=12, required_root_label=None):\n        # valid_hole_assignments can return None if the grammar returns something\n        # that doesn&#x27;t have the same number of holes and floaters (which is a grammar bug)\n        if holes_assignments is not None:\n            # Now we have the assignments of labels to holes, but we need\n            # to actually build the *tree* using that information\n            well_formed_tree = tree_from_assignments(mrs.top,\n                                                     holes_assignments,\n                                                     mrs_predication_dict,\n                                                     mrs)\n            yield well_formed_tree\n                \n\ndef tree_from_assignments(hole_label, assignments, predication_dict, mrs, index=None):\n    if index is None:\n        # Use a list so the value will get modified during recursion\n        index = [0]\n\n    # Get the list of predications that should fill in the hole\n    # represented by labelName\n    if hole_label in assignments.keys():\n        predication_list = predication_dict[assignments[hole_label]]\n    else:\n        predication_list = predication_dict[hole_label]\n\n    # predication_list is a list because multiple items might\n    # have the same key and should be put in conjunction (i.e. be and&#x27;d together)\n    conjunction_list = []\n    for predication in predication_list:\n        predication_name = predication.predicate\n\n        # Recurse through this predication&#x27;s arguments\n        # and look for any scopal arguments to recursively convert\n        args = []\n        for arg_name in predication.args.keys():\n            original_arg = predication.args[arg_name]\n\n            # CARG arguments contain strings that are never\n            # variables, they are constants\n            if arg_name in [&quot;CARG&quot;]:\n                final_arg = original_arg\n            else:\n                argType = original_arg[0]\n                if argType == &quot;h&quot;:\n                    final_arg = tree_from_assignments(original_arg, assignments, predication_dict, mrs, index)\n                else:\n                    final_arg = original_arg\n\n            args.append(final_arg)\n\n        conjunction_list.append(TreePredication(index=index[0], name=predication_name, args=args))\n        index[0] += 1\n\n    return conjunction_list\n\nWith all that, we can now write code that takes a phrase and generates all the trees from it:\ndef Example6():\n    for mrs in mrss_from_phrase(&quot;2 files are large&quot;):\n        print(mrs)\n        for tree in trees_from_mrs(mrs):\n            print(tree)\n        print()\n            \nRunning Example6 results in:\n&lt;MRS object (udef_q card _file_n_of _large_a_1) at 140212230080768&gt;\n[udef_q(x3,[card(2,e9,x3), _file_n_of(x3,i10)],[_large_a_1(e2,x3)])]\n\n&lt;MRS object (udef_q compound number_q card _file_n_of _large_a_1) at 140212232351632&gt;\n[number_q(x9,[card(2,x9,i15)],[udef_q(x3,[compound(e8,x3,x9), _file_n_of(x3,i16)],[_large_a_1(e2,x3)])])]\n[udef_q(x3,[number_q(x9,[card(2,x9,i15)],[compound(e8,x3,x9), _file_n_of(x3,i16)])],[_large_a_1(e2,x3)])]\n\n&lt;MRS object (loc_nonsp number_q card udef_q _file_n_of _large_a_1) at 140212230080768&gt;\n[udef_q(x3,[_file_n_of(x3,i16)],[number_q(x5,[card(2,x5,i11)],[loc_nonsp(e4,e2,x5), _large_a_1(e2,x3)])])]\n[number_q(x5,[card(2,x5,i11)],[udef_q(x3,[_file_n_of(x3,i16)],[loc_nonsp(e4,e2,x5), _large_a_1(e2,x3)])])]\n\n&lt;MRS object (appos generic_entity udef_q card proper_q named _large_a_1) at 140212232351632&gt;\n[proper_q(x5,[named(Files,x5)],[udef_q(x3,[generic_entity(x3), card(2,e11,x3)],[appos(e4,x3,x5), _large_a_1(e2,x3)])])]\n[udef_q(x3,[generic_entity(x3), card(2,e11,x3)],[proper_q(x5,[named(Files,x5)],[appos(e4,x3,x5), _large_a_1(e2,x3)])])]\n\n&lt;MRS object (number_q card udef_q _file_n_of _be_v_id subord _large_a_1) at 140212230080768&gt;\n[subord(e17,[udef_q(x3,[_file_n_of(x3,i15)],[number_q(x5,[card(2,x5,i10)],[_be_v_id(e2,x3,x5)])])],[_large_a_1(e21,i22)])]\n[subord(e17,[number_q(x5,[card(2,x5,i10)],[udef_q(x3,[_file_n_of(x3,i15)],[_be_v_id(e2,x3,x5)])])],[_large_a_1(e21,i22)])]\n[udef_q(x3,[_file_n_of(x3,i15)],[subord(e17,[number_q(x5,[card(2,x5,i10)],[_be_v_id(e2,x3,x5)])],[_large_a_1(e21,i22)])])]\n[udef_q(x3,[_file_n_of(x3,i15)],[number_q(x5,[card(2,x5,i10)],[subord(e17,[_be_v_id(e2,x3,x5)],[_large_a_1(e21,i22)])])])]\n[number_q(x5,[card(2,x5,i10)],[subord(e17,[udef_q(x3,[_file_n_of(x3,i15)],[_be_v_id(e2,x3,x5)])],[_large_a_1(e21,i22)])])]\n[number_q(x5,[card(2,x5,i10)],[udef_q(x3,[_file_n_of(x3,i15)],[subord(e17,[_be_v_id(e2,x3,x5)],[_large_a_1(e21,i22)])])])]\n\n&lt;MRS object (loc_nonsp number_q card udef_q _file_n_of subord _large_a_1) at 140212232351632&gt;\n[subord(e17,[udef_q(x3,[_file_n_of(x3,i16)],[number_q(x5,[card(2,x5,i11)],[loc_nonsp(e2,x3,x5)])])],[_large_a_1(e21,i22)])]\n[subord(e17,[number_q(x5,[card(2,x5,i11)],[udef_q(x3,[_file_n_of(x3,i16)],[loc_nonsp(e2,x3,x5)])])],[_large_a_1(e21,i22)])]\n[udef_q(x3,[_file_n_of(x3,i16)],[subord(e17,[number_q(x5,[card(2,x5,i11)],[loc_nonsp(e2,x3,x5)])],[_large_a_1(e21,i22)])])]\n[udef_q(x3,[_file_n_of(x3,i16)],[number_q(x5,[card(2,x5,i11)],[subord(e17,[loc_nonsp(e2,x3,x5)],[_large_a_1(e21,i22)])])])]\n[number_q(x5,[card(2,x5,i11)],[subord(e17,[udef_q(x3,[_file_n_of(x3,i16)],[loc_nonsp(e2,x3,x5)])],[_large_a_1(e21,i22)])])]\n[number_q(x5,[card(2,x5,i11)],[udef_q(x3,[_file_n_of(x3,i16)],[subord(e17,[loc_nonsp(e2,x3,x5)],[_large_a_1(e21,i22)])])])]\n\n&lt;MRS object (generic_entity udef_q card udef_q _file_n_of _be_v_id subord _large_a_1) at 140212230080768&gt;\n[subord(e17,[udef_q(x3,[_file_n_of(x3,i15)],[udef_q(x5,[generic_entity(x5), card(2,e10,x5)],[_be_v_id(e2,x3,x5)])])],[_large_a_1(e21,i22)])]\n[subord(e17,[udef_q(x5,[generic_entity(x5), card(2,e10,x5)],[udef_q(x3,[_file_n_of(x3,i15)],[_be_v_id(e2,x3,x5)])])],[_large_a_1(e21,i22)])]\n[udef_q(x3,[_file_n_of(x3,i15)],[subord(e17,[udef_q(x5,[generic_entity(x5), card(2,e10,x5)],[_be_v_id(e2,x3,x5)])],[_large_a_1(e21,i22)])])]\n[udef_q(x3,[_file_n_of(x3,i15)],[udef_q(x5,[generic_entity(x5), card(2,e10,x5)],[subord(e17,[_be_v_id(e2,x3,x5)],[_large_a_1(e21,i22)])])])]\n[udef_q(x5,[generic_entity(x5), card(2,e10,x5)],[subord(e17,[udef_q(x3,[_file_n_of(x3,i15)],[_be_v_id(e2,x3,x5)])],[_large_a_1(e21,i22)])])]\n[udef_q(x5,[generic_entity(x5), card(2,e10,x5)],[udef_q(x3,[_file_n_of(x3,i15)],[subord(e17,[_be_v_id(e2,x3,x5)],[_large_a_1(e21,i22)])])])]\n\n&lt;MRS object (unknown generic_entity udef_q card udef_q _file_n_of _be_v_id subord _large_a_1) at 140212232351632&gt;\n[udef_q(x12,[_file_n_of(x12,i16)],[udef_q(x4,[generic_entity(x4), card(2,e10,x4), subord(e19,[_be_v_id(e18,x12,x4)],[_large_a_1(e23,i24)])],[unknown(e2,x4)])])]\n[udef_q(x4,[udef_q(x12,[_file_n_of(x12,i16)],[generic_entity(x4), card(2,e10,x4), subord(e19,[_be_v_id(e18,x12,x4)],[_large_a_1(e23,i24)])])],[unknown(e2,x4)])]\n[udef_q(x4,[generic_entity(x4), card(2,e10,x4), subord(e19,[udef_q(x12,[_file_n_of(x12,i16)],[_be_v_id(e18,x12,x4)])],[_large_a_1(e23,i24)])],[unknown(e2,x4)])]\n\n&lt;MRS object (unknown udef_q generic_entity card udef_q _file_n_of _be_v_id subord _large_a_1) at 140212230080656&gt;\n[udef_q(x12,[_file_n_of(x12,i16)],[udef_q(x4,[generic_entity(x4), card(2,i10,x4), subord(e19,[_be_v_id(e18,x12,x4)],[_large_a_1(e23,i24)])],[unknown(e2,x4)])])]\n[udef_q(x4,[udef_q(x12,[_file_n_of(x12,i16)],[generic_entity(x4), card(2,i10,x4), subord(e19,[_be_v_id(e18,x12,x4)],[_large_a_1(e23,i24)])])],[unknown(e2,x4)])]\n[udef_q(x4,[generic_entity(x4), card(2,i10,x4), subord(e19,[udef_q(x12,[_file_n_of(x12,i16)],[_be_v_id(e18,x12,x4)])],[_large_a_1(e23,i24)])],[unknown(e2,x4)])]\n\nYou can see that each MRS parse can generate a variable number of fully-resolved trees. The next topic will describe a heuristic for determining which of those trees is the one the user meant.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Generating MRS and Trees", "teaser":"Converting Phrases to MRS and Scope-Resolved Mrss\nTo complete our backtracking solver, we need to write the code that will convert a human phrase into ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0071WhichParseAndTree", "excerpt":"Determining the Right Scope-Resolved MRS\nIn the previous section, we wrote the code to generate all the MRS parses for a phrase, and all the  that result from the MRS. Next we have to decide which one the user intended and write the code to run it. As discussed in the conceptual topic on Choosing a Scope-Resolved MRS, returning the response from the first MRS parse and scope-resolved MRS that succeeded (or failed) is good heuristic to use in general. \nTo implement the code for choosing the right scope-resolved MRS, we're going to create a new class that will be the main entry point into the whole system. It is called UserInterface and its main method is interact_once(). Each call to that method does a single \"command/response\" interaction with the system mostly using code we've already written. Here's a summary of its logic:\nUse the code we wrote in the previous topic to convert the phrase to MRS and then generate the scope-resolved MRSs for the MRS, go through them in order. \n\nSolve the scope-resolved MRSs using a modification to the call() function from Conjunctions topic which is called solve. Go through these in order.\n\nIf an error occurs when solving a scope-resolved MRS, get a string for it by calling generate_message_with_index (which gets passed as an argument to interact_once). We built this in the English Domain Names section\n\nWhen we are done, actually respond using the (slightly refactored) respond_to_solutions() function we built in the Propositions Section\n\nThe new code is at the end of the function, where we apply all the operations to a single state object and then store it away as the new state.  Otherwise, changes would just get discarded and the next interaction wouldn't see them.\nOur new code iterates through every MRS, then every scope-resolved MRS it has.  If the function succeeds on a particular scope-resolved MRS, it stops processing. Otherwise, it continues until it finds a succcess or runs out of trees. If nothing succeeds, it will report the first tree failure.\nHere is the full code for it:\nclass UserInterface(object):\n    def __init__(self, state, vocabulary):\n        self.max_holes = 13\n        self.state = state\n        self.execution_context = ExecutionContext()\n        self.vocabulary = vocabulary\n\n    # response_function gets passed three arguments:\n    #   response_function(mrs, solutions, error)\n    # It must use them to return a string to say to the user\n    def interact_once(self, response_function):\n        # input() pauses the program and waits for the user to\n        # type input and hit enter, and then returns it\n        user_input = str(input(&quot;? &quot;))\n        best_failure = None\n\n        # Loop through each MRS and each tree that can be\n        # generated from it...\n        for mrs_raw in self.mrss_from_phrase(user_input):\n            for tree in self.trees_from_mrs(mrs_raw):\n                print(tree)\n                # Collect all the solutions for this tree against the\n                # current world state\n                mrs = {&quot;Index&quot;: mrs_raw.index,\n                       &quot;Variables&quot;: mrs_raw.variables,\n                       &quot;RELS&quot;: tree}\n\n                call_state = self.state.set_x(&quot;mrs&quot;, (mrs, ))\n                solutions = []\n                try:\n                    for item in context().solve(vocabulary, call_state, mrs[&quot;RELS&quot;]):\n                        solutions.append(item)\n                except NotImplementedError as e:\n                    print(str(e))\n                    continue\n\n                # Determine the response to it\n                error_text = response_function(call_state,\n                                               context().deepest_error_predication_index(),\n                                               context().deepest_error()) if len(solutions) == 0 else None\n\n                message = respond_to_solutions(call_state, mrs, solutions, error_text)\n                if len(solutions) &gt; 0:\n                    # This worked, give a response\n                    print(message)\n\n                    # apply the results to the current world state if it was a command\n                    if sentence_force(mrs) == &quot;comm&quot;:\n                        self.state = self.apply_solutions_to_state(self.state, solutions)\n                        print(f&quot;New state: {str(self.state.objects)}&quot;)\n\n                    return\n                else:\n                    # This failed, remember it if it is the &quot;best&quot; failure\n                    # which we currently define as the first one\n                    if best_failure is None:\n                        best_failure = message\n\n        # If we got here, nothing worked: print out the best failure\n        print(best_failure)\n        \n        ...\n\nHere is the modified ExecutionContext that has the new solve() method that is only there to reset the predication index since it can now be called multiple times as we process new phrases:\nclass ExecutionContext(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self._error = None\n        self._error_predication_index = -1\n        self._predication_index = -1\n\n    def solve(self, vocabulary, state, term):\n        self.reset()\n        yield from call(vocabulary, state, term)\n\n    def call(self, vocabulary, state, term):\n        ...\n        \n    ...\n\nBelow is the modified respond_to_solutions() function. It no longer generates solutions or error text, instead it requires the caller to pass them in. That allows us to centralize the code that does the solving into interact_once().  It also returns the response instead of printing it now.  The rest of the code is the same:\ndef respond_to_solutions(state, mrs, solutions, error_text):\n    force = sentence_force(mrs)\n    if force == &quot;prop&quot;:\n        # This was a proposition, so the user only expects\n        # a confirmation or denial of what they said.\n        # The phrase was &quot;true&quot; if there was at least one answer\n        if len(solutions) &gt; 0:\n            return &quot;Yes, that is true.&quot;\n        else:\n            return f&quot;No, that isn&#x27;t correct: {error_text}&quot;\n\n    elif force == &quot;ques&quot;:\n        # See if this is a &quot;WH&quot; type question\n        wh_predication = find_predication(mrs[&quot;RELS&quot;], &quot;_which_q&quot;)\n        if wh_predication is None:\n            # This was a simple question, so the user only expects\n            # a yes or no.\n            # The phrase was &quot;true&quot; if there was at least one answer\n            if len(solutions) &gt; 0:\n                return &quot;Yes.&quot;\n            else:\n                return f&quot;No, {error_text}&quot;\n        else:\n            # This was a &quot;WH&quot; question\n            # return the values of the variable asked about\n            # from the solution\n            # The phrase was &quot;true&quot; if there was at least one answer\n            if len(solutions) &gt; 0:\n                wh_variable = wh_predication.args[0]\n                for solutions in solutions:\n                    return f&quot;{str(solutions.get_binding(wh_variable).value)}&quot;\n            else:\n                return f&quot;{error_text}&quot;\n\n    elif force == &quot;comm&quot;:\n        # This was a command so, if it works, just say so\n        # We&#x27;ll get better errors and messages in upcoming sections\n        if len(solutions) &gt; 0:\n            return f&quot;Done!&quot;\n        else:\n            return f&quot;Couldn&#x27;t do that: {error_text}&quot;\n\nWe also moved the functions that parse and build trees (mrss_from_phrase, tree_from_assignments and trees_from_mrs) to be part of the UserInterface class just to clean up the code.\nWith this, we now have a (simple) fully-functioning interactive natural language system! Here's a simple example that runs it in a loop, and an interactive session using some phrases we've used throughout the tutorial to test it:\ndef Example12():\n    state = State([Actor(name=&quot;Computer&quot;, person=2),\n                   Folder(name=&quot;Desktop&quot;),\n                   Folder(name=&quot;Documents&quot;),\n                   File(name=&quot;file1.txt&quot;, size=2000000),\n                   File(name=&quot;file2.txt&quot;, size=100)])\n\n    user_interface = UserInterface(state, vocabulary)\n\n    while True:\n        user_interface.interact_once(generate_message_with_index)\n        print()\n        \n\nRunning that sample leaves you at the command prompt waiting for you to interact.  Here's a session that runs all the phrases we've done in previous sections:\n? a file is large\n[_a_q(x3,[_file_n_of(x3,i8)],[_large_a_1(e2,x3)])]\nYes, that is true.\n\n? which file is large?\n[_which_q(x3,[_file_n_of(x3,i8)],[_large_a_1(e2,x3)])]\n(File(file1.txt, 2000000),)\n\n? delete a large file\n[_a_q(x4,[_large_a_1(e9,x4), _file_n_of(x4,i10)],[_delete_v_1(e2,i3,x4)])]\nImplementation for Predication _delete_v_1(e2,i3,x4) not found\n[pronoun_q(x3,[pron(x3)],[_a_q(x8,[_large_a_1(e13,x8), _file_n_of(x8,i14)],[_delete_v_1(e2,x3,x8)])])]\nDone!\nNew state: [Actor(name=Computer, person=2), Folder(Desktop), Folder(Documents), File(file2.txt, 100)]\n\n? which file is large?\n[_which_q(x3,[_file_n_of(x3,i8)],[_large_a_1(e2,x3)])]\n[udef_q(x3,[_which_q(x10,[generic_entity(x10)],[nominalization(x3,[_file_v_1(e14,x10,i15)])])],[_large_a_1(e2,x3)])]\nImplementation for Predication udef_q(x3,[_which_q(x10,[generic_entity(x10)],[nominalization(x3,[_file_v_1(e14,x10,i15)])])],[_large_a_1(e2,x3)]) not found\n[_which_q(x10,[generic_entity(x10)],[udef_q(x3,[nominalization(x3,[_file_v_1(e14,x10,i15)])],[_large_a_1(e2,x3)])])]\nImplementation for Predication generic_entity(x10) not found\nwhich file is not large\n\n? which folder is large?\n[_which_q(x3,[_folder_n_of(x3,i8)],[_large_a_1(e2,x3)])]\nwhich folder is not large\n\n? a folder is large\n[_a_q(x3,[_folder_n_of(x3,i8)],[_large_a_1(e2,x3)])]\nNo, that isn&#x27;t correct: a folder is not large\n\ninteract_once() prints out the trees that get found so it is easier to see which is being used and which have missing predications. It also helps point out when a tree failed and the solver is trying more trees to find a success. You can see that in action by looking at the difference between the first \"which file is large?\" which only generates one tree since it succeeds, and the second one which fails since there are no large files.  The second one keeps going trying to find a tree that works.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Choosing a Parse and Tree", "teaser":"Determining the Right Scope-Resolved MRS\nIn the previous section, we wrote the code to generate all the MRS parses for a phrase, and all the  that res ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint0230Summary", "excerpt":"Summary and What Wasn't Covered\nIn the course of this internals section, we have implemented everything necessary to build a simple natural language system that can be used to allow human language phrases to be the interface for many types of applications.  The basic approach is exactly how Perplexity is implemented, but because Perplexity is a production system, there are many more corner cases, exceptions and performance improvements in its code. The idea of this whole section is to allow you to build your own Perplexity-type system, perhaps with another language, perhaps with a different approach after learning how Perplexity itself is architected.\nHowever, one key part of how to implement a Perplexity-like system has not been described: building the mechanism to properly implement solution groups as described in Collective and Distributive Readings. These are required for many types of sentences including any that have multiple plurals, such as \"two girls ate two ice cream cones\". A conceptual description of how to implement this is covered in the appendices of the conceptual material: Implementing the Solution Group Algorithm and Optimizing the Solution Group Algorithm.\nComprehensive source for the completed tutorial is available here\n\n", "title":"Summary", "teaser":"Summary and What Wasn't Covered\nIn the course of this internals section, we have implemented everything necessary to build a simple natural language s ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/pxint/pxint03000PythonDecorators", "excerpt":"Python Decorators and the Vocabulary Class\nThis section describes a more arcane part of Python called \"decorators\" that we use to register predication methods in the Vocabulary Class. It is not important to understand how the code works, but it is here for those that are interested.\nPython decorators allow us to run code at load time that inspects whatever they decorate and take action. In this case, we will take the name and arguments of the function passed to @Predication(), and record it in the vocabulary instance we are given. That way, we will have an object that knows all the predications after the file is loaded.\nThe vocabulary class is simple: it has a dictionary that maps predication names to functions:\nclass Vocabulary(object):\n    def __init__(self):\n        self.all = dict()\n\n    def AddPredication(self, module, function, delphin_name):\n        self.all[delphin_name] = [module, function]\n\n    def Predication(self, delphin_name):\n        return self.all.get(delphin_name, None)\n\nThe Predication class is the actual \"decorator\" class. It uses the fact that Python functions can define other functions within them.\nTODO: Describe in more detail how this decorator works\n\ndef Predication(vocabulary, name=None):\n    # Gets called when the function is first created\n    # function_to_decorate is the function definition\n    def PredicationDecorator(function_to_decorate):\n        def WrapperFunction(*args, **kwargs):\n            # For now just iterate from the predication,\n            # later we&#x27;ll do more here\n            yield from function_to_decorate(*args, **kwargs)\n\n        predication_name = name if name is not None else function_to_decorate.__name__\n        vocabulary.AddPredication(function_to_decorate.__module__, function_to_decorate.__name__, predication_name)\n\n        return WrapperFunction\n\n    return PredicationDecorator\n\nComprehensive source for the completed tutorial is available here\n\n", "title":"A. Python Decorators", "teaser":"Python Decorators and the Vocabulary Class\nThis section describes a more arcane part of Python called \"decorators\" that we use to register predication ...", "site":"Perplexity", "section":"Perplexity Internals", "categories":"", "tags":""}
]
