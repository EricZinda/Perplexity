[{"body": ""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devhowto/devhowtoOverview", "excerpt":"Overview\nThe DELPH-IN Consortium has developed a large and rich set of technologies for manipulating natural language. The list of DELPH-IN applications is a great place to start for a survey of different approaches to using them.  There you will find pointers to uses such as identification of speculative or negated event mentions in biomedical text (MacKinlay et al 2011), question generation (Yao et al 2012), detecting the scope of negation (Packard et al 2014), relating natural language to robot control language (Packard 2014), and recognizing textual entailment (PETE task; Lien & Kouylekov 2015). ERS representations have also been beneficial in semantic transfer-based MT (Oepen et al 2007, Bond et al 2011), ontology acquisition (Herbelot & Copestake 2006), extraction of glossary sentences (Reiplinger et al 2012), sentiment analysis (Kramer & Gordon 2014), and the ACL Anthology Searchbench (Sch\u00e4fer et al 2011), and many more.\nThis tutorial is designed to show developers how to consume a narrow set of DELPH-IN technologies (especially MRS and ACE) to build an application. It focuses on one particular application (a natural language interface to a computer's file system), but the concepts should apply to any type of constrained system ('constrained' in the sense of the size of the world under discussion). It also takes one particular approach to building the system by logically evaluating the output of the DELPH-IN parsers against a world definition. While this approach may not be the right one for every application, the concepts illustrated and the tools used along the way should be more broadly applicable.\nThe tutorial will use the DELPH-IN English Resource Grammar (ERG) to parse English, but the concepts are the same across the DELPH-IN grammars.  In fact, the library functions we build have no dependency on the grammar at all. They can be used for any of the DELPH-IN grammars.\nPython was chosen as a simple, popular, open-source language available on many platforms. However, the examples and approach shown here could be implemented in any language. There is not much code in the core solver and associated helper functions that would need to be translated. The overwhelming majority of code will be in the implementation of the terms you implement for your own domain.\nIt is designed to be read in order, but the most important background is in the first two sections, The Minimal Recursion Semantics (MRS) Format and Building Well-Formed MRS Trees. These should definitely be read before moving on to the rest of the topics. The rest of the topics broadly break down into conceptual topics which cover the algorithms and concepts needed to implement a system and how-to topics which walk through writing the Python code to implement them.\nComprehensive source for the completed tutorial is available here.\n\n", "title":"Overview", "teaser":"Overview\nThe DELPH-IN Consortium has developed a large and rich set of technologies for manipulating natural language. The list of DELPH-IN applicatio ...", "site":"Perplexity", "section":"Developer Tutorial Overview", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devhowto/devhowtoMRS", "excerpt":"The Minimal Recursion Semantics (MRS) Format\nThis section provides an overview of the Minimal Recursion Semantics format which is the primary artifact used by DELPH-IN to represent the meaning of a phrase. It should be sufficient for understanding all of the rest of the material in the tutorial.  For a deeper dive into MRS, explore Minimal Recursion Semantics: An Introduction.\n\nThe DELPH-IN English Resource Grammar (ERG), via the ACE parser, converts an English phrase into a text format called the \"Minimal Recursion Semantics\" (MRS) format which is designed to allow software to process human language. ACE can also be used with any of the other DELPH-IN grammars to convert other natural languages into the MRS format. While the examples below use English, the concepts apply across the DELPH-IN grammars.\nBecause language is ambiguous, most phrases parse into more than one MRS document, each representing a different interpretation of the phrase. Each MRS document encodes one high-level meaning of the phrase into a list of predicate-logic-like predicates (called predications).\nEach MRS document also has multiple interpretations. Using constraints that are included as part of the MRS, a set of trees (called well-formed trees) can be built from the flat list of predications in a given MRS.  These well-formed trees define all the alternative meanings of that particular MRS.\nSo, a phrase generates n MRS documents, each of those generates m well-formed trees, which results in n x m possible interpretations of a single phrase. One of the challenges of building a system that uses natural language is to determine which of the many possible meanings was intended by the user (one approach to doing this will be discussed in a future section of the tutorial).\nFor example, the phrase: \"Look under the table.\" produces 12 different MRS documents (also called \"parses\" or \"interpretations\"). These include interpretations that mean: \n\"Look (at whatever is) under the table\" \n\n\"Look (around while you are) under the table\" \n\n... among 10 others. \nThe MRS document for the first interpretation is:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _under_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _look_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nUsing the constraints described in the HCONS section (which we will describe later), there are two well-formed trees that can be built from that MRS, which describe the two alternatives that it could mean:\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x9)\n_the_q(x9,RSTR,BODY)               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\n                 \u2514\u2500 pronoun_q(x3,RSTR,BODY)    \u250c\u2500\u2500 _under_p_dir(e8,e2,x9)\n                                        \u2514\u2500 and(0,1)\n                                                 \u2514 _look_v_1(e2,x3)\n\n               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\npronoun_q(x3,RSTR,BODY)            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x9)\n                    \u2514\u2500 _the_q(x9,RSTR,BODY)    \u250c\u2500\u2500 _under_p_dir(e8,e2,x9)\n                                        \u2514\u2500 and(0,1)\n                                                 \u2514 _look_v_1(e2,x3)\n\nThe rest of this section will give you a base understanding of the MRS format so that we can explore how to build these well-formed trees in a later section and ultimately write software that derives the speaker's intended meaning from them.  Deriving their intended meaning is the topic of this entire tutorial.\nUnderspecification\nA DELPH-IN parser like ACE will usually generate more than one MRS document representing the various high-level interpretations of a phrase. Each one contains a list of predicate-logic-like predications and not a tree like you'll see in many natural language systems.  That's because it is underspecified.  Even though the parser has already done one level of interpretation on the phrase, there are still (usually) multiple ways to interpret that.  \nThe final interpretations of a phrase are called \"well-formed MRS trees\". The MRS document doesn't pick a primary interpretation by choosing a specific tree, it provides the rules for building all of them. That's what \"underspecified\" means. Every book is in a cave could mean \"all books are in the same cave\" or \"every book is in a (possibly different) cave\". Given just the phrase, it isn't clear which the speaker intended, so the MRS provides all the alternatives. Context (which the MRS doesn't have) usually helps to decide which is meant.\nThis section will go through the entire MRS document in detail, but as a navigational guide to the format itself: The list of predicate-logic-like predications in provided in the RELS section of the MRS document:\n...\n\nRELS: &lt; \n[ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _under_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _look_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\n\n...\n\n... and the HCONS section lists the constraints on putting the predications together to create a well-formed tree which represents a single meaning:\n... \n\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nThe MRS is underspecified, and the RELS together with the HCONS provide the information to make it specific and recover the various possible meanings.\nPredications\nA phrase is converted into a list of predicate-logic like predications in the MRS which you can see in the RELS section of the MRS for \"Look under the table\":\n...\n\nRELS: &lt; \n[ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _under_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _look_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\n\n...\n\nPredications are \"predicate-logic-like\" in that they state a relation or a fact about their arguments that must be true in order for the MRS to be true. The arguments are most often variables and, if you find values for all the variables that make all the predications in the MRS true in a given world, then you have \"solved\" or \"resolved\" the MRS. You have figured out (in a sense) the meaning of the sentence. So, predications do the work in an MRS by providing constraints or restrictions on the variables they are passed. \nFor example: the predication _table_n_1(x9) in the example above is saying \"restrict the set of things in the variable x9 to be only those which are a 'table'\" or, alternatively: \"ensure that x9 contains a 'table'\".  Depending on how you ultimately solve the MRS, you might look at these variables as containing sets or individual items. Our approach will start by iteratively solving the MRS using individual items, so we'll be describing predications as restricting to individual items for the rest of the tutorial.\nIf we evaluated a different predication such as _large_a_1(x9) immediately afterward, it would mean \"also make sure the thing in x9 is 'large'\".  An MRS that contains both predications like that is saying, \"restrict x9 to be a 'large table' from the world we are talking about\".\nWe'll get into the other examples later after we've covered more basics.\nPredication Labels\nEach predication has a label in the MRS, indicated by LBL:. The label serves as an ID or a pointer to the predication. Note that predications can share the same label. In fact, this is how the MRS indicates they are \"in conjunction\" (i.e. should be interpreted together using a logical \"and\", as in the above example).\nLook at the labels for the different predications in an MRS for \"Look under the large table\" and note that _large_a_1 and _table_n_1 share the same label, indicating they are \"in conjunction\":\n[ TOP: h0\nINDEX: e2\nRELS: &lt; [ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _large_a_1 LBL: h13 ARG0: e14 [ e SF: prop TENSE: untensed MOOD: indicative PROG: bool PERF: - ] ARG1: x9 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _under_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _look_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nThese labels are used to turn the flat list of predications into the set of well-formed trees that represent its various meanings. The section below on scopal arguments gives an overview of how this works. The Well-Formed Trees topic describes it in detail.\nPredication Names\nThe name of a predication, for example, _table_n_1, encodes important information about it:\nThe \"lemma\" or root word (this is the first word you see): \"table\"\n\nWhether it was actually seen in the text (starts with _) or added abstractly by the system (no initial _)\n\nIts part of speech. The _n_ in _table_n_1 means \"table\" is a \"noun\". The _q in _the_q means \"the\" is a \"quantifier\" (quantifiers are described below)\n\nIt may have extras at the end like _1 to indicate which \"variant\" or synonym of the word it represents\n\nThere is some documentation for what the predications mean, which can be found by doing a search of the documentation. Otherwise, their meaning can often be determined by looking at the MRS and intuiting what they are trying to do using your knowledge of the language. If all else fails, you can post on the message boards.  \nPredication Arguments and Variables\nPredications have arguments with names like ARG0, ARG1, ARG2, RSTR, BODY, etc.  Think of those exactly like the name of named arguments in some programming languages such as Python.\nThey also have variables assigned to the arguments like x5, h1, e6.  The initial letter in the name indicates the \"type\" of variable it is.  The types create a hierarchy, with the bottommost \"leaves\" being the types that are the most concrete and most common in predications. Each of these types will be discussed below:\n    u\n   / \\\n  i   p\n / \\ / \\\ne   x   h\n\nThe number on a variable just makes it unique. When the same variable name appears in more than one place it is shared, just like if you used a Python variable in more than one place in a function.\nSo, if an MRS has two predications like this:\n[ _large_a_1 LBL: h13 ARG0: e14 [ e SF: prop TENSE: untensed MOOD: indicative PROG: bool PERF: - ] ARG1: x9 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n\n... you can see that:\n_large_a_1 has two arguments: ARG0 and ARG1, and the variables assigned to them are: e14 and x9. The first is of type event (e) and the second is of type instance (x)\n\n_table_n_1 shares x9 in its ARG0 and so both predications are restricting the same variable. This means that, ultimately, x9 should contain only \"large tables\"\n\nThinking of MRS variables as variables in a math equation can help: The MRS is effectively defining a formula with variables. If you pick variable values such that the MRS is true for a given world, then you have understood the meaning of the MRS in that world.\nOf all the arguments, ARG0 is special.  It holds a variable that \"represents\" the predication, sometimes called the \"characteristic\" or \"distinguished\" variable, but most often the \"instrinsic variable\".  If you read the Minimal Recursion Semantics: An Introduction documentation, you'll see the term \"introduced\" is used to describe the intrinsic variable.  A predicate is described as \"introducing\" its \"intrinsic variable\" (which is always ARG0). Sometimes phrases like \"the variable introduced by predicate X...\" are used.  This will become important later, mostly when we talk about events or about how to convert predications back into a phrase. For now, it is enough to understand that ARG0 represents the predication in some special ways.\nOne final point: Every variable in an MRS is introduced by exactly one predication in the MRS (which is why they can serve as makeshift \"representations\" of the predication). We'll come back to this when we talk about i, p and u variable types.\nH (Handle) Variables, aka \"Scopal Arguments\"\nThe semantic meaning of an MRS is ultimately represented by a tree (described in the next topic) and handle variables passed to predications (aka \"scopal arguments\") provide the mechanism to build a tree from the list of predications.\nHandle variables represent the \"holes\" where branches of the tree can be placed. To do this, handle variables are set to the LBL: of another predication. As described above, the MRS LBL: field serves as a way to \"label\" each predication with a unique identifier. Thus, the LBL: of a predication can be assigned to a handle variable in a different predication to indicate that it should be placed there. By assigning LBL:s to holes like that, an entire tree can be built.\nWhen a tree is built and being resolved, a predication with handle arguments is expected to use those branches to do ... whatever it is supposed to do. For example, the _the_q has two handle arguments, h5 and h6 in the MRS for \"The dog is small\":\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _dog_n_1 LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _small_a_1 LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\nIn building a tree, we have assigned LBL: h7 to h5 and LBL: h1 to h6:\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _dog_n_1(x3)\n_the_q(x3,RSTR,BODY)\n                 \u2514\u2500 _small_a_1(e2,x3)\n\nThink of this process like a lambda function being passed to a function in a programming language like C++ or C#.  The the_q predication itself will be responsible for \"doing something\" with the two branches it is passed.  What, exactly, is specific to the predication. We'll go into this more in a future topic in the tutorial. For now, think about scopal arguments as places to put other predications which are acting like programming language \"lambda functions\".\nBecause the MRS is underspecified, it usually doesn't directly list which predication to put in which scopal argument. You figure that out by the process of creating a well-formed tree.  However, if a predication has a LBL: that is the same handle as a scopal argument, then that part of the tree has been specified and is \"locked in place\" (i.e. there is no hole there for something else to be).\nX (Instance) Variables\nInstance (x) variables are just like normal First Order Logic variables, or like variables in popular programming languages. The types of things they can contain are \"individuals\", which is another name for a \"thing in the world\".  They hold the things the speaker is talking about.\nIn the MRS for \"Look under the large table\":\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _large_a_1 LBL: h13 ARG0: e14 [ e SF: prop TENSE: untensed MOOD: indicative PROG: bool PERF: - ] ARG1: x9 ]\n[ _table_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _under_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _look_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\n... there are only two instance variables that represent the \"things in the world being talked about\":\nx9: \"the large table\"\n\nx3: \"you\". This is implied since it is a command. I.e. \"[You] look under the large table\". You can tell it wasn't in the original phrase because the predication doesn't start with _.\n\nThe other variables in the MRS are there to help build up the tree (h variables, described previously) or allow predications to refer to each other (e variables, described next).  x variables are the most concrete type of variable that maps most obviously to what is being said in the phrase.\nNote that instance variables are always scoped by a quantifier when a well-formed tree is built. Quantifiers are described later, but for now think of them as a predication named with _q and with the argument structure: (x, h, h). The first argument of the quantifier, x, is the variable being \"scoped\", and the two branches in its scopal arguments are the only branches allowed to use that particular x variable.  That's what \"scoped by a quantifier\" means. This is important to know when creating well-formed trees but also helps explain some of the uses of other variable types later in this section.\nE (Event) Variables\nEvent variables have a rich history and lot of fascinating conceptual linguistic background to them (Davidson 1967a is a good start), but for our purposes, we can think of them as holding a \"bag of information\" (represented in code as a dictionary, perhaps). Predications introduce them to provide a place for other predications to hang information that will be used by the introducer. \nFor example, event variables are used by adverbs like \"slowly\" as in, \"move slowly\", to provide the move predication with information about how to move. slowly does this by adding data to the event variable that move introduces. You can see in the MRS below for \"move slowly\" that _slow_a_1 is passed the e2 event variable that _move_v_1 introduces:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _slow_a_1 LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ]\n[ _move_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\nThe _slow_a_1 predication is passed the e2 argument so that it can attach data about \"how to do something\" to the event. _move_v_1 needs e2 passed to it so that it can inspect it and determine how to do the \"moving\".  \nEvents can also be used to add information about where to do something. For example, in \"go to the store\", \"to\" is one of many prepositions that can be used with \"go\" to say where to go. So, if a preposition like \"to\" is in the phrase, it modifies the event that \"go\" introduces:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _store_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _to_p_dir LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _go_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nEvent variables conceptually hold a single \"event\" that accumulates information over the course of evaluating the predications. Multiple predications may \"enrich\" it with information before it's actually used by, for example, a verb. Contrast this with an instance (x) variable which only holds a particular individual at a given point it time. Said another way: an instance variable is like a string and can only hold one value, where an event is like a dictionary or a list and can hold many and be added to over time.\nNote that the DELPH-IN grammars are very liberal in putting event variables on predications and, depending on context, sometimes they aren't used. This is just to prevent the consumer of the MRS from having to deal with the same predication both with and without an event variable.\nThe predication that introduces an event variable will often (but not always) be the predication that consumes or \"does something\" with the \"fully enriched\" event. Predications that have it in other arguments will often (but not always) be simply adding information to the event.\nOther Variables Types: I, U, P\nRecall that the variable types in DELPH-IN form a hierarchy. So far we've discussed the bottommost \"leaves\", which are most commonly seen:\n    u\n   / \\\n  i   p\n / \\ / \\\ne   x   h\n\nThe other three types of variables represent a type that is \"in-between\" or \"underspecified\" between the other \"concrete\" types (e, x, h).  In general, these appear when the ERG can't decide the type of something since it falls somewhere between the types (i.e. is \"underspecified\").  From the ERG documentation:\n\"i (for individual) is a generalization over eventualities and instances; p (the half-way mark in the alphabet between h and x) is a generalization over labels and instances; and u (for unspecific or maybe unbound) generalizes over all of the above. Note that Copestake et al. (2001) use individual for what is called instance here.\"\n\nIn practice, they appear in two pretty specific scenarios:\nUnquantified x variables: Some predications in the ERG have an argument that is conceptually an individual (x) type, but does not require quantification. Since the rules require that all x variables are scoped by a quantifier, the most appropriate of the three \"in-between\" types will be used instead as a \"work-around\". This is usually i since these are most often of type x, and i is the most specific of the options that includes x. As with all non-x variables, this will be \"existentially quantified\" (globally defined) -- that is the whole point of using them here.\nDropped arguments: Sometimes the predication that would introduce a variable is missing. For example, take \"I left\" vs. \"I left Oregon\". In the latter, \"Oregon\" becomes a predication that introduces a variable that \"left\" uses, but in the former, this predication doesn't exist, so the variable is not introduced. In this case, the missing (or \"dropped\") variable uses an i, p or u type in place of the original type. Variables typed like this should be treated like the act of passing None in Python or Null in SQL to a function. The easiest way to detect when one of these three variable types means \"dropped or ignored argument\" is by checking if any other predication is also using it (as in the previous case). If not, it is probably dropped/ignored.\n- i means dropped e or x\n- u means dropped e, x, or h\n- p means dropped x or h\nVariable Properties\nVariables in an MRS have properties, which are like single argument predications for the variables. They define many different properties of a variable that aren't included anywhere else. They are defined after the variable in the MRS, surrounded by []. You can see several examples in the MRS for \"he will go\":\n[ pronoun_q LBL: h5 ARG0: x3 [ x PERS: 3 NUM: sg GEND: m IND: + PT: std ] RSTR: h6 BODY: h7 ]\n[ pron LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg GEND: m IND: + PT: std ] ]\n[ _go_v_1 LBL: h1 ARG0: e2 [ e SF: prop TENSE: fut MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n\nThe properties provided depend on the type of variable:\nInstance (x) variables can have these properties:\nNumber (NUM): sg (singular) or pl (plural)\n\nPerson (PERS): 1,2, or 3 for first-person (speaker) I/we, second-person (hearer) you, and third-person otherwise\n\nIndividuated (IND): + or - (meaning true or false). Distinguishes individuated entities introduced by count nouns such as cat or cats from non-individuated referents for mass nouns such as rice\n\nGender (GEN): m for male, f for female, n otherwise\n\nPT: ?\n\nEvent (e) variables can have these properties:\nTense (TENSE): past for past, pres for present, fut for future, or untensed\n\nViewpoint aspect (or 'grammatical aspect') describes the situation from a particular viewpoint, dividing it into endpoints and stages (Smith 1991, 1997)\nPERF (for perfect): + or - (meaning true or false)\n\nPROG (for progressive): + or - (meaning true or false)\n\n\nSentence Force (SF): comm for command, ques for question, prop for proposition. Indicates the type of sentence.\n\nMood (MOOD): Roughly describes the opinions or attitudes of the speaker, with most common values being: subjunctive and indicative\n\nQuantifier Predications\nQuantifiers in DELPH-IN are the primary predications that glue a tree together. They provide two functions: they show where in the tree certain variables can be used (i.e. provide scope to the variable) and they often also constrain \"how much\" of the variable can be used. \"The\", \"a\", \"some\" and \"all\" are really common examples. \nQuantifier predications in DELPH-IN always have a specific argument signature: \nquantifier_q(x,h,h)\n\nIn addition to (often) doing the job of saying \"how much of\" their x variable there should be to make the MRS true (\"lots\", \"some\", \"the\", etc), they provide scope to the x variable. All x variables must be scoped by a quantifier, which means that they can only be used in the branches of the tree that are contained in the quantifier's two h (scopal) arguments. This rule for well-formedness means that there are many quantifiers that don't do \"real\" quantification at all, they are in the MRS solely to scope the x variable. Some also act like \"markers\" of some kind (again without doing any quantification).\nThe MRS for \"go north\" shows an example of this:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ def_implicit_q LBL: h11 ARG0: x9 [ x PERS: 3 NUM: sg ] RSTR: h12 BODY: h13 ]\n[ place_n LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg ] ]\n[ _north_a_1 LBL: h10 ARG0: i14 [ i ] ARG1: x9 ARG2: u15 ]\n[ pronoun_q LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ loc_nonsp LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _go_v_1 LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h12 qeq h10 &gt; ]\n\n                                \u250c\u2500\u2500 place_n(x9)\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n                    \u2502             \u2514 _north_a_1(i14,x9,u15)\ndef_implicit_q(x9,RSTR,BODY)\n                         \u2502                 \u250c\u2500\u2500\u2500\u2500\u2500\u2500 pron(x3)\n                         \u2514\u2500 pronoun_q(x3,RSTR,BODY)    \u250c\u2500\u2500 loc_nonsp(e8,e2,x9)\n                                                \u2514\u2500 and(0,1)\n                                                         \u2514 _go_v_1(e2,x3)\n\nThe variable x9 represents north but nothing in the phrase is \"quantifying\" direction in any way.  Since the rules for MRS require x variables to be quantified (among other reasons), an abstract quantifier called def_implicit_q is used to do the scoping of the variable.\nNote that, unlike non-quantifier predications, the first (ARG0) argument of a quantifier does not \"introduce\" an \"intrinsic variable\" (as described in the variables section), quantifiers just scope and optionally quantify their ARG0.\nConstraints\nThe HCONS section of the MRS is used when building a well-formed tree. It puts CONStraints on where the Handles for predications can be validly placed and still be a legal interpretation of the phrase. The only constraints used in \"modern\" MRS are qeq constraints so that's all you'll see in this section.  \nA qeq constraint always relates an h argument of one predication, called a \"hole\", to the handle (LBL:) of another predication. It states that the handle must be a direct or eventual child of the hole in the tree and, if not direct, the only things between the hole and the handle can be quantifiers.  Said a different way: \nA qeq constraint of \"X qeq Y\" says that the direct path from X to Y must only contain quantifiers (except for the final predication Y).\n\nAs we work through fully resolving the MRS into a tree, we'll see more description and examples of how the HCONS section is used.\nIndex\nOne final part of the MRS needs to be described: INDEX:\nTOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q__xhh LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _cave_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ pronoun_q__xhh LBL: h4 ARG0: x3 [ x PERS: 2 PT: zero ] RSTR: h5 BODY: h6 ]\n[ pron__x LBL: h7 ARG0: x3 [ x PERS: 2 PT: zero ] ]\n[ _to_p_dir__eex LBL: h1 ARG0: e8 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: e2 ARG2: x9 ]\n[ _go_v_1__ex LBL: h1 ARG0: e2 [ e SF: comm TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; \n\nThe INDEX part of the MRS indicates the variable introduced by the predication (or predications if there is a conjunction) that is the \"main point of the phrase\". It is \"the thing being done\", which is usually the main verb.  In the example above INDEX: e2 is referring to the variable introduced by _go_v_1__ex.  This indicates that the verb go is the \"main point of the phrase\". This is called the \"syntactic head\" in linguistics.\nNote that the INDEX does not always point at a verb. In phrases that just state that something \"is\" something else, such is: \"the flower is blue\", \"is\" is not included. \"blue\" acts like the verb and is the INDEX:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _the_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _flower_n_1 LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _blue_a_1 LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 &gt; ]\n\n\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _flower_n_1(x3)\n_the_q(x3,RSTR,BODY)\n                 \u2514\u2500 _blue_a_1(e2,x3)\n\nMore information on INDEX is described in the section on sentence force.\nThe next topic walks through the rules of creating \"well-formed MRS trees\", and is the last big chunk of conceptual background needed before we start building the system.\nComprehensive source for the completed tutorial is available here.\n\n", "title":"Minimal Recursion Semantics (MRS)", "teaser":"The Minimal Recursion Semantics (MRS) Format\nThis section provides an overview of the Minimal Recursion Semantics format which is the primary artifact ...", "site":"Perplexity", "section":"MRS Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devhowto/devhowtoWellFormedTree", "excerpt":"Building Well-Formed MRS Trees\nTo understand this section, first make sure you have a basic understanding of the MRS format.  \n\nLet's use the sentence \"every book is in a cave\" as an example. If the phrase is parsed with the ACE parser, you get an MRS document like this:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _a_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _cave_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _every_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _book_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _in_p_loc LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ARG2: x9 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nOur goal is to eventually \"solve\" the MRS by finding values for its MRS variables such that it is \"true\". When complete, these variables indicate what the speaker meant and allow us to do something about it.  \nTo resolve an MRS against a world state (a particular state of the world at a moment in time) and get solutions to it (meaning the set of MRS variable assignments that make it true) you need to turn it into a well-formed MRS tree. We will examine how shortly, but for now just know that a well-formed MRS tree has (among other things) nodes that are the predications from the MRS like _every_q__xhh and arcs that are links between the scopal arguments of the predications and other nodes, like this:\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _book_n_of(x3,i8)\n_every_q(x3,RSTR,BODY)          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _cave_n_1(x9)\n                   \u2514\u2500 _a_q(x9,RSTR,BODY)\n                                     \u2514\u2500 _in_p_loc(e2,x3,x9)\n\nThis tree represents one interpretation of \"every book is in a cave\", namely, \"every book is in a (possibly different) cave\". \nTo \"solve\" this tree against a particular world state, you walk it in depth-first order: every_q is the starting, leftmost node. It starts by selecting a book on its upper branch, and then solves its lower branch with the selected book. This finds \"a cave that the (selected) book is in\". every_q does this for every book in the world state. If they all succeed (they must all succeed because the speaker said \"every\"), we have a solution to the MRS. Because _every_q chooses a book and then a cave that it is in, it allows a different cave to be selected for each book. This tree will be only true if every book is in a (possibly different) cave.\nBut this is only one interpretation. Another interpretation of the same MRS is: \"all books are in the same exact cave\". The speaker might have meant that interpretation, which is represented by this tree:\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _cave_n_1(x9)\n_a_q(x9,RSTR,BODY)              \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _book_n_of(x3,i8)\n               \u2514\u2500 _every_q(x3,RSTR,BODY)\n                                     \u2514\u2500 _in_p_loc(e2,x3,x9)\n\nWhen a_q is the leftmost node, it starts by selecting a cave on its upper branch, and then resolves its lower branch with that selection, making sure that \"every book is in the (selected) cave\". This will only be true if there is (at least one) cave that every book is in.\nDon't worry if you don't completely understand how the solutions are obtained yet.  The point is that there are different interpretations for the same MRS, represented by different trees. The rest of the tutorial will work through how these get solved.\n\nBoth of these trees are represented by the same MRS document. The MRS structure is said to be underspecified, meaning that a single MRS document allows multiple interpretations. \nHere's the MRS for \"Every book is in a cave\" again, so we can see how:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _a_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _cave_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _every_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _book_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _in_p_loc LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ARG2: x9 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nThe MRS is a flat list of predications so that it avoids building a single tree which would \"lock in\" one interpretation.  How it does this is described in detail next, but in summary: It leaves \"holes\" using scopal (h) arguments for various predications and provides constraints (the HCONS) for plugging the predications together \"legally\".  If you combine the predications by following the constraints (among other things), you'll end up with a \"well-formed MRS tree\" which defines one valid interpretation of the sentence. If you build all the well-formed trees, you have all the possible interpretations.\nThis interpretation is what we need in order to eventually \"solve\" the phrase for the variables it contains. This topic describes how to build that tree.\nHoles and Constraints\n\"Holes\" are h arguments in a predication that refer to a predicate label that is not defined. In the above MRS, h0 (the TOP:), h11, h12, h5, and h6 are all \"holes\" since none of the predicates use those names as their LBL:.\nThe HCONS section of the MRS puts CONStraints on which placement of Handles in holes is valid.\nThe only kind of constraint used in \"modern\" MRS is a qeq constraint.  A qeq constraint always relates a hole to a (non-hole) handle and says that the handle must be a direct or eventual child in the tree. Furthermore, if not directly connected, the only things between the hole and the handle can be quantifiers.  \nSaid a different way: \nA qeq constraint of h0 qeq h1 (as in the above example) says that the direct path in the final tree from h0 to h1 must only contain quantifier predicates, but can contain as many as you want, as long as they don't violate other constraints.\n\nSo, in this MRS:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _a_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _cave_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _every_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _book_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _in_p_loc LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ARG2: x9 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nh1 is the LBL of the _in_p_loc__exx predicate. Given the qeq constraint of h0 qeq h1, it would be perfectly valid to assign h0 = h1 (meaning put the predication labelled by h1 in the h0 hole) since the path from h0 to h1 is direct. \nAgain, given the qeq constraint of h0 qeq h1: You could alternatively assign h0 = h4 (h0 is the \"hole\" at the top of the tree, h4 is the label for _every_q), and h6 = h1 (h6 is a \"hole\" in _every_q, h1 is the label for _in_p_loc). With this configuration, h0 qeq h1 is still valid because the path from h0 to h1 only includes the every_q quantifier and h1 itself.\nOnce you fill all the holes with unique predications, and you follow all of the qeq constraints, you'll end up with a tree that is \"scope-resolved\", but not yet guaranteed to be \"well-formed\". There is one more rule to check.\nX Variable Scoping\nAll of the arguments that aren't handles in the MRS for Every book is in a cave except two (e2 and i8) are x variables:\n[ TOP: h0\nINDEX: e2\nRELS: &lt; \n[ _a_q LBL: h10 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] RSTR: h11 BODY: h12 ]\n[ _cave_n_1 LBL: h13 ARG0: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n[ _every_q LBL: h4 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] RSTR: h5 BODY: h6 ]\n[ _book_n_of LBL: h7 ARG0: x3 [ x PERS: 3 NUM: sg IND: + ] ARG1: i8 ]\n[ _in_p_loc LBL: h1 ARG0: e2 [ e SF: prop TENSE: pres MOOD: indicative PROG: - PERF: - ] ARG1: x3 ARG2: x9 ]\n&gt;\nHCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\nThe rules for MRS say that any variable in the MRS is \"globally defined\" (or \"existentially qualified\" in logic terms) for the whole structure except for x variables.  So, both e2 and i8 don't need any special handling, they are globally defined.\nx variables, on the other hand, can only be defined by quantifiers, and are only defined for the branches of the tree that are attached to the quantifier's scopal (h) arguments: RSTR and BODY.\nSo, while the predications can be in any order in the tree with respect to their e  (or i or u if it had them) arguments, the tree must be checked to make sure all of the x arguments have an eventual parent which is a quantifier which puts them in scope (i.e. has the x variable as its first argument: ARG0). This is an additional constraint that has to be checked to build a \"well-formed\" tree.\nIf the labels from the MRS are all in (exactly) one place, the built tree passes all qeq constraints, and the x variables are all properly scoped, then it is a \"well-formed\" tree that we can now attempt to solve.  That's what we're going for here.\nResolving the tree\nFinding ways to efficiently create these trees is an area of active research because natural language can easily create MRS structures that have a ton of holes.  n holes, in the worst case, can require n! checks to resolve, if done exhaustively.  So, an MRS structure with 12 holes (which is easy to generate) could require up to 480,000,000 checks before finding a valid solution if you just try every combination.  \nTo generate the well-formed trees, you could simply try all possible combinations of holes and labels, do the qeq and x scoping checks on each, and only keep the valid ones. This will only be practical for the simplest possible trees.\nAnother algorithm, the one we'll use in the tutorial, is able to prune the search space and works much faster.  The Python implementation can usually generate all trees for an MRS with 12 holes in around 1.5s (with some outliers being slower) on a 2013-era MacBook Pro.  This will be sufficient for the purposes of this tutorial.  Something like \"put the diamond on the table where the safe is and the book is\" generates MRS structures with up to 14 holes and could take up to 30 seconds to generate all the valid interpretations (1500+ valid interpretations in some cases!) for each MRS.  It turns out it is very rarely necessary to generate all the interpretations, but regardless: because it scales factorially, things slow down fast after 12 holes.\nThere are definitely more efficient approaches, but the algorithm below has the advantage of being relatively simple. Here is one alternative.  There are definitely more.\nA Simple, Fast Enough, Algorithm\nIt isn't important to fully understand this algorithm as long as you understand what it has to do: build a well-formed MRS tree, and what the rules are in doing that. We'll use this code as a library routine all throughout the tutorial, but we won't dive into its implementation again. If you've followed along and understood the content so far, you've got enough background to go to the next section where we start to dive into how to implement the predications.\n\nThis description is for those that are interested in how the algorithm works, and isn't necessary for understanding the rest of the tutorial:\nFirst some definitions used in this algorithm:\nHole: A scopal (i.e. h type) argument in an MRS predicate that doesn't refer to an existing predication\n\nFloater: A tree of predications that have had zero or more of their scopal (i.e. h type) arguments filled by unique predications.  [This is not at official MRS term, it is one created for this algorithm]\n\nAs a reminder, a tree is \"well-formed\" if:\nEach floater is assigned to one, and only one, hole. No holes or floaters are left at the end  \n\nNone of the assignments of floaters to holes violates a qeq constraint \n\nAny variable introduced by a quantifier is not used outside of the branches assigned to its RSTR or Body arguments  \n\nHere's the intuition for how the algorithm works: We are going to walk a search tree.  Every node of the search tree represents a partial assignment of floaters to holes that meets the above 3 constraints. Every arc from a parent node in the search tree to a child node in the search tree represents a unique assignment of a (otherwise unassigned) floater to a hole.  If that assignment violates a constraint, the search tree node is not valid (since obviously keeping this assignment and adding floaters to it can't be valid either) and we stop searching that whole branch of the search tree. This pruning is what makes it faster than the really naive \"try every option\" approach. Every node in the search tree that has no holes left to assign is a solution.\nAlgorithm Flow Summary: We start at the TOP: hole and record on it any qeq constraints that apply to it and any X variables that are in scope for it (none at the start). As we traverse an arc in the search tree and assign a new floater to a hole, we propagate any constraints and in-scope variables from the (parent) hole to the holes in the (child) floater.  Then we create the next node in the search tree by choosing the next hole to fill from the existing node.\nStart with:\nEach node in the search tree has the following structures that represent where the search has progressed to:\nallHolesDict:              Dictionary populated with all the holes in the MRS. Each hole has information about:\n- The qeq constraints that currently apply to it\n- The X variables that are currently in scope for it\n- The floater it is from\nnodeAssignmentList:        Assignments of floaters to holes that the search tree node represents. Empty for the initial node.\nnodeRemainingHolesList:    Holes left to fill in this search tree node. Only contains the TOP: hole for the initial node.\nnodeRemainingFloatersList: Floaters still unassigned at this node in the search tree. Contains all floaters for the initial node. Each floater contains information about:\n- A list of holes it contains\n- A list of unresolved x variables it contains\n- A list of any Lo parts of a qeq constraint it contains (if it doesn't also have the Hi part in the floater) \nAlgorithm:\nStarting at the initial node:\nGet currentHole by removing the first hole from nodeRemainingHolesList \n\nGet currentFloater by removing each floater from nodeRemainingFloatersList and: \nIf currentFloater does not violate the constraints in currentHole: \nAdd currentHole = currentFloater to nodeAssignmentList\n\nPropagate the constraints and variables from the new parent to all holes in currentFloater \n\nAdd holes from currentFloater to the end of nodeRemainingHolesList \n\nCheck number of holes left:\nif == 0, return nodeAssignmentList as a solution\n\notherwise, continue the search by \"creating a new search tree node\" via recursing to the top of the algorithm\n\n\n\n\nReturns:\nnodeAssignmentList which is simply a dictionary where the keys are holes and the value is the floater that was assigned to it.\nOnce this has run its course you will have all the valid well-formed trees for the MRS. \nHere is the Python code for the main routine:\ndef TryAlternativeHoleAssignments(allHolesDict, nodeRemainingHolesListOrig, nodeRemainingFloatersList, nodeAssignmentList):\n    # Grab the first hole to fill and remove it from the list\n    currentHole = allHolesDict[nodeRemainingHolesListOrig[0]]\n    nodeRemainingHolesList = nodeRemainingHolesListOrig[1:]\n\n    index = 0\n    # Try each remaining floater in this hole\n    for index in range(0, len(nodeRemainingFloatersList)):\n        # Grab the current floater and pull from the list for when we recurse\n        currentFloater = nodeRemainingFloatersList[index]\n        newNodeRemainingFloatersList = [x for i, x in enumerate(nodeRemainingFloatersList) if i != index]\n\n        # Check if constraints are met. If not, prune entire search space by\n        # skipping since none of its children can work either\n        errorOut = []\n        if not CheckConstraints(currentHole[&quot;Constraints&quot;], currentFloater, errorOut):\n            # Constraint Failed: try the next one\n            continue\n\n        # Hole successfully filled\n        # Assign the floater to the hole in a copy of assignments since we will be\n        # changing on each loop\n        currentAssignments = copy.deepcopy(nodeAssignmentList)\n        currentAssignments[currentHole[&quot;Label&quot;]] = currentFloater[&quot;Label&quot;]\n\n        if len(newNodeRemainingFloatersList) == 0:\n            # We filled the last hole, return the solution\n            yield currentAssignments\n            return\n\n        # If this floater has more holes, add them to a copy of the nodeRemainingHolesListOrig\n        # Fixup any of the holes from this floater in a *copy* of holeDict since it also holds the holes\n        # and the pointer to the hole is being changed so we don&#x27;t want other nodes to get changed too\n        newNodeRemainingHolesList = copy.deepcopy(nodeRemainingHolesList)\n        newHoleDict = copy.deepcopy(allHolesDict)\n        FixupConstraintsForFloaterInHole(currentHole[&quot;Constraints&quot;], currentFloater, newHoleDict)\n        for nextHoleName in currentFloater[&quot;FloaterTreeHoles&quot;]:\n            newNodeRemainingHolesList.append(nextHoleName)\n\n        # This hole was filled, see if any remain\n        if len(newNodeRemainingHolesList) &gt; 0:\n            # recurse\n            yield from TryAlternativeHoleAssignments(newHoleDict, newNodeRemainingHolesList, newNodeRemainingFloatersList, currentAssignments)\n\n    # At this point we tried all the floaters in this hole\n    return\n\nComprehensive source for the completed tutorial is available here.\n\n", "title":"Well-Formed Trees", "teaser":"Building Well-Formed MRS Trees\nTo understand this section, first make sure you have a basic understanding of the MRS format.  \n\nLet's use the sentence ...", "site":"Perplexity", "section":"MRS Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devhowto/devhowtoMRSSolver", "excerpt":"Solving an MRS\nIt is important to understand what MRS is and what a well-formed MRS tree is before reading this section. Visit those links first to understand the basic concepts.\n\nA well-formed MRS tree can be thought of as an equation that is true or false depending on the values of its variables. Recall that predications are of the form: _table_n_1(x) or compound(e,x,x). Just like functions in mathematics or programming languages, they have a name and a set of arguments. They are true when their arguments are set to values that are or mean what the predication means. \nSo:\nIf we set x = 'a cat' then _table_n_1(x) will be false\n\nIf we set x = 'the brown table' then _table_n_1(x) will be true\n\n_table_n_1(x) means: \"the object in x is a table\". It might also be many other things, like brown or large or missing, etc. But as long as it is at least a table, _table_n_1(x) is true.\nHow a cat or the brown table are actually represented doesn't matter as long as the predication can interpret it. It could be a string or an object of some kind.\nA group of multiple predications separated by commas means they are \"in conjunction\", which means the commas should be treated as and. So,large(x), file(x) will only be true if x is set to values that make all the predications true. In this example, x must be set to something that is a large file. Again, x could be a large yellow file or a large file of paperwork, but each predication just tests for some property of x and is true as long as that property is true, regardless of its other properties.\nSolving a well-formed tree means finding values for the variables that make all the predications true.\nHere's a simple example. Let's solve large(x), file(x) in a world with 3 objects in it:\na folder\na small file\na large file\n\nx variables in an MRS represent \"individuals\" or \"things in the world\". So, we need to find which are the individuals from the world that, when put into x, make both the predications in large(x), file(x) be true. \nWhile this is trivial to solve by looking at it, once the world contains a million objects we will need a more systematic approach.\nA Backtracking MRS Solver\nWe can look at solving an MRS as a constraint satisfaction problem which is a well-studied class of problems that have a finite set of constraints over variables. In the MRS case, the constraints are the predications:\nlarge(x) constrains x to only be those objects that are large\n\nfile(x) constrains x to only be those objects that are a file\n\nlarge(x), file(x) constrains x to be a large file\n\nOne simple approach to solving constraint satisfaction problems (like finding the solutions to an MRS) is to use \"backtracking\". The simplest backtracking algorithm is to:\nTraverse the predications from the well-formed MRS tree, depth-first\n\nWhen an unassigned variable in a predication is encountered: \nAssign it the first item in the world\n\nMark it as a backtrack point\n\n\nIf a predication is false:\n\"backtrack\" to the nearest backtrack point and retry with the next item in the world\n\nIf there are no more items to retry with, backtrack further to the next backtrack point and try again. \n\n\nThis will try all items in the world, in all variables, until it finds all solutions. Backtracking allows the search space to be pruned to avoid whole sets of assignments that can't possibly work, thus improving the performance vs. a full search of all possibilities.\nLet's use the backtracking algorithm to solve a slightly more interesting example, \"large file in folder\":\n[It is important to note that these are not real MRS or well-formed tree examples yet!  That will come soon.]\nformula: large(x), file(x), folder(y), in(x, y)\n\nworld individuals:\na folder\na small file\na large file\n\nworld facts:\n[a large file] is in [a folder]\n\nThe \"world individuals\" above are the only objects that exist in the world. x values in the MRS will hold these as values.\nThe \"world facts\" above are facts about the relationships between things in the world that predications such as in(x, y) can refer to to see if they are true.\nAs above, it doesn't matter how either of these is actually represented in a program, as long as the predications know how to find and interpret them. We'll be building an example of such a system in this tutorial.\nTo make the backtracking algorithm more explicit, and to make the formula more like real MRS predications, we need to introduce a notion of \"variable scope\". Variable scope shows where a variable is introduced and which predications can use it. \nWe'll represent scope by a made-up function for now: scope(variable, [predication_list]). The function states that variable can be used by all the predications in [predication_list]. And, since scope() itself is a predication, more variables can be defined in predication_list using another scope(). This allows us to represent our formula using scoping, like this:\nformula: scope(x, [large(x), file(x), \n                                      scope(y, [folder(y), in(x, y)])\n                  ])\n\nThe formula is formatted to make it easier to see the nesting. You can see that this is just a flat way of representing a tree shaped like this:\n                            \u250c\u2500\u2500 large(x)\n                            \u2502 \u250c\u2500\u2500 file(x) \n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1,2)\n                \u2502               \u2514\u2500\u2500 scope(y, predication_list)\nscope(x, predication_list)                          \u2502\n                                                    \u2514\u2500 and(0,1)\n                                                           \u2502 \u2514 in(x, y)\n                                                           \u2514 folder(y)\n\n... where and(...) has been used to explicitly show the conjunctions (i.e. ands).\nThe backtracking algorithm does its job by recursively \"evaluating\" the scope() predications:\nEvaluating a scope() means:\nAssign a world value to the scope's variable\n\nEvaluate its predication_list using that value (see below for how)\n\nIf the list is false, restart the list using the next world value\n\nIf the list is true, the scope() predication is true\n\nEvaluating a predication_list means:\nEvaluate the first predication in the list using the current values of all variables in scope\n\nIf true, try the next predication in the list\n\nIf false, the list is false\n\nIf all the predications are true, the list is true\n\n\nSo, working through the example:\n|Action|Formula|\n|---|---|\n|Start with initial formula |    scope(x, [large(x), file(x), scope(y, [folder(y), in(x, y)])]) |\n|set x='a folder' (the first item in the world) |    scope('a folder', [large('a folder'), file('a folder'), scope(y, [folder(y), in('a folder', y)])]) |\n|first item in list is false|    ... large('a folder')...|\n|backtrack: set x='a small file' (the next item in the world) |    scope('a small file', [large('a small file'), file('a small file'), scope(y, [folder(y), in('a small file', y)])]) |\n|first item in list is false|    ... large('a small file')...|\n|backtrack: set x='a large file' |    scope('a large file', [large('a large file'), file('a large file'), scope(y, [folder(y), in('a large file', y)])]) |\n|first item in list is true| ... large('a large file')...|\n|second item in list is true| ... file('a large file')...|\n|third item in list is scope(): set y='a folder' (the first item in the world)|    ...  scope('a folder', [folder('a folder'), in('a large file', 'a folder')])|\n|first item in scope(y, ...) is true|    ... folder('a folder') ...|\n|second item in scope(y, ...) is true|    ... in('a large file', 'a folder')...|\n|thus: scope(y, ...) is true for y='a folder'|    ...  scope('a folder', [folder('a folder'), in('a large file', 'a folder')])|\n|thus: scope(x, ...) is true for x='a large file' and y='a folder'|scope('a large file', [large('a large file'), file('a large file'), scope('a folder', [folder('a folder'), in('a large file', 'a folder')])])|\nThis example shows how:\nIteratively assigning values to each variable in a scope and\n\nEvaluating the predication list within a scope and\n\nBacktracking when there is a failure\n\n... will eventually find all the solutions to the formula (or prove that there are none). \nIt works because we are effectively trying all values in all variables. But, it is better than literally just assigning all values to all variables, one by one, until we find the answer, because backtracking eliminates whole branches in the search space. There are other optimizations that can be done, and we will do more as we go, but the basic approach is straightforward.\nAt this point, it should be noted that there are other algorithms for solving constraint satisfaction problems. Furthermore, the MRS tree can sometimes be transformed into other forms, such as a predicate logic formula, and turned into a different kind of problem which can be solved using completely different approaches. This tutorial will be using the backtracking algorithm because it is simple, efficient enough for many problems, and has the nice property that it can handle all MRS formulas. It has the downside that it can be very inefficient in some cases. We'll work through some of those and find optimizations for some of the most egregious problems.\nBut, before we can solve a real well-formed MRS tree, we need to account for more of its features. First up is allowing the solver to represent things operating \"together\".\n", "title":"Backtracking", "teaser":"Solving an MRS\nIt is important to understand what MRS is and what a well-formed MRS tree is before reading this section. Visit those links first to un ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devhowto/devhowtoMRSSolverSets", "excerpt":"Add \"Together\" and \"Separately\" To the Solver\nIf there were multiple large files in folders, the formula we ended the MRS Solver section with:\nformula: large(x), file(x), folder(y), in(x, y)\n\n... would find them all as different \"solutions\". Recall that a \"solution\" is an assignment of a single value to all variables, such as:\nsolution 1: x=file1, y=folder1\nsolution 2: x=file2, y=folder2\n...\n\nSo, using that approach, we could look at the formula as representing the phrase: \"large files in folders\" since it will find multiple if they exist. But, this only works because of how \"in\" behaves. If a and b are \"in\" a folder, a is in the folder and b is in the folder. \nThis isn't true of all verbs, however. The verb \"to lift\" can distinguish cases that mean very different things.  \nFor example:\nstudents lifted a table\n\n...could mean: \nTwo students (together) lifted a table (at the same time)\n\nTwo students (separately) lifted a (different) table\n\nWe need to be able to capture the semantic of the students working together or separately in our solutions. Simply having single values assigned to variables can't do that.\nHandling Sets\nTo represent individuals operating \"together\" or \"separately\" we can make a simple extension to the algorithm: require that variables always contain a set of one or more things from the world. Predications can then interpret a set of greater than one element as meaning \"together\".  A set of one item can mean \"separately\" or \"alone\". \nThis change allows the solver to represent a solution where Alice and Bob are lifting a table together like this: lift([alice, bob], [table1]). The fact that the first argument to lift is a set of two people means they are working together, which wasn't possible before.\nWith this change, a scope() predication now needs to assign all possible sets of values to its variable in order to explore the solution tree and find all the solutions. This can quickly become quite expensive, but there are optimizations we will explore. For now, we'll use the direct approach to keep the algorithm simple.\nLet's work through an example of a world where two students are lifting a table:\nformula: student(x), table(y), lift(x, y)\nscoped formula: scope(x, [student(x), scope(y, [table(y), lift(x, y)])])\n\nworld individuals:\n  alice\n  bob\n  table1\n\nworld facts:\n  [alice, bob] lift [table1]\n\nTo find all solutions, x and y now must be iteratively assigned all combinations of things in the world by their scope() predication, but the rest of the algorithm proceeds as before. \nUnlike in(), when lift() encounters a set of more than one item in either of its arguments, it has to check the world to see if the actors are lifting together, or if tables are being lifted together.\nSummarizing the results in truth table form:\n|assignment|formula result|\n|---|---|\n|x=[alice], y=[alice]| false|\n|x=[alice], y=[bob]| false|\n|x=[alice], y=[table1]| true|\n|x=[alice], y=[alice, bob]| false|\n|x=[alice], y=[alice, table1]| false|\n|x=[alice], y=[bob, table1]| false|\n|x=[alice], y=[alice, bob, table1]| false|\n|x=[bob], y=[alice]| false|\n|x=[bob], y=[bob]| false|\n|x=[bob], y=[table1]| true|\n|x=[bob], y=[alice, bob]| false|\n|x=[bob], y=[alice, bob, table1]| false|\n|x=[alice, bob], y=[alice]| false|\n|x=[alice, bob], y=[bob]| false|\n|x=[alice, bob], y=[table1]| true|\n|...| etc.|\nObserve how the variable assignments now contain sets (represented by []), and every combination of world individuals (that is not the empty set) is tried. Not all combinations are shown for all variables because:\nThe number of non-empty combinations of world individuals is (2^n - 1): think about representing each individual as a binary bit saying whether the individual is included (1) or not (0). n individuals means n bits. n bits can represent 2^n numbers. We subtract off the number that has all zeros since we don't want an empty set. In this case, that only means 7 combinations of individuals. \n\nBut: we also need all combinations of assignments of those individuals to x and y. That is a \"cartesian product\", which means we'd need to show (2^n - 1) * (2^n - 1) = 49 assignments in the list. This can quickly become an unmanageable number, but there are some approaches to taming the combinatorics that we'll go through later.\n\nIn the new form, the solutions we get back (i.e. the variable assignments that make the formula  true in the above table) are shown below, along with their meaning:\n|assignment|meaning|\n|---|---|\n|x=[alice], y=[table1]| Alice lifted a table|\n|x=[bob], y=[table1]| Bob lifted a table|\n|x=[alice, bob], y=[table1]| Alice and Bob lifted a table together|\nThus, the algorithm still gives us all the assignments of variables that make the formula true in the world, but now our formulation can express things operating together or separately.\nHowever, we need something more to allow representing plurals in a phrase, as described in the next section.\n", "title":"Representing 'Together'", "teaser":"Add \"Together\" and \"Separately\" To the Solver\nIf there were multiple large files in folders, the formula we ended the MRS Solver section with:\nformula ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devhowto/devhowtoMRSSolverSolutionGroups", "excerpt":"Collective and Distributive Readings\nIf we change the \"students lifted a table\" example from the previous section slightly, we can uncover another layer of meaning we need to represent in the solver. \nFor example:\nTwo students lifted one table\n\n...could mean: \n1. Two students [together] lifted one table [at the same time]\n2. Two students [separately] lifted one [different] table\n\nSo, in addition to representing things working together or separately by using sets as we did in the previous section, we need to deal with the fact that terms representing sets in language create a new layer of ambiguity: it isn't always clear if you are talking about the whole group of \"two students\" working together, or subsets of the group working separately. The solver needs to be able to find either solution properly.\nLet's start by defining some linguistics terminology to help us talk about the different ways students are grouped in the interpretations above:\nA group of items operating together are called collective: #1 has collective students.\n\nA group of items where different subsets of the group operate \"separately\" are called distributive: #2 has distributive students. \n\nNow, notice that there is more going on than just a different grouping of students. Reading #1 above describes a single table being lifted, whereas reading #2 has two ... but they both come out of a phrase that says \"... lifted one table\". This happens because the phrases are both being interpreted as \"one table [per group]\". #1 has a single group (of two students), #2 has two groups (of one student). \nSo, to discuss the whole phenomena across the phrase (and not just how the students are being grouped), the term \"reading\" is used in conjunction with collective or distributive. As in: \"#1 is a collective reading\" and \"#2 is a distributive reading\". Defining these a bit more rigorously:\nFor: \"M students lifting N tables\":\nTo be the distributive reading:\nStudents: must be grouped distributively into subgroups, which means:\n2 or more subgroups\n\nEvery student is in exactly one subgroup\n\nThe total of students across the subgroups must add up to M\n\n\nTables: Each student subgroup with more than one student must be together lifting exactly N tables\n\nTo be the collective reading:\nStudents must be grouped collectively, which means:\nExactly 1 \"subgroup\" that contains the entire set of students\n\n\nTables: Identical to the distributive reading, but using just one \"subgroup\" that contains everyone\n\n\nCumulative Readings\nIf we change the phrase again just slightly to allow for more than one table:\nTwo students lifted two tables\n\n... language lets in one more possible interpretation ... by counting total tables (not per group):\n3. One student lifted one table and another student lifted a different table.\n\nThis interpretation distributively groups the students, but counts the tables differently.  This can be confusing, so let's do the three definitions at once:\nFor: \"M students lifting N tables\":\nThe distributive reading: \"Two students [separately] lifted two tables [each]\"\nStudents: must be grouped distributively into subgroups, which means:\n2 or more subgroups\n\nEvery student is in exactly one subgroup\n\nThe total of students across the subgroups must add up to M\n\n\nTables: Each student subgroup with more than one student must be together lifting exactly N tables\n\nThe collective reading: \"Two students [together] lifted two tables [at the same time]\"\nStudents must be grouped collectively, which means:\nExactly 1 \"subgroup\" that contains the entire set of students\n\n\nTables: Identical to the distributive reading, but using just one \"subgroup\" that contains everyone\n\nThe cumulative reading: \"One student lifted one table and another student lifted a different table\"\nStudents: Identical to the distributive reading.\n\nTables: The total of tables across all subgroups must add up to M\n\n\nNote how the math for the cumulative reading is different than the math for collective and distributive readings. Collective and distributive readings require M tables per student subgroup, whereas cumulative requires M tables, total, across all student subgroups.\nIt is important to note that this is not some DELPH-IN feature or artifact, this is how human language works. We are just trying to emulate it by building an algorithm that processes phrases like a human would.\nAlgorithm Fixes for Collective, Distributive and Cumulative\nThe backtracking algorithm we've defined in previous sections will actually find the collective, distributive, and cumulative solutions to an MRS, if they exist, because it will find all solutions to the MRS.  But, there is a problem with the way we're currently defining \"solution\". To see why, let's bring back the three readings:\n\"two students lifted two tables\"\nThe distributive reading: \"Two students [separately] lifted two tables [each]\"\n\nThe collective reading: \"Two students [together] lifted two tables [at the same time]\"\n\nThe cumulative reading: \"One student lifted one table and another student lifted a different table\"\n\n\nNote that situations #1 and #3 are only properly represented by a group of solutions as we've defined \"solution\": \nSolution: Assignments of single set-based values to all variables that make the MRS true \n\nThere isn't a way to represent #1 and #3 as a single solution (i.e. a single set of variable assignments) in this model. For example, look at #1: Since each student is lifting a different \"two tables\", it will take 4 solutions to capture the meaning:\nx=[student1], y=[table1]\nx=[student1], y=[table2]\nx=[student2], y=[table3]\nx=[student2], y=[table4]\n\nEven if each student is lifting two tables at the same time, we still need two solutions:\nx=[student1], y=[table1, table2]\nx=[student2], y=[table3, table4]\n\nWe need to represent 2 students operating separately which means they must be in their own set, and variables can only be assigned one set-based value in a solution. Thus, distributive or cumulative scenarios will require a group of solutions to represent the answer. This is the change we need to make to the solver.\nSolution Groups\nWe can address the problem by changing our solver algorithm to generate solution groups, and then start interpreting a group of solutions as a complete answer. Let's go through the different scenarios using the grouping approach.\nFirst, a collective reading scenario:\nformula: student(x), table(y), lift(x, y)\nscoped formula: scope(x, [student(x), scope(y, [table(y), lift(x, y)])])\n\nworld individuals:\n  alice\n  bob\n  table1\n  table2\n\nworld facts:\n  [alice, bob] lift [table1, table2]\n\nThe solution group that represents this can actually be represented by a single solution in the group:\nSolution Group for the collective reading: \"Two students [together] lifted two tables [at the same time]\"\n|solution|interpretation|\n|---|---|\n|x=[alice, bob], y=[table1, table2]| Alice and Bob [together] lifted two tables [at the same time]|\n\nNext, a distributive reading scenario:\nformula: student(x), table(y), lift(x, y)\nscoped formula: scope(x, [student(x), scope(y, [table(y), lift(x, y)])])\n\nworld individuals:\n  alice\n  bob\n  table1\n  table2\n  table3\n  table4\n\nworld facts:\n  [alice] lift [table1]\n  [alice] lift [table2]\n  [bob] lift [table3]\n  [bob] lift [table4]\n\nThe solution group that represents this requires multiple solutions in the group:\nSolution Group for the distributive reading: \"Two students [separately] lifted two tables [each]\"\n|solution|interpretation|\n|---|---|\n|x=[alice], y=[table1]| Alice [separately] lifted one table|\n|x=[alice], y=[table2]| Alice [separately] lifted another table|\n|x=[bob], y=[table3]| Bob [separately] lifted one table|\n|x=[bob], y=[table4]| Bob [separately] lifted another table|\n\nFinally, a cumulative reading:\nformula: student(x), table(y), lift(x, y)\nscoped formula: scope(x, [student(x), scope(y, [table(y), lift(x, y)])])\n\nworld individuals:\n  alice\n  bob\n  table1\n  table2\n\nworld facts:\n  [alice] lift [table1]\n  [bob] lift [table2]\n\nThe solution group that represents this also requires multiple solutions in the group:\nSolution Group for The cumulative reading: \"One student lifted one table and another student lifted a different table\"\n|solution|interpretation|\n|---|---|\n|x=[alice], y=[table1]| Alice [separately] lifted one table|\n|x=[bob], y=[table2]| Bob [separately] lifted one table|\n\nSummary\nWith the addition of solution groups, the solver can now properly represent the meaning of plural sentences across collective, distributive and cumulative readings.\nNext up is a description of how the solver can actually do the grouping and arrive at those answers.\nTODO: talk about forward and reverse readings with respect to word order being a function of the tree that is generated.\n", "title":"Collective, Distributive, Cumulative", "teaser":"Collective and Distributive Readings\nIf we change the \"students lifted a table\" example from the previous section slightly, we can uncover another lay ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devhowto/devhowtoMRSSolverSolutionGroupsAlgorithm", "excerpt":"Solution Group Algorithm\nAs described in the previous section, the only way to represent the semantics of collective, distributive and cumulative readings of a sentence like:\nstudents lifted a table\n\nformula: student(x3), table(x10), lift(x3, x10)\nscoped formula: scope(x3, [student(x3), scope(x10, [table(y), lift(x3, x10)])])\n\n... is to have the solver create groups of solutions (\"solution groups\") that are the complete answers -- a single solution to the MRS is not enough. This section describes one algorithm that can accomplish this.\nOverview\nThe basic approach is to generate the solutions, exactly like we've been doing so far, but then add a new \"grouping pass\" afterward. The grouping pass will find the groups of solutions that meet all the numeric constraints that the words in the phrase have placed on the variables. The groups found represent the complete answers to the MRS.  \nTo illustrate what \"numeric constraint\" means, take \"students lifted a table\":\n\"students ...\" is plural, which means the contraint is: count(students) > 2\n\n\"... a table\" means the constraint is: count(tables) = 1\n\netc.\n\nTo generate solution groups from the flat list of solutions, we could start by generating all combinations of solutions and testing them. For a given combination from the above example: to determine count(students), we could simply count the students across all the solutions in the combination. If we do this as well for count(tables), and return those combinations where count(students) > 1 and count(tables) = 1, we will produce groups which are valid, but will miss any answers that require a \"per previous value\" count. So, we'll miss the distributive groups. We need to do a slightly more complicated counting algorithm that is \"per previous value\" to get all the readings.\nHere's an overview of how the algorithm can determine groups that properly account for cumulative, collective and distributive readings:\nDetermine the order variables appear when evaluating the tree\n\nWalk the variables in order. For each variable: count individuals in the solutions two different ways:\nCumulatively: Total the variable individuals across all solutions in the group (as above)\n\nDistributively/collectively: Group the individuals by the value of the previous variable in the order, and then do the total per previous value. If the totals are all the same, across all previous values, that is the count. If not, this count fails and has no value.\nIf this is the first variable: there is no \"previous variable\" to use for the \"total per previous value\" definition of collective and distributive. Therefore, the first variable can only be totalled as cumulative. \n\n\n\nIf either count meets the variable constraint, it succeeds and the next variable in the order is tried. If not, this group fails.\n\nIf the end is reached and all variables succeeded, this is a valid solution group.\n\n\nTo get the groups that should be checked using the process above, we (you guessed it...) try every combination of solutions that solving the tree produced. We will end this entire section with ways of efficiently doing this, but we'll start with the simplistic approach because it is easier to follow and does work, just not efficiently as it could. \nFiguring out which constraints are on the variables is a longer story, which the next few sections will cover.\nVariable Constraints Overview\nNotice that every x variable used in a tree has some kind of numeric constraint applied to it, even if implied. We can model them all using a between(min, max) (inclusive) constraint with a lower bound and an upper bound. The upper bound can be \"inf\", meaning \"infinity\".\nFor \"students lifted a table\":\n\"students ...\" is plural, which means: between(2, inf)\n\n\"... a table\" means: between(1, 1) (i.e. exactly 1)\n\nFor \"which file is under 2 tables?\":\n\"... file ...\" is singular, which means: between(1, 1)\n\n\"... 2 tables ...\" specifies two, so: between(2, 2)\n\nbetween(1, inf) is the default constraint, meaning: \"anything\". Variables with no other constraint get this one -- it is implied.\nThe next section talks about how to extract these constraints from the tree itself.\nDetermining Constraints From the MRS Tree\nNumeric constraints can come from 3 places in an MRS: quantifiers, adjectives and the plurality property of a variable. Determining constraints will force us to finally start looking at full MRS documents as opposed to simplified MRS fragments that use the artificial scope() predication we invented in the previous section.\nLet's start with \"two students lifted a table\". Here's one MRS reading of it, along with one well-formed tree:\n[ &quot;two students lifted a table&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: prop TENSE: past MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ udef_q&lt;0:3&gt; LBL: h4 ARG0: x3 [ x PERS: 3 NUM: pl IND: + ] RSTR: h5 BODY: h6 ]\n          [ card&lt;0:3&gt; LBL: h7 ARG0: e9 [ e SF: prop TENSE: untensed MOOD: indicative PROG: - PERF: - ] ARG1: x3 CARG: &quot;2&quot; ]\n          [ _student_n_of&lt;4:12&gt; LBL: h7 ARG0: x3 ARG1: i10 ]\n          [ _lift_v_cause&lt;13:19&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x11 [ x PERS: 3 NUM: sg IND: + ] ]\n          [ _a_q&lt;20:21&gt; LBL: h12 ARG0: x11 RSTR: h13 BODY: h14 ]\n          [ _table_n_1&lt;22:27&gt; LBL: h15 ARG0: x11 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 h13 qeq h15 &gt; ]\n\n                        \u250c\u2500\u2500 _student_n_of(x3,i10)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n            \u2502             \u2514 card(2,e9,x3)\nudef_q(x3,RSTR,BODY)\n                 \u2502             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x11)\n                 \u2514\u2500 _a_q(x11,RSTR,BODY)\n                                    \u2514\u2500 _lift_v_cause(e2,x3,x11)\n\nText Tree: udef_q(x3,[_student_n_of(x3,i10), card(2,e9,x3)],_a_q(x11,_table_n_1(x11),_lift_v_cause(e2,x3,x11)))\n\nTwo points to note as we transition to using real MRS trees instead of simplified trees:\nAt this point, we can dispense with the artificial scope() predication because the MRS quantifier predications (those with _q at the end) fulfill the same variable scoping role as scope(). They declare where in the tree a variable can be used.  They also can add numeric constraints to the variable, as we'll see below.\n\nPredications in MRS have variable types beyond the x-type variables we've been using. For the examples we'll see here, these can be safely ignored. We'll handle those in a later section.\n\nWith that covered, let's walk through how to get the numeric constraints from the above MRS.\nOrder of Variables\nFirst, notice that the variable order in this tree is [x3, x11] (read left to right) since that is the order of the variable quantifiers when evaluating the tree depth-first.\nQuantifier Constraints\nEach variable in an MRS must have a quantifier that scopes it (the artificial scope() predication performed this function in prior examples), and quantifiers always add a numeric criteria to the variable they scope.  Some, like udef_q in our example, add the default criteria between(1, inf). This simply means: \"at least one\". The _a_q quantifier means \"a single thing\", so it adds between(1, 1). \nThus, the quantifiers in this example add these constraints:\n|x3 (students)|x11(table)|\n|---|---|\n|udef: between(1, inf)| _a_q: between(1, 1)|\nAdjective Constraints\nSome adjectives also add numeric constraints. In our example, the adjective \"two\" gets converted to the predication: card(2,e9,x3) in the MRS. This predication adds the constraint between(2, 2) to x3. Now we have these:\n|x3 (students)|x11(table)|\n|---|---|\n|udef: between(1, inf)| _a_q: between(1, 1)|\n|card: between(2, 2)| |\nPlural Variable Properties\nFinally, some variables (x3 in our example), are defined to be plural by the MRS, as indicated by NUM: pl in the variable properties of x3:\n[ udef_q&lt;0:3&gt; LBL: h4 ARG0: x3 [ x PERS: 3 NUM: pl IND: + ] RSTR: h5 BODY: h6 ]\n\nThis adds the constraint between(2, inf) to x3. \nx11 from _table_n_1(x11) is singular based on its variable properties:\n[ _lift_v_cause&lt;13:19&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x11 [ x PERS: 3 NUM: sg IND: + ] ]\n\n...  so it adds between(1, 1):\nThus, our final list of constraints is:\n|x3 (students)|x11(table)|\n|---|---|\n|udef: between(1, inf)| _a_q: between(1, 1)|\n|card: between(2, 2)| [NUM: sg]: between(1, 1) |\n|[NUM: pl]: between(2, inf)| |\nCombining Constraints\nThe final constraints from the example can be combined.  If x3 must be:\n\"between 1 and infinity\" and \"between 2 and infinity\" then saying \"between 2 and infinity\" is enough.\n\n\"between 2 and infinity\" and \"between 2 and 2 (i.e. exactly 2)\" then saying \"between 2 and 2\" is enough.\n\nUsing this logic, the final list of constraints above can be reduced to:\n|x3 (students)|x11(table)|\n|---|---|\n|between(2, 2)| between(1, 1)|\nWhich matches the intuition that there should be exactly two students and exactly one table (possibly for each student) in \"two students lifted a table\".\nMRS Constraints Summary\nSo, now we have an approach to gathering the constraints from the MRS:\nFor each x variable in the MRS:\nAdd the appropriate constraint for its quantifier\n\nAdd any constraints from adjectives that modify it\n\nAdd the NUM: pl or NUM: sg constraint\n\nReduce them to the minimal set\n\n\nThe Final Algorithm: Introducing Phase 0\nThis section started by describing the two phases of the solver algorithm:\nPhase 1: Evaluate the MRS tree to get the solutions\n\nPhase 2: Group the solutions into solution groups that meet the phrase's numeric constraints\n\nIt turns out that the (just described) process of building the numeric constraints is really a \"Phase 0\". And, if you think about what adjectives like \"two\" (or \"a few\" or \"many\") actually do, their entire contribution is to act as a numeric constraint. Their work happens during Phase 2 ... they have nothing to do in Phase 1. So, after we extract the criteria from them in Phase 0, they should be removed from the tree and Phase 1 should be solved using the modified tree without them.\nFurthermore, recall that quantifiers do two things: scope a variable and add a numeric constraint to the variable. So, after you extract the numeric constraint from quantifiers like _a_q or _some_q, you've also removed all of their contribution to Phase 1 except for variable scoping. So, we don't remove them, but we do replace them with the most generic quantifier: udef_q.\nThus, Phase 0 analyzes a full tree for \"2 students lifted a table\", one of which is this:\n                        \u250c\u2500\u2500 _student_n_of(x3,i10)\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n            \u2502             \u2514 card(2,e9,x3)\nudef_q(x3,RSTR,BODY)\n                 \u2502             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x11)\n                 \u2514\u2500 _a_q(x11,RSTR,BODY)\n                                    \u2514\u2500 _lift_v_cause(e2,x3,x11)\n\n... but then, after extracting numeric constraints, converts it to a tree without the numeric constraints in it (since those will run in Phase 2), and provides this modified tree to Phase 1:\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _student_n_of(x3,i10)\n            \u2502             \nudef_q(x3,RSTR,BODY)\n                 \u2502               \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x11)\n                 \u2514\u2500 udef_q(x11,RSTR,BODY)\n                                      \u2514\u2500 _lift_v_cause(e2,x3,x11)\n\n... and finally Phase 3 runs the extracted numeric constraints over the Phase 1 solutions to generate the final solution groups. \nHere's the full algorithm all in one place:\nPhase 0: Setup\nStart with a well-formed MRS Tree\n\nDetermine the list of x variables in the tree and the order they will be evaluated in\n\nDetermine the constraints placed on each x variable by predications that modify it\n\nCreate a modified tree by:\nRemoving adjective predications that added numeric constraints\n\nChanging quantifiers that added numeric constraints to udef_q\n\n\nPhase 1: Solution Generation\nGenerate the list of solutions to the modified tree using the approach described in the previous section\n\nPhase 2: Group Generation\nFor each possible combination of solutions from Phase 1: Walk the x variables in evaluation order. \n\nFor each x variable: Count individuals in the solutions two different ways:\nCumulatively: Total the variable individuals across all solutions in the combination\n\nDistributive/collectively: Group the individuals by the value of the previous variable in the order, and total individuals in this variable per previous value. If the totals are all the same, across all previous values, that is the count. If not, this count fails and has no value.\nIf this is the first variable, there is no \"previous variable\" to use in the \"total per previous value\" definition of distributive/collective. Therefore, the first can only be totalled cumulatively\n\n\n\nIf either count meets the variable constraints: it succeeds and the next variable in the order is tried\nIf not: this group fails and the next combination group starts at step #5\n\n\nIf the end of the variables is reached and all succeeded, this combination is a valid solution group\n\n\nWhen numeric constraints are removed from an MRS we are left with a relatively straightforward constraint satisfaction problem that should be able to return solutions quickly, but there still may be many solutions.\nExample\nThat can be a lot to take in, so let's go through an example, \"students lifted a table\":\n[ &quot;students lifted a table&quot;\n  TOP: h0\n  INDEX: e2 [ e SF: prop TENSE: past MOOD: indicative PROG: - PERF: - ]\n  RELS: &lt; [ udef_q&lt;0:8&gt; LBL: h4 ARG0: x3 [ x PERS: 3 NUM: pl IND: + ] RSTR: h5 BODY: h6 ]\n          [ _student_n_of&lt;0:8&gt; LBL: h7 ARG0: x3 ARG1: i8 ]\n          [ _lift_v_cause&lt;9:15&gt; LBL: h1 ARG0: e2 ARG1: x3 ARG2: x9 [ x PERS: 3 NUM: sg IND: + ] ]\n          [ _a_q&lt;16:17&gt; LBL: h10 ARG0: x9 RSTR: h11 BODY: h12 ]\n          [ _table_n_1&lt;18:23&gt; LBL: h13 ARG0: x9 ] &gt;\n  HCONS: &lt; h0 qeq h1 h5 qeq h7 h11 qeq h13 &gt; ]\n\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _student_n_of(x3,i8)\nudef_q(x3,RSTR,BODY)          \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x10)\n                 \u2514\u2500 _a_q(x10,RSTR,BODY)\n                                   \u2514\u2500 _lift_v_cause(e2,x3,x10)\n\nText Tree: udef_q(x3,_student_n_of(x3,i8),_a_q(x10,_table_n_1(x10),_lift_v_cause(e2,x3,x10)))\n\nPhase 0: Setup\nStart with a well-formed MRS Tree\n\nDetermine the list of x variables in the tree and the order they will be evaluated in\n\nDetermine the constraints placed on each x variable by predications that modify it.\n\n\nUsing the approach described above, the evaluation order of variables is [x3, x10] in a depth-first traversal and the found constraints for the variables are:\n|x3 (students)|x10(table)|\n|---|---|\n|udef: between(1, inf)| _a_q: between(1, 1)|\n|[NUM: pl]: between(2, inf)| [NUM: sg]: between(1, 1) |\nWhen simplified, they are:\n|x3 (students)|x10(table)|\n|---|---|\n|between(2, inf)| between(1, 1) |\nCreate a modified tree by:\nRemoving adjective predications that added numeric constraints\n\nChanging quantifiers that added numeric constraints to udef_q\n\n\n\nThe modified tree is:\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _student_n_of(x3,i8)\nudef_q(x3,RSTR,BODY)             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _table_n_1(x10)\n                 \u2514\u2500 udef_q(x10,RSTR,BODY)\n                                      \u2514\u2500 _lift_v_cause(e2,x3,x10)\n\nPhase 1: Solution Generation\nGenerate the list of solutions to the modified tree using the approach described in the previous section\n\n\nUsing a (unshown) world state, and using the approach described in the previous section, the solutions to the modified tree are (let's say):\n&quot;students lifted a table&quot;\n\nTree: udef_q(x3,_student_n_of(x3,i8),udef_q(x10,_table_n_1(x10),_lift_v_cause(e2,x3,x10)))\n\nSolution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\nSolution 2: x3=[student2], x10=[table2]\nSolution 3: x3=[student3], x10=[table3]\nSolution 4: x3=[student3], x10=[table4]\nSolution 5: x3=[student4], x10=[table5]\nSolution 6: x3=[student4], x10=[table6]\nSolution 7: x3=[student5,student6], x10=[table7]            &quot;student5 and student6 [together] are lifting table7&quot;\nSolution 8: x3=[student5,student6], x10=[table8]\nSolution 9: x3=[student7,student8], x10=[table9, table10]   &quot;student7 and student8 [together] are lifting table9 and table10 [at the same time]&quot;\nSolution 10: x3=[student9], x10=[table11, table12]          &quot;student9 is lifting table11 and table12 [at the same time]&quot;\nSolution 11: x3=[student10,student11], x10=[table13]\nSolution 12: x3=[student12], x10=[table14]\n\nPhase 2: Group Generation\nFor each possible combination of solutions from Phase 1: Walk the x variables in evaluation order. \n\n\nStart by generating (as yet untested) groups that are all combinations of the above solutions. These may or may not be solution groups, we don't know yet: we need to test each one:\nGroup 1:\n  Solution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\n\nGroup 2:\n  Solution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\n  Solution 2: x3=[student2], x10=[table2]\n\nGroup 3:\n  Solution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\n  Solution 2: x3=[student2], x10=[table2]\n  Solution 3: x3=[student3], x10=[table3]\n\n... etc. (there are *many* more groups not listed)\n\nFor each group:\nFor each x variable: Count individuals in the solutions two different ways:\nCumulatively: Total the variable individuals across all solutions\n\nDistributive/collectively: Group the individuals by the value of the previous variable in the order, and total individuals in this variable per previous value. If the values are all the same, that is the count. If not, this count fails and has no value.\nIf this is the first variable, there is no \"previous variable\" to use in the \"total per previous value\" definition of distributive/collective. Therefore, the first can only be totalled cumulatively\n\n\n\nIf either count meets the variable constraints: it succeeds and the next variable in the order is tried\nIf not: this group fails and the next group starts at step #5\n\n\nIf the end of the variables is reached and all succeeded, this combination is a valid solution group\n\n\nUsing the constraints we determined:\n|x3 (students)|x10(table)|\n|---|---|\n|between(2, inf)| between(1, 1) |\n... let's analyze each group:\nGroup 1:\n  Solution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\n\nx3 is the first variable so we only do the cumulative count for it: cumulative_count=1. The constraint on x3 is between(2, inf). Thus: this group fails.\nGroup 2:\n  Solution 1: x3=[student1], x10=[table1]                     &quot;student1 is lifting table1&quot;\n  Solution 2: x3=[student2], x10=[table2]\n\nx3 is the first variable so we only do the cumulative count for it: cumulative_count=2 which passes the constraint between(2, inf). Try the next variable.  \nx10 gets both kinds of count: \ncumulative_count=2. This fails the between(1, 1) constraint, but we have one more try...\n\ndist_coll_count(student1)=1, dist_coll_count(student2)=1. Both counts are the same so dist_coll_count=1 The constraint on x10 is between(1, 1). Thus: this variable succeeds.\n\nThere are no more variables, thus this group is an answer: a distributive answer.\netc. \nAll of the groups that succeed are solution groups and will be valid collective, distributive or cumulative readings of the phrase in that world.\nThere are some subtleties that need to be address with this algorithm. Namely: which of these solution groups to respond to the user with (described in the next section) and global constraints from words like \"the\" (described in the section after that).\n", "title":"Coll/Dist/Cuml Algorithm", "teaser":"Solution Group Algorithm\nAs described in the previous section, the only way to represent the semantics of collective, distributive and cumulative read ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
, {"url": "https://blog.inductorsoftware.com/Perplexity/home/devhowto/devhowtoMRSSolverSolutionCombinations", "excerpt":"Combination Algorithm\nIn the section introducing the solution grouping algorithm, the algorithm starts with:\nFor each possible combination of solutions from Phase 1 ...\n\nAnd leaves how to generate them as an exercise for the reader. In this section, we'll go through one approach to generating combinations of solutions that properly deals with the kinds of answers users expect and allows for some performance optimizations.\nOnly 2 Solution Groups Are Needed\nThe number of solution groups for a tree in a given world can be quite large, but the system only needs 2 of them for any response (question, proposition or command). This allows for some nice performance optimizations. Let's go through each type of phrase to see why.\nWH-Questions\n\"WH-Questions\" are \"which/who/what/where\" questions that expect a list as a response. Let's use this tree from the phase \"which 2 files are in a folder?\":\n                          \u250c\u2500\u2500 _file_n_of(x3,i10)\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500 and(0,1)\n              \u2502             \u2514 card(2,e9,x3)\n_which_q(x3,RSTR,BODY)\n                   \u2502             \u250c\u2500\u2500\u2500\u2500\u2500\u2500 _folder_n_of(x11,i16)\n                   \u2514\u2500 _a_q(x11,RSTR,BODY)\n                                      \u2514\u2500 _in_p_loc(e2,x3,x11)\n\n... in this world:\n\\desktop\\file1.txt\n\\desktop\\file2.txt\n\\system\\file3.txt\n\\system\\file4.txt\n\nSome solution groups for this are:\nGroup:\n  \\desktop\\file1.txt\n  \\desktop\\file2.txt\n\nGroup:\n  \\system\\file3.txt\n  \\system\\file4.txt\n  \nGroup:\n  \\desktop\\file1.txt\n  \\system\\file3.txt\n\nGroup:\n  \\desktop\\file1.txt\n  \\system\\file4.txt\n\nGroup:\n  \\desktop\\file1.txt\n  \\system\\file4.txt\n  \netc., there are more ...\n\nHow many of these solution groups does the system need in order to respond? 1 of them? all of them? If we want the system to respond in the way a user expects, we need to observe the way a human would respond. \nHere are some typical responses a human might make when asked questions about the world above:\nLin: Which 2 files are in a folder?\nMila: Umm...there are more than 2 files in a folder ... which do you mean?\n\nIrene: Which 2 files are in a folder?\nHana: Actually, there are a bunch of files in a folder, 2 of of them are: file1.txt and file2.txt\n\nJuan: Which 2 files are in a folder?\nCarlos: Well, lets see: file1.txt and file2.txt are in \\desktop, file3.txt and file4.txt are in \\documents, ...\n\nThe first two explicitly or implicitly acknowledge that the question is implying there are only 2 files in a folder, but the participants are willing to respond to a phrase the user didn't ask, giving them the benefit of the doubt. The last one interprets the phrase more broadly as something like \"what are all the sets of 2 files in a folder\".  Carlos is probably a puzzle or math guy and thought it was a trick question.\nAnother example: In a physics class of 20 students, where only one student got 100%, the professor is asked, \"Which students aced the exam?\" and responds with \"Only Mariam.\" Note that the question had \"students\" (plural) and the professor felt the need to say \"only\" to indicate that they weren't really answering the question asked since they responded in singular. Saying simply \"Mariam\" feels slightly wrong, but note that if 2 students aced it, saying \"Mariam and Aron\" would be just fine and not feel wrong at all. So, something is being acknowledged in the one student case.\nSo, building a system that is completely literal and responds to \"Which 2 files are in a folder?\" with \"There are more than only 2 files in a folder.\" (Mila's response above), might be correct but will be annoying.  The Carlos answer is the most complete and generous, but could result in a huge (possibly expensive) answer when the user, who also understands that the question implicitly means \"only\", probably misunderstood the world state. Hana's answer is a good middle ground that gives an answer \"just in case\", but acknowledges that the question was probably a misunderstanding of the world state. Hers also doesn't overload the questioner with a huge number of answers.\nThis implies that, for WH-questions (where, what, who, etc), we need to get one answer to respond and see if there is another to let the questioner know there are more. We need 2 answers.\nYes/No Questions\nWhat about (using the same examples from above): \"Are there 2 files in a folder?\" or \"Did students ace the exam\"? These act the same as WH-questions:\nResponding to \"Are there 2 files in a folder?\" with \"Yes.\" is technically true for the above example, but would probably be considered a little misleading. So the answerer might respond with something like \"Technically yes, but there are more.\"\n\nResponding to \"Did students ace the exam?\" with \"Yes.\" would cause most people to be mildly annoyed later if they find out there was only one. \n\nThis implies that, for Yes/No questions, we need to get one answer to respond and test if there is another answer to let the questioner know there are more. So, we also need 2 answers.\nPropositions\nContinuing with our example, this time as a proposition: \"2 files are in a folder\" or \"students aced the exam\". These act just like Yes/No questions: The first is \"technically true\" the second is just wrong. So: 2 answers required.\nCommands\nWhat should \"delete 2 files in a folder\" do? Deleting all examples of \"2 files in a folder\" feels wrong. There seems to be an implied \"one instance of\" after delete. A clearer example might be \"delete a file in a folder\". There are 4 examples (solution groups) of \"a file in a folder\" in the world in question, but deleting them all due to that phrase would be certainly wrong.\nSo, if we decide that we should only pick one of the solution groups to act on for commands, it should be noted that deleting \"2 files\" or \"a file\" when there is more than one solution group feels a bit random. For this example, a human might ask, \"Do you mean a random 2 files?\". Certainly saying, \"delete files in a folder\", if there is only 1 file, feels wrong, just like \"Talk to the students that aced the exam\" when there is only one student feels wrong.  Either would probably get a response like \"OK, but there is only one\" to communicate that the listener isn't going to do exactly what was commanded.\nAll this is to say that, again, commands should also retrieve 2 solution groups. The first is what will be \"done\", the second is to see if some kind of clarifying response should be given.\nSo, to summarize, we only need to return 2 solution groups in the algorithm we develop, across all types of phrases. This will give us some room for performance optimization.\nMaximal, Minimal, and Subset Solution Groups\nBased on the above analysis, we're going to need to retrieve two solution groups (if they exist) when processing any user phrase and show the user (or do) the first group. The second group is just tested to see if it exists and then say \"there are more answers here...\" in some form.\nThe problem is: as we've seen in previous sections, there can be many correct solution groups for a given answer which aren't \"maximal\".  To see what \"maximal\" means, take: \"which files are in a folder?\" when there are these files in a folder:\n/folder/file1.txt\n/folder/file2.txt\n/folder/file3.txt\n/folder/file4.txt\n\n... one technically correct answer is:\n/folder/file1.txt\n/folder/file2.txt\n\n... another technically correct answer is:\n/folder/file1.txt\n/folder/file2.txt\n/folder/file3.txt\n\netc. \nBasically, any combination of files in a folder is a \"technically correct\" answer so long as it is > 1 (due to plural \"files\"). While it is technically correct, if you asked a person, \"which files are in a folder\" and they gave you one of those answers, you might be a bit annoyed and clarify with \"can you give me the whole list?\"  Let's call these \"subset solution groups\".\nSo, since we are only going to return one solution group, we really want to return the maximal solution group, the one where no more solutions can be added to the group while still keeping it a valid group. Keeping it a valid group means all solutions in the group conform to at least one type of answer (collective, distributive or cumulative). It is OK if they all conform to more than one, however.\nIn general, subset solution groups can be generated any time a criteria for a variable has a range of values that can be true. When the solution group is at the bottom of the range for that variable it is a \"minimal\" solution, at the top is a \"maximal\" solution, anything in between is a \"subset\" solution. \nTwo examples:\nEven one plural variable in an MRS can potentially generate multiple subset groups.  For example: \"men are walking\" (when talking about a specific group of men). The entire group of \"men\" can be represented in one solution group, so you'd just expect one group in answer to, \"Which men are walking?\". But: subsets of that group would also be true, so other solution groups are also technically correct.\n\nWith two variables: \"men(x) are walking a dog(y)\" (when talking about one group of men walking a particular dog) you'd still only expect one solution group in answer to \"Which men are walking a dog?\": the \"maximal\" solution. But again, subsets would be technically true, just not really telling the whole story.\n\nAll this is to say: if you're only going to give one answer (which we are), it should be a maximal one. To make the system responsive, though, it should start returning an answer as soon as one meets the constraints (i.e. when we have a \"minimal\" answer), but then keep returning answers as the set gets enlarged. That way, the user can see answers as they come.\nTo sum up:\nSince we are only going to show the user one solution group, it should be a maximal group\n\nIt should get returned iteratively, starting as soon as there is a minimal group that meets its constraints, but the entire maximal group should be ultimately returned\n\nThe complete solution group shown should meet the rules for one of the three types (collective, distributive or cumulative)\n\nBased on this, it is worth defining a few terms that we can use as we walk through more scenarios:\na \"minimal solution group\" is one where the constraints meet the minimum required to be a solution group. Since adding a new solution only ever increases variable counts (since variables always have at least one individual), the first solution group that meets the criteria will always be minimal (it may also be maximal!)\n\na \"maximal solution group\" is one where no more solutions can be added to the solution group and still have it a) meet the criteria and b) have all solutions be contributing to a single mode. This could be because all the criteria are at their maximum, or it could be because there are no more solutions to add.\n\na \"subset solution group\" is anything that isn't maximal but is still a solution. It is a \"subset\" of some maximal solution group in that all of its rows are completely included in that other group.\n\na \"unique solution group\" is one that isn't a subset of another solution group. It has at least one solution that is not in any other.\n\nWe'll use these terms as we develop the algorithm below.\nIt is important to note that these terms are all invented for this algorithm. They (or even the notion of \"solution group\") are not DELPH-IN or even linguistic terms.  They are artifacts of the particular approach being used to solve MRS trees.\nAlgorithm Version 1\nThis will form the skeleton of the algorithm we're going to eventually settle on. It is a general purpose algorithm that creates all combinations of items in a set:\nStart with a list of sets: set_list, which initially contains a single empty set. \n\nWhen a new solution is found, for each selected_set in set_list:\n\nBuild a new_set by adding the solution to selected_set \n\nIf new_set meets or could eventually meet the criteria (once more rows are added), add it to set_list\n\nIf new_set actually did meet the criteria, also return it as a solution group\n\nThis algorithm works because each set in set_list becomes a base for creating new combinations when a new solution comes in. And, when that new alternative is created, it also gets added to set_list so it can also form new combinations. In this way, we generate all possible combinations.\nThis algorithm for creating all possible combinations has a very useful property: it doesn't require knowing the length of the flat list of solutions coming in, and it builds combinations out of the items it already has before retrieving another solution. This means it will allow us to efficiently stream solutions to it without having to calculate them all up front, which could be very expensive.  \nThis is not the final algorithm because, while it will produce all combinations that meet the criteria, it also produces the problematic \"subset\" or \"minimal\" solutions that we described above. But, it will form a good skeleton for an algorithm we can use with modifications.\nAlgorithm Version 2\nWe need 3 things from the final algorithm:\n(for all cases) Retrieve a minimal solution group as quickly as possible. For yes/no questions and propositions, we just need to prove there is one solution, so a minimal solution is enough to create the initial answer. For wh-questions and commands, we want to start showing the answers as soon as we have them for responsiveness.  So, in all cases, we don't care if it is maximal for the initial response, we just want it quickly.\n\n(for WH-questions and commands) We want to stream the rest of the solutions until there is a maximal group. This is so we respond to the user or do the command with a full answer (as described above). After receiving the minimal solution group, we'd like to continue getting additional solutions that belong in that solution group as they become available, until we have the maximal solution group. \n\n(for all cases) Detect if there is more than one unique solution group. This allows us to say \"there are more\" (as described above). Importantly, it needs to be a unique solution group, not one that is a subset of another group.\n\nLet's walk through how to modify the algorithm so it meets each requirement.\nRetrieve a Minimal Solution Group Quickly\nAlgorithm version 1 already does this. It returns a solution group as soon as it detects it is a valid collective, distributive or cumulative solution. No changes are needed to meet this requirement.\nStreaming Solutions Until There is a Maximal Group\nAlgorithm version 1 only generates alternative solution groups -- it doesn't say which are simply enlarging a previously returnedsolution group with another solution.\nTo fix this, note that each returned solution group was generated by taking an existing group from the set list and adding a solution to it. So, the algorithm can give each set a unique ID and a \"lineage\" that tracks where it came from. For example, set id 5 might have a lineage of 0:3:5 indicating that it came directly from set 3, and 3 came from 0. The lineage shows the set history (which sets this set came from) for this set.\nIf we include the lineage when we return a solution group, the caller can see if it is a simple update of a solution group they already have by comparing their lineages.  If they share a prefix, then the new one is a descendent -- it is just \"a little more\" of that solution. The caller must then use that new lineage as its base to compare from. This last step is needed so it doesn't think all the alternatives generated from its current solution group were also \"a little more\". It is effectively following one set as it grows.\nIn this way, we can get a minimal solution group first and slowly grow it over time by examining every solution group that comes from the algorithm and comparing the lineages to the solution we have. This allows us to stream the solutions as they get added to a solution group, eventually ending with the maximal solution group.\nIf there are 5 unique solution groups for a given phrase, this means we will effectively be picking one at random to show the user. This is OK since, if there are many solutions, it really doesn't matter which we show. [TODO: explain why].\nDetect If There Is More Than One Unique Solution Group\nAlgorithm Version 1 doesn't indicate whether a returned solution group is a unique solution group -- one that isn't a subset of any other. It just returns solution groups that have 1 more solution than those it has generated before. This problem is really the inverse of the one above. In this case, we want to see if a new solution group isn't a subset of the one we've selected.\nThe lineage described above provides a way to determine this. A solution group can only be a subset of another if its lineage is a prefix of the other. Said another way: if group 1 is a subset of group 2, group 2 will have group 1's exact lineage as the start of its lineage. This is because lineage shows a complete history of how a set came to be. If there is a solution that has a different lineage than the one we are tracking as \"the chosen solution to show the user\", it must include at least one answer that is different than the chosen one, and thus it must be a different unique solution.\nSo, we will be able to detect if we have more than one unique solution group by picking the lineage that is \"the answer\" we'll show the user, and then seeing if we can find another solution group that has a different lineage. If there is one, that is a second unique solution group.\nWhen Can We Stop\nIf at least one variable has max=inf we need to go all the way to the end to get the maximal solution. If none do, we actually want the minimal solution (but tell the user there are more). So we can stop after we find two solutions\nTODO: finish this\nAlgorithm 2 Design\nWe now have everything we need to design Algorithm 2. It will be more efficient than Algorithm 1 while also allowing us to give the kinds of answers a user will expect. It uses the same skeleton as Algorithm 1, but has some extensions to meet the requirements above. There are two parts: a \"combination generator\" based on Algorithm 1, and a \"solution group picker\" which is new.\nCombination Generator\nStart with:\nset_list (a list of sets), which initially is only a single empty set\n\nWhen a new solution is found, for each selected_set in set_list:\nBuild new_set by adding the solution to selected_set\n\nGenerate a unique_id. Then, create a lineage for new_set by appending unique_id to the end of the selected_set lineage\n\nIf new_set meets or could meet the criteria (once more rows are added), add it, along with its lineage, to set_list\n\nIf new_set actually did meet the criteria, also return it, and its lineage, as a solution group\n\nSolution Group Picker\nStart with more_than_one_solution_group=False and chosen_solution=None\nGet the first solution group from the combination generator. This is the chosen_solution. Yield it as the \"minimal solution\" to the caller.\n\nFrom then on, for each new_solution_group returned from the combination generator:\n\nIf the lineage of chosen_solution is a prefix of new_solution_group:\nReturn the new solution in new_solution_group as the next solution in chosen_solution.\n\nSet chosen_solution to be the new_solution_group\n\n\nOtherwise, set more_than_one_solution_group to True\n\nWhen complete, indicate to the caller if more_than_one_solution_group is True or False\nThis algorithm will allow the user interface to call the Solution Group Picker and have it return the \"answer\" solution group (if one exists), as well as a flag indicating if there are other solution groups so it can respond appropriately as described above.\nPerformance Optimizations\nGiven what we now know about what is needed from our combination generator, there are many optimizations that can be made to improve performance. Here are a couple:\nQuit generating at 2: Since we only really care about 2 solution groups, the generator doesn't need to keep track of all the sets to build all combinations.  Instead, once it has returned two unique solution groups, it only needs to generate iterations of those. In fact, it really only needs to generate iterations of the first. This eliminates a lot of work generating and testing sets that aren't used.\n\nMerge answers: We can reduce the number of sets we have to consider in set_list by observing that we only need to add a new set to the set list if we have a set that needs to be the base for more alternatives. Variables that have constraints with an upper limit of inf don't need to generate all the combinations since they will just be subsets of the one maximal set. So, if a solution only introduces new individuals to variables that have an upper limit of inf, it can just be merged into that set, it doesn't need to be added as a separate set to set_list.\n\nOther Observations Still Being Developed\nFor prop and ques phrases, we want to add \"there are more\" even if there are more in the current solution group. If the user says, \"a few files are in this folder\" and there are 100, we'd like it to say \"yes but there are more\". For wh-ques and comm phrases, we want it to say \"there are more\" if there is another solution group. Said another way: for prop, we need to respond with \"there are more\" if it is \"at least\" or \"exactly\" once we get above the level that a normal person would say \"at least\" for.  So, sometimes we say \"there are more\" for when there is another solution group, but other times we say \"there are more\" for when \"only\" would have failed.  For example: \"a few files ...\" works for 100 files since it is \"at least\". but \"only a few files\" would fail.\n\nAny variable that has max=inf will end up with only 1 valid set of individuals in any solution group. If all variables have this, there will be only one unique solution group.  A variable that has a range such as between(2, 4), will generate a subset for each count until it gets to 4. For example, there will be a subset that has 2 items, one that has 3, and one that has 4. It will also generate alternatives that are unique for each set < 4.\n\n", "title":"Combinations and Proper Responses", "teaser":"Combination Algorithm\nIn the section introducing the solution grouping algorithm, the algorithm starts with:\nFor each possible combination of solution ...", "site":"Perplexity", "section":"MRS Solver Conceptual", "categories":"", "tags":""}
]
